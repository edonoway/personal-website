<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Bits That Count: Quantifying and Predicting Emergent Capabilities in Language Models</title>
  <script src="https://d3js.org/d3.v7.min.js"></script>
  <style>
    :root {
      --coral: #D97757;
      --coral-light: #E89B7E;
      --coral-dark: #B85A3C;
      --dark-blue: #1a1a2e;
      --cream: #FAF8F5;
      --cream-dark: #F0EDE8;
      --text: #2D2D2D;
      --text-light: #666;
      --border: #E0DCD5;
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      line-height: 1.7;
      color: var(--text);
      background: var(--cream);
    }

    article {
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem 1.5rem 4rem;
    }

    header {
      text-align: left;
      margin-bottom: 3rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid var(--border);
    }

    h1 {
      font-size: 2.2rem;
      font-weight: 700;
      color: var(--dark-blue);
      margin-bottom: 1rem;
      line-height: 1.2;
    }

    .authors {
      font-size: 1rem;
      color: var(--text-light);
      margin-bottom: 1rem;
    }

    .summary {
      font-style: italic;
      color: var(--text-light);
      /* font-weight: 700; */
      /* max-width: 600px; */
      /* margin: 0 auto; */
    }

    h2 {
      font-size: 1.6rem;
      font-weight: 600;
      color: var(--dark-blue);
      margin: 3rem 0 1.5rem;
      padding-top: 1rem;
      border-top: 1px solid var(--border);
    }

    h3 {
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--dark-blue);
      margin: 2rem 0 1rem;
    }

    p {
      margin-bottom: 1.25rem;
      max-width: 700px;
    }

    strong {
      color: var(--dark-blue);
    }

    .highlight {
      background: linear-gradient(180deg, transparent 60%, rgba(217, 119, 87, 0.2) 60%);
    }

    .formula {
      font-family: 'Georgia', serif;
      font-size: 1.1rem;
      text-align: center;
      padding: 1.5rem;
      background: var(--cream-dark);
      border-radius: 8px;
      margin: 1.5rem 0;
      border-left: 4px solid var(--coral);
    }

    ul, ol {
      margin: 1rem 0 1.5rem 1.5rem;
      max-width: 700px;
    }

    li {
      margin-bottom: 0.5rem;
    }

    /* Visualization containers */
    .visualization {
      background: white;
      border-radius: 12px;
      padding: 1.5rem;
      margin: 2rem 0;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
      border: 1px solid var(--border);
    }

    .viz-title {
      font-size: 1.1rem;
      font-weight: 600;
      color: var(--dark-blue);
      margin-bottom: 0.5rem;
    }

    .viz-subtitle {
      font-size: 0.9rem;
      color: var(--text-light);
      margin-bottom: 1rem;
    }

    .viz-container {
      position: relative;
      width: 100%;
      min-height: 300px;
    }

    .viz-controls {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      align-items: center;
      margin-top: 1rem;
      padding-top: 1rem;
      border-top: 1px solid var(--border);
    }

    .viz-controls label {
      font-size: 0.85rem;
      color: var(--text-light);
    }

    .viz-controls input[type="range"] {
      width: 200px;
      accent-color: var(--coral);
    }

    .viz-controls button {
      background: var(--coral);
      color: white;
      border: none;
      padding: 0.5rem 1rem;
      border-radius: 6px;
      cursor: pointer;
      font-size: 0.85rem;
      transition: background 0.2s;
    }

    .viz-controls button:hover {
      background: var(--coral-dark);
    }

    .viz-controls button.secondary {
      background: var(--cream-dark);
      color: var(--text);
    }

    .viz-controls button.secondary:hover {
      background: var(--border);
    }

    .viz-controls button.active {
      background: var(--dark-blue);
    }

    .toggle-group {
      display: flex;
      gap: 0.25rem;
    }

    .toggle-group button {
      border-radius: 0;
    }

    .toggle-group button:first-child {
      border-radius: 6px 0 0 6px;
    }

    .toggle-group button:last-child {
      border-radius: 0 6px 6px 0;
    }

    .metric-display {
      font-family: 'SF Mono', 'Monaco', 'Consolas', monospace;
      font-size: 1.5rem;
      color: var(--coral);
      font-weight: 600;
    }

    /* SVG styles */
    svg {
      display: block;
      width: 100%;
      height: auto;
    }

    .axis text {
      font-size: 11px;
      fill: var(--text-light);
    }

    .axis line, .axis path {
      stroke: var(--border);
    }

    .grid line {
      stroke: var(--cream-dark);
      stroke-dasharray: 2, 2;
    }

    .annotation {
      font-size: 12px;
      fill: var(--text-light);
    }

    .annotation-box {
      fill: white;
      stroke: var(--border);
      rx: 4;
    }

    /* Calculator styles */
    .calculator {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
    }

    .calc-inputs {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .calc-input-group {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .calc-input-group label {
      font-size: 0.85rem;
      font-weight: 500;
      color: var(--text-light);
    }

    .calc-input-group input,
    .calc-input-group select {
      padding: 0.5rem;
      border: 1px solid var(--border);
      border-radius: 6px;
      font-size: 1rem;
    }

    .calc-output {
      background: var(--cream-dark);
      padding: 1.5rem;
      border-radius: 8px;
    }

    .calc-result {
      font-size: 2rem;
      font-weight: 700;
      color: var(--coral);
    }

    .calc-warning {
      color: var(--coral-dark);
      font-size: 0.9rem;
      margin-top: 0.5rem;
      padding: 0.5rem;
      background: rgba(217, 119, 87, 0.1);
      border-radius: 4px;
    }

    /* Tooltip */
    .tooltip {
      position: absolute;
      background: var(--dark-blue);
      color: white;
      padding: 0.5rem 0.75rem;
      border-radius: 6px;
      font-size: 0.8rem;
      pointer-events: none;
      opacity: 0;
      transition: opacity 0.15s;
      z-index: 100;
    }

    /* Illustrations */
    .illustration {
      background: white;
      border-radius: 12px;
      padding: 1.5rem;
      margin: 2rem 0;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
      border: 1px solid var(--border);
      text-align: center;
    }

    .illustration svg {
      display: block;
      margin: 0 auto;
    }

    .illustration-caption {
      font-size: 0.9rem;
      color: var(--text-light);
      margin-top: 1rem;
      margin-bottom: 0;
      font-style: italic;
      max-width: 600px;
      margin-left: auto;
      margin-right: auto;
    }

    /* Footnotes */
    .footnote {
      font-size: 0.85rem;
      color: var(--text-light);
      border-top: 1px solid var(--border);
      margin-top: 3rem;
      padding-top: 1rem;
    }

    .footnote p {
      margin-bottom: 0.5rem;
    }

    sup {
      color: var(--coral);
      font-weight: 500;
    }

    /* Responsive */
    @media (max-width: 768px) {
      h1 { font-size: 1.75rem; }
      h2 { font-size: 1.4rem; }
      .calculator { grid-template-columns: 1fr; }
      .viz-controls { flex-direction: column; align-items: flex-start; }
    }
  </style>
</head>
<body>
  <article>
    <header>
      <h1>Bits That Count: Quantifying and Predicting Emergent Capabilities in Language Models</h1>
      <p class="authors">Elizabeth Donoway, Hailey Joren, Ethan Perez, John Schulman, Fabien Roger, Jan Leike</p>
      <p class="summary">Quantifying and predicting what language models know, how much they (can) learn, and how they learn it.</p>
    </header>

    <section id="introduction">
      <p>It's unclear what models know.</p>

      <p>It's hard to get them to show us—they don't just tell us (yet), and we often don't even know the right questions to ask.</p>

      <p>Language models are pretrained on vast amounts of diverse data, acquiring capabilities that may remain hidden until the right prompt or training signal surfaces them. We can't enumerate all the capabilities a model might have, and sometimes we can't even anticipate them. Though we've made significant progress—and it's hard to dispute the many practical successes of AI that have been achieved anyway—we still have much to learn about what models know, how they learn, and how capable they might be.</p>

      <p>This uncertainty has practical consequences.</p>

      <p><strong>For safety:</strong> If a dangerous capability is latent, it can be surfaced with minimal intervention—a few examples, a clever prompt, an unexpected deployment context. If the capability must be taught from scratch, the information barrier is higher and more predictable. Knowing which regime we're in changes how we assess risk.</p>

      <p><strong>For evaluation:</strong> When we fine-tune models to assess their capabilities, are we measuring what they already know, or inadvertently teaching them something new? If our elicitation procedure crosses into teaching, we're no longer evaluating the model that will be deployed—we're evaluating a different model, one that learned during the evaluation itself.</p>

      <p><strong>For efficiency:</strong> Training is expensive. If a capability is already latent, massive datasets and high-rank adapters are wasteful. If it must be taught, insufficient data wastes time. Knowing the learning regime in advance lets us allocate resources appropriately.</p>

      <p><strong>For science:</strong> We largely lack formal descriptions of how models learn. We have heuristics and intuitions, but these are difficult to make predictions from. A quantitative framework for learning dynamics would let us ask—and answer—questions we currently can't even formulate precisely.</p>

      <p>We develop such a framework here, introducing <span class="highlight"><strong>Excess Description Length</strong></span> (EDL) as an operational metric for the generalizable information a model learns from training data. EDL distinguishes teaching from elicitation, tracks transitions between learning mechanisms, and predicts parameter capacity limits for fine-tuning.</p>

      <!-- <p>EDL offers a more comprehensive framework for evaluating model capabilities and learning, one that also aligns closely with our understanding of human learning and cognition.</p> -->
    </section>

    <h2>Learning as Compression</h2>

    <section id="alice-bob">
      <h3>Alice and Bob Learn How to Communicate Better</h3>

      <p>Imagine Alice has fine-tuned a language model and wants to share it with Bob. Bob already has the same base model and the same training inputs, but not the labels. Instead of sending gigabytes of weight differences, Alice could just send the labels along with instructions describing exactly how to replicate her training procedure.<sup>[1]</sup> She can even use the base model itself to communicate the labels to Bob. Bob trains his copy on them and reconstructs her model exactly.<sup>[2]</sup></p>

      <!-- Alice and Bob diagram: Two scenarios comparison -->
      <div class="illustration">
        <svg viewBox="0 0 800 380" style="max-width: 800px; width: 100%; height: auto;">
          <!-- Scenario 1: Sending weights (bad) -->
          <g transform="translate(0, 0)">
            <rect x="10" y="10" width="380" height="160" rx="8" fill="#fef6f6" stroke="#c66" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="200" y="30" text-anchor="middle" font-size="12" font-weight="600" fill="#c66">Option 1: Send the weights</text>

            <!-- Alice -->
            <g transform="translate(40, 50)">
              <circle cx="25" cy="25" r="20" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">A</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Alice</text>
            </g>

            <!-- Huge file -->
            <g transform="translate(120, 45)">
              <rect x="0" y="0" width="120" height="70" rx="4" fill="#1a1a2e"/>
              <text x="60" y="25" text-anchor="middle" font-size="9" fill="white">Weight Diff</text>
              <text x="60" y="42" text-anchor="middle" font-size="14" fill="#D97757" font-weight="bold">4.2 GB</text>
              <text x="60" y="58" text-anchor="middle" font-size="8" fill="#999">billions of floats</text>
            </g>

            <!-- Arrow -->
            <path d="M 250 80 L 300 80" stroke="#c66" stroke-width="2"/>
            <polygon points="300,80 290,74 290,86" fill="#c66"/>

            <!-- Bob -->
            <g transform="translate(320, 50)">
              <circle cx="25" cy="25" r="20" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">B</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Bob</text>
            </g>

            <!-- X mark -->
            <text x="200" y="145" text-anchor="middle" font-size="11" fill="#c66">Slow! Takes hours to transfer...</text>
          </g>

          <!-- Scenario 2: Sending data (good) -->
          <g transform="translate(410, 0)">
            <rect x="0" y="10" width="380" height="160" rx="8" fill="#f6fef6" stroke="#5a5" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="190" y="30" text-anchor="middle" font-size="12" font-weight="600" fill="#5a5">Option 2: Send the training data</text>

            <!-- Alice -->
            <g transform="translate(30, 50)">
              <circle cx="25" cy="25" r="20" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">A</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Alice</text>
            </g>

            <!-- Small file -->
            <g transform="translate(110, 55)">
              <rect x="0" y="0" width="80" height="50" rx="4" fill="#50C878"/>
              <text x="40" y="20" text-anchor="middle" font-size="9" fill="white">Labels</text>
              <text x="40" y="38" text-anchor="middle" font-size="12" fill="white" font-weight="bold">~2 MB</text>
            </g>

            <!-- Plus recipe -->
            <g transform="translate(200, 60)">
              <text x="0" y="20" font-size="14" fill="#666">+</text>
              <rect x="15" y="0" width="60" height="40" rx="4" fill="#F0EDE8" stroke="#E0DCD5"/>
              <text x="45" y="15" text-anchor="middle" font-size="8" fill="#666">Recipe:</text>
              <text x="45" y="28" text-anchor="middle" font-size="7" fill="#666">lr, epochs...</text>
            </g>

            <!-- Arrow -->
            <path d="M 280 80 L 310 80" stroke="#5a5" stroke-width="2"/>
            <polygon points="310,80 300,74 300,86" fill="#5a5"/>

            <!-- Bob trains -->
            <g transform="translate(320, 45)">
              <circle cx="25" cy="25" r="20" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">B</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Bob</text>
              <text x="25" y="75" text-anchor="middle" font-size="8" fill="#4A90D9">trains locally</text>
            </g>

            <!-- Check mark -->
            <text x="190" y="145" text-anchor="middle" font-size="11" fill="#5a5">Fast! Same result, way less data.</text>
          </g>

          <!-- Speech bubble from Alice -->
          <g transform="translate(100, 180)">
            <path d="M 0 30 Q 0 0 30 0 L 570 0 Q 600 0 600 30 L 600 70 Q 600 100 570 100 L 100 100 L 80 130 L 90 100 L 30 100 Q 0 100 0 70 Z" fill="#FAF8F5" stroke="#E0DCD5" stroke-width="1"/>
            <text x="300" y="35" text-anchor="middle" font-size="11" fill="#1a1a2e" font-style="italic">"The model diff is huge and would take forever to send!</text>
            <text x="300" y="52" text-anchor="middle" font-size="11" fill="#1a1a2e" font-style="italic">What if I just sent you the dataset I used instead? It's only 10,000 examples.</text>
            <text x="300" y="69" text-anchor="middle" font-size="11" fill="#1a1a2e" font-style="italic">You can train your own copy—took me 30 minutes with this recipe."</text>
            <text x="300" y="90" text-anchor="middle" font-size="10" fill="#666">— Alice</text>
          </g>

          <!-- Key insight -->
          <g transform="translate(150, 320)">
            <rect x="0" y="0" width="500" height="45" rx="6" fill="#D97757" opacity="0.1" stroke="#D97757"/>
            <text x="250" y="20" text-anchor="middle" font-size="12" fill="#1a1a2e" font-weight="600">Key insight: Sending the training data is equivalent to sending the weight update.</text>
            <text x="250" y="38" text-anchor="middle" font-size="11" fill="#666">The information content is the same—but the data is much smaller!</text>
          </g>
        </svg>
        <p class="illustration-caption">Alice can share her fine-tuned model by sending training data instead of weights. Both contain the same information, but the data is far more compact.</p>
      </div>

      <p>How many bits does Alice need to send?</p>

      <p>This is the <strong>minimum description length</strong> (MDL) of the training data—the shortest message that lets Bob reconstruct the fine-tuned model given what he already knows.</p>

      <p>To minimize the description length—that is, the file size—Alice can compress the labels. But she and Bob need to use the same compression algorithm so that Bob can decompress them. Here, the model itself becomes the compression algorithm. If the model already predicts a label well, Alice needs very few bits to communicate it. Saying "the answer is 68" to a model that already thinks "68" is likely requires almost no information. But if the model expects "14" when the answer is actually "68", Alice needs more bits to convey the surprise. Better predictions mean shorter messages.</p>

      <p>If Alice sends labels sequentially, she and Bob can use an optimizer—say, SGD—to iteratively improve (train) their shared model as it compresses. They each update their copy after each batch Bob receives, using only the labels Bob has received so far. This keeps the compression algorithm identical on both ends, so Bob can always decompress.</p>

      <p>Over time, the model's predictions improve, so Alice can send each new batch of labels using progressively smaller files. Once every label in the dataset has been received by Bob, he has all the information necessary to recreate Alice's fine-tuned model.</p>
    </section>

    <section id="computing-mdl">
      <h3>Computing MDL from a Training Run</h3>

      <p>MDL is simply the sum of log-losses on each training label, computed <em>before</em> the model updates on that label. It measures how many bits the model needed to receive to encode all the training labels once. In terms of training, this is the total log-loss accumulated over the first epoch.</p>

      <!-- Visualization 1: Accumulating MDL -->
      <div class="visualization" id="viz-mdl">
        <div class="viz-title">Accumulating MDL</div>
        <div class="viz-subtitle">Watch the model accumulate bits as it processes training data. The shaded area represents the total MDL.</div>
        <div class="viz-container" id="mdl-chart"></div>
        <div class="viz-controls">
          <button id="mdl-play">Play</button>
          <label>Training step: <span id="mdl-step-display">0</span></label>
          <input type="range" id="mdl-slider" min="0" max="100" value="0">
          <div class="metric-display">MDL = <span id="mdl-value">0</span> bits</div>
        </div>
      </div>
    </section>

    <section id="mdl-to-edl">
      <h3>From MDL to EDL</h3>

      <p>MDL tells us how much information the model received. But how much did it actually <em>learn</em>? How much structure did it extract about patterns that generalize to new data?</p>

      <p>After training (potentially for multiple epochs), evaluate the model on held-out test data. The test loss represents the model's remaining uncertainty—the information it <em>couldn't</em> compress into its parameters.</p>

      <p>If the model learned nothing generalizable, its test loss would be as high as its initial training loss. MDL would equal n × L<sub>test</sub>, and there would be no "excess."</p>

      <p>If the model learned perfectly, its test loss would be zero. Everything in MDL would be "excess"—information that got compressed into the weights.</p>

      <p><strong>Excess description length</strong> is the difference:</p>

      <div class="formula">
        <strong>EDL = MDL − n × L<sub>test</sub></strong>
      </div>

      <p>This is the information that was "excess" during training—bits the model needed to receive early on but wouldn't need anymore after learning. It's the information that got absorbed into the parameters. <em>The bits that count toward generalization.</em></p>

      <!-- EDL intuition diagram -->
      <div class="illustration">
        <svg viewBox="0 0 800 320" style="max-width: 800px; width: 100%; height: auto;">
          <!-- Scenario 1: Bob without trained model -->
          <g transform="translate(20, 20)">
            <rect x="0" y="0" width="360" height="130" rx="8" fill="#fef6f6" stroke="#c66" stroke-width="1"/>
            <text x="180" y="25" text-anchor="middle" font-size="12" font-weight="600" fill="#c66">Scenario A: Bob has only the base model</text>

            <!-- Alice sends MDL -->
            <g transform="translate(20, 45)">
              <circle cx="20" cy="20" r="16" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">A</text>
            </g>

            <!-- Big message -->
            <g transform="translate(80, 40)">
              <rect x="0" y="0" width="140" height="50" rx="4" fill="#D97757"/>
              <text x="70" y="22" text-anchor="middle" font-size="10" fill="white">Compressed labels</text>
              <text x="70" y="38" text-anchor="middle" font-size="14" fill="white" font-weight="bold">MDL bits</text>
            </g>

            <!-- Arrow -->
            <path d="M 230 65 L 270 65" stroke="#c66" stroke-width="2"/>
            <polygon points="270,65 260,59 260,71" fill="#c66"/>

            <!-- Bob base -->
            <g transform="translate(285, 45)">
              <circle cx="20" cy="20" r="16" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">B</text>
              <text x="20" y="50" text-anchor="middle" font-size="8" fill="#666">Base model</text>
            </g>

            <text x="180" y="115" text-anchor="middle" font-size="10" fill="#666">Bob needs ALL the information to reconstruct Alice's model</text>
          </g>

          <!-- Scenario 2: Bob WITH trained model -->
          <g transform="translate(410, 20)">
            <rect x="0" y="0" width="360" height="130" rx="8" fill="#f6fef6" stroke="#5a5" stroke-width="1"/>
            <text x="180" y="25" text-anchor="middle" font-size="12" font-weight="600" fill="#5a5">Scenario B: Bob already has the trained model</text>

            <!-- Alice sends less -->
            <g transform="translate(20, 45)">
              <circle cx="20" cy="20" r="16" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">A</text>
            </g>

            <!-- Small message -->
            <g transform="translate(80, 45)">
              <rect x="0" y="0" width="100" height="40" rx="4" fill="#50C878"/>
              <text x="50" y="18" text-anchor="middle" font-size="9" fill="white">Just residuals</text>
              <text x="50" y="32" text-anchor="middle" font-size="12" fill="white" font-weight="bold">n × L<tspan baseline-shift="sub" font-size="8">test</tspan></text>
            </g>

            <!-- Arrow -->
            <path d="M 195 65 L 270 65" stroke="#5a5" stroke-width="2"/>
            <polygon points="270,65 260,59 260,71" fill="#5a5"/>

            <!-- Bob trained -->
            <g transform="translate(285, 40)">
              <circle cx="20" cy="20" r="16" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">B</text>
              <rect x="-5" y="42" width="50" height="20" rx="3" fill="#1a1a2e"/>
              <text x="20" y="56" text-anchor="middle" font-size="7" fill="white">Trained</text>
            </g>

            <text x="180" y="115" text-anchor="middle" font-size="10" fill="#666">Bob only needs residual uncertainty—he already learned the patterns!</text>
          </g>

          <!-- The difference = EDL -->
          <g transform="translate(100, 165)">
            <rect x="0" y="0" width="600" height="140" rx="8" fill="#D97757" opacity="0.08" stroke="#D97757"/>
            <text x="300" y="25" text-anchor="middle" font-size="14" font-weight="600" fill="#1a1a2e">The Difference = EDL</text>

            <!-- Visual equation -->
            <g transform="translate(50, 50)">
              <!-- MDL box -->
              <rect x="0" y="0" width="100" height="60" rx="4" fill="#D97757" opacity="0.7"/>
              <text x="50" y="25" text-anchor="middle" font-size="11" fill="white">MDL</text>
              <text x="50" y="45" text-anchor="middle" font-size="10" fill="white">(all bits sent)</text>

              <!-- Minus -->
              <text x="130" y="35" font-size="24" fill="#1a1a2e">−</text>

              <!-- n*L_test box -->
              <rect x="160" y="10" width="100" height="40" rx="4" fill="#50C878"/>
              <text x="210" y="35" text-anchor="middle" font-size="11" fill="white">n × L<tspan baseline-shift="sub" font-size="8">test</tspan></text>

              <!-- Equals -->
              <text x="290" y="35" font-size="24" fill="#1a1a2e">=</text>

              <!-- EDL box -->
              <rect x="320" y="0" width="160" height="60" rx="4" fill="#D97757"/>
              <text x="400" y="25" text-anchor="middle" font-size="14" fill="white" font-weight="bold">EDL</text>
              <text x="400" y="45" text-anchor="middle" font-size="10" fill="white">(bits that generalize)</text>
            </g>

            <text x="300" y="125" text-anchor="middle" font-size="11" fill="#666" font-style="italic">EDL = the information the model actually learned—what it couldn't have predicted without training</text>
          </g>
        </svg>
        <p class="illustration-caption">EDL measures the difference: how many bits Alice needs to send to Bob without the trained model vs. with it. This difference is exactly what the model learned.</p>
      </div>

      <!-- Visualization 2: MDL/EDL Decomposition -->
      <div class="visualization" id="viz-edl-decomp">
        <div class="viz-title">The MDL/EDL Decomposition</div>
        <div class="viz-subtitle">See how MDL decomposes into EDL (learned information) and residual (test loss × n).</div>
        <div class="viz-container" id="edl-decomp-chart"></div>
        <div class="viz-controls">
          <div class="toggle-group">
            <button id="show-mdl" class="active">Show MDL</button>
            <button id="show-edl" class="secondary">Show EDL</button>
            <button id="show-both" class="secondary">Show Both</button>
          </div>
          <label>Adjust L<sub>test</sub>: <input type="range" id="ltest-slider" min="0.1" max="2" step="0.05" value="0.8"></label>
          <span id="ltest-display">0.80</span>
        </div>
      </div>

      <!-- Visualization: Multi-epoch training -->
      <div class="visualization" id="viz-multi-epoch">
        <div class="viz-title">Training as Information Extraction</div>
        <div class="viz-subtitle">The dataset is an information source (MDL). Training extracts generalizable information (EDL). More epochs can increase extraction, but can't add information beyond what's in the data.</div>
        <div class="viz-container" id="multi-epoch-chart"></div>
        <div class="viz-controls">
          <button id="epoch-play">Play Training</button>
          <label>Step: <span id="step-display">0</span> / 1000</label>
          <input type="range" id="step-slider" min="0" max="1000" value="0" step="10">
          <div style="display: flex; gap: 2rem; margin-left: auto;">
            <div style="font-size: 0.85rem;">
              <span style="display: inline-block; width: 12px; height: 12px; background: rgba(232, 155, 126, 0.5); margin-right: 4px; vertical-align: middle;"></span>
              MDL (bits in data): <span id="mdl-total" class="metric-display" style="font-size: 1rem;">0</span>
            </div>
            <div style="font-size: 0.85rem;">
              <span style="display: inline-block; width: 12px; height: 12px; background: #D97757; margin-right: 4px; vertical-align: middle;"></span>
              EDL (bits learned): <span id="edl-total" class="metric-display" style="font-size: 1rem;">0</span>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="why-this-works">
      <h3>Why This Works</h3>

      <p>Learning is compression. When a model learns a pattern, it can predict future instances of that pattern with lower loss, meaning fewer bits needed to encode them.</p>

      <p>A model that has learned "numbers sum according to arithmetic" can encode "23 + 45 = 68" very cheaply. A model that treats each arithmetic fact as an arbitrary association needs many bits per fact.</p>

      <p>EDL captures exactly this: it measures how much the model's predictions improved through learning, expressed in the natural currency of information theory—bits.</p>
      
      <p>EDL also captures the learning dynamics. As the model learns, its predictions improve, so the bits needed to encode new labels decrease. The rate of this decrease reflects how quickly the model is learning generalizable patterns.</p>

      <p>Crucially, EDL separates generalization from memorization. A model that memorizes the training set achieves low training loss but high test loss, so EDL remains small because L<sub>test</sub> is large. Only patterns that transfer to held-out data contribute to EDL.</p>

      <p>In this way, EDL provides a more nuanced view of model performance and learning than traditional metrics. It highlights the importance of generalization and the ability to apply learned knowledge to new situations, rather than simply memorizing the training data. It emphasizes that efficient learners achieve better compression by leveraging learned complexity—existing knowledge—to reduce the bits needed for learning.</p>
    </section>

    <section id="note-on-loss">
      <h3>A Note on Loss</h3>

      <p>Log-loss is a natural choice for measuring the information content of training data and the learning process. It has a clear interpretation in terms of bits, and it directly reflects the model's uncertainty about the training labels.</p>

      <p>However, it's important to recognize that log-loss is not a perfect proxy for all capabilities we care about. Most metrics we might want to use are not differentiable, and we may not even be able to express them quantitatively, anyway. Log-loss is often the best proxy we have.</p>

      <p>Natural language tasks can have many "correct" responses—different phrasings that correspond to the same answer—and the dataset selects one of these as the label. For tasks with multiple valid responses, the dataset's choice of "ground truth" can introduce noise, meaning that low loss doesn't always correspond to high performance on the underlying task—or the actual capability we want to assess. In such cases, EDL may not perfectly capture the emergence of capabilities that are not well-aligned with the specific labels used during training.</p>

      <!-- <p>Natural language tasks can have many "correct" responses—different phrasings that correspond to the same answer—and the dataset selects one of these as the label. This choice of "ground truth" means that labels are noisy (they don't fully match the true distribution of correct responses), and that loss doesn't always closely track the behaviors we care about.</p> -->

      <p>We want to emphasize that loss and EDL, respectively, measure <em>information</em> and information <em>learned</em> (compression) with respect to a <em>specific distribution</em>; they are not direct measures of <em>capability itself</em>. We measure loss (and EDL) because we hope it tracks well with metrics we <em>do</em> care about for meaningful capability learned, not because it <em>is</em> the metric we care about.</p>

      <p>Despite these limitations, log-loss and EDL remain valuable tools for quantifying learning dynamics and generalization in language models. They provide a consistent framework for measuring how much information a model has absorbed from its training data, even if it doesn't capture every nuance of capability development.</p>


    <h2>More Is Different</h2>

    <section id="emergence">
      <p>In 1972, Philip Anderson argued that the reductionist program in physics—explaining everything by decomposing it into fundamental parts—misses something essential. "The ability to reduce everything to simple fundamental laws," he wrote, "does not imply the ability to start from those laws and reconstruct the universe." At every level of scale and organization, new properties appear that are qualitatively different from anything present at the level below. Superfluidity cannot be predicted from the quantum mechanics of individual helium atoms. Consciousness does not follow from neuron firing rates. The whole is not merely the sum of its parts—<em>more is different</em>.</p>

      <p>This insight—that complexity at one scale gives rise to qualitatively new phenomena at another—is the principle of <strong>emergence</strong>. And it turns out to be central to understanding what language models learn.</p>

      <h3>Emergence in Language Models</h3>

      <p>Consider what happens during pretraining. A model processes billions of tokens, each one a local observation: a word following other words. No single token teaches the model arithmetic. No single paragraph teaches it to reason about code, or to translate between languages, or to write poetry. But collectively, at scale, these local patterns give rise to capabilities that are qualitatively different from anything present in any individual training example. The model develops internal representations that capture abstract structure: algorithms, conceptual relationships, reasoning strategies. These are emergent properties of the training process—they arise from the collective interaction of vast amounts of data with the model's parameters, and they cannot be understood by examining any single component in isolation.</p>

      <p>This is Anderson's principle, instantiated in a neural network. <em>More is different</em>: more data, more parameters, more computation produce capabilities that are not simply "more of the same" but something qualitatively new.</p>

      <h3>The Complexity of Capabilities</h3>

      <p>In algorithmic information theory, the <em>complexity</em> of a system is the length of its shortest description. More complex systems require longer descriptions—more bits to specify.</p>

      <p>We can evaluate any system in terms of its complexity, regardless of what that system is or how it manifests. Functions, computer programs, humans, rocks, the universe, and—most relevant for our experiments here—models and capabilities all have their own respective complexities, determined by what components they're composed of and how those components interact.</p>

      <p>As a visual example, consider the complexities of systems with two degrees of freedom, shape and color:</p>

      <!-- Complexity comparison diagram -->
      <div class="illustration">
        <svg viewBox="0 0 800 220" style="max-width: 800px; width: 100%; height: auto;">
          <!-- System A: 25 blue circles -->
          <g transform="translate(20, 10)">
            <rect x="0" y="0" width="350" height="200" rx="8" fill="#f6f9fe" stroke="#4A90D9" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="175" y="25" text-anchor="middle" font-size="13" font-weight="600" fill="#1a1a2e">System A: 25 blue circles</text>

            <!-- 5x5 grid of blue circles -->
            <g transform="translate(30, 40)">
              <!-- Row 1 -->
              <circle cx="0" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="0" r="10" fill="#4A90D9"/>
              <!-- Row 2 -->
              <circle cx="0" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="28" r="10" fill="#4A90D9"/>
              <!-- Row 3 -->
              <circle cx="0" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="56" r="10" fill="#4A90D9"/>
              <!-- Row 4 -->
              <circle cx="0" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="84" r="10" fill="#4A90D9"/>
              <!-- Row 5 -->
              <circle cx="0" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="112" r="10" fill="#4A90D9"/>
            </g>

            <!-- Arrow -->
            <path d="M 170 100 L 210 100" stroke="#666" stroke-width="2"/>
            <polygon points="210,100 200,94 200,106" fill="#666"/>

            <!-- Compressed description -->
            <g transform="translate(225, 65)">
              <rect x="0" y="0" width="100" height="70" rx="6" fill="#F0EDE8" stroke="#E0DCD5"/>
              <circle cx="30" cy="35" r="14" fill="#4A90D9"/>
              <text x="55" y="40" font-size="16" fill="#1a1a2e" font-weight="500">× 25</text>
            </g>
            <text x="275" y="160" text-anchor="middle" font-size="11" fill="#50C878" font-weight="500">Short description</text>
          </g>

          <!-- System B: Four different shapes -->
          <g transform="translate(400, 10)">
            <rect x="0" y="0" width="380" height="200" rx="8" fill="#fef9f6" stroke="#D97757" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="190" y="25" text-anchor="middle" font-size="13" font-weight="600" fill="#1a1a2e">System B: 4 distinct shapes</text>

            <!-- Four shapes in a row -->
            <g transform="translate(40, 50)">
              <!-- Red square -->
              <rect x="0" y="8" width="28" height="28" rx="2" fill="#D97757"/>
              <!-- Blue circle -->
              <circle cx="80" cy="22" r="16" fill="#4A90D9"/>
              <!-- Green triangle -->
              <polygon points="145,38 160,6 175,38" fill="#50C878"/>
              <!-- Yellow rhombus -->
              <polygon points="235,6 255,22 235,38 215,22" fill="#E8A838"/>
            </g>

            <!-- Arrow down -->
            <path d="M 190 100 L 190 120" stroke="#666" stroke-width="2"/>
            <polygon points="190,120 184,110 196,110" fill="#666"/>

            <!-- Long description -->
            <g transform="translate(50, 130)">
              <rect x="0" y="0" width="280" height="50" rx="6" fill="#F0EDE8" stroke="#E0DCD5"/>
              <text x="140" y="22" text-anchor="middle" font-size="10" fill="#1a1a2e">red square, blue circle,</text>
              <text x="140" y="38" text-anchor="middle" font-size="10" fill="#1a1a2e">green triangle, yellow rhombus</text>
            </g>
            <text x="190" y="198" text-anchor="middle" font-size="11" fill="#c66" font-weight="500">Long description</text>
          </g>
        </svg>
        <p class="illustration-caption">System A contains more objects but has a shorter description—it is less complex. System B requires specifying each shape and color individually.</p>
      </div>

      <p>The same principle applies to capabilities. A model that has learned the algorithm for addition has a compact representation that covers infinitely many arithmetic facts. A model that memorizes individual facts needs a separate entry for each one—incompressible, high complexity.</p>

      <h3>Where Emergence Meets Elicitation</h3>

      <p>Here is where Anderson's principle connects to the central question of this work.</p>

      <p>During pretraining, "more is different": scale produces emergent capabilities—complex internal representations that couldn't exist in a smaller model or with less data. These emergent capabilities have a measurable <em>complexity</em>, an information cost that was paid during pretraining.</p>

      <p>The question we ask is: what happens when we fine-tune? Is the model surfacing complexity that already exists in its weights, or is it building new complexity from scratch?</p>

      <p>When the relevant complexity is already present—when the emergent capability is latent—the model doesn't need to reconstruct it. It only needs a small signal that says, in effect, "use <em>this</em> capability for <em>this</em> task." This is <strong>elicitation</strong>: accessing emergent structure that already exists. The information cost is low, because the complexity was already paid for.</p>

      <p>When the relevant complexity is absent—when the capability never emerged during pretraining—the model must build it during fine-tuning. It must pay the full information cost of constructing new representations. This is <strong>teaching</strong>: creating complexity that doesn't yet exist. The information cost is high, because emergence hasn't happened yet.</p>

      <p>Our section titles are a nod to the interplay between these ideas. Anderson's "more is different" describes how scale creates emergence. The scaling-era mantra emphasizes the power of more data and more compute. We find that both need qualification. When the emergent complexity already exists, <strong>"less is all you need"</strong>—remarkably little information suffices to surface it. When it doesn't, <strong>"more is necessary"</strong>—you can't shortcut the information cost of building complexity from scratch.</p>

      <p>EDL measures this cost. And the scaling of EDL with data reveals which learning mechanism—elicitation or teaching—governs the dynamics we observe.</p>
    </section>

    <h2>Dynamical Signatures of Elicitation and Teaching</h2>

    <section id="signatures">
      <p>When we plot EDL per token against the number of training examples, we see qualitatively different patterns depending on the dominant learning mechanism at a given dataset size.</p>

      <h3>Elicitation: Monotonically Decreasing</h3>

      <p>For models with latent capabilities, EDL per token decreases monotonically as we add training examples.</p>

      <p>The first example may be highly informative, aligning a model's outputs to the desired response format and reducing uncertainty about which of its capabilities are relevant for the task ("Oh, you want me to output numbers in this format for arithmetic problems"). But subsequent examples add less and less. The model already knows arithmetic; additional examples just confirm what it already knows. There is no new algorithmic information to be learned.</p>

      <!-- Elicitation cartoon: uncertainty collapse with specific hypotheses -->
      <div class="illustration">
        <svg viewBox="0 0 900 300" style="max-width: 900px; width: 100%; height: auto;">
          <!-- Stage 1: Prompt with many possible responses -->
          <g transform="translate(15, 10)">
            <text x="105" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">Prompt: "23 + 45 ="</text>

            <!-- Prompt box -->
            <rect x="35" y="22" width="140" height="32" rx="6" fill="#1a1a2e"/>
            <text x="105" y="43" text-anchor="middle" font-size="11" fill="white" font-family="monospace">23 + 45 =</text>

            <!-- Arrow down -->
            <path d="M 105 58 L 105 72" stroke="#666" stroke-width="1.5"/>
            <polygon points="105,76 101,68 109,68" fill="#666"/>

            <!-- Model considering hypotheses label -->
            <text x="105" y="92" text-anchor="middle" font-size="9" fill="#666">Model's output distribution:</text>

            <!-- Hypothesis bars - all bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" text-anchor="end">"68"</text>
              <rect x="70" y="2" width="65" height="12" rx="2" fill="#D97757"/>
              <text x="140" y="11" font-size="8" fill="#666">18%</text>

              <text x="65" y="27" font-size="9" fill="#1a1a2e" text-anchor="end">"...is even"</text>
              <rect x="70" y="18" width="50" height="12" rx="2" fill="#4A90D9"/>
              <text x="125" y="27" font-size="8" fill="#666">14%</text>

              <text x="65" y="43" font-size="9" fill="#1a1a2e" text-anchor="end">"...problem"</text>
              <rect x="70" y="34" width="40" height="12" rx="2" fill="#50C878"/>
              <text x="115" y="43" font-size="8" fill="#666">11%</text>

              <text x="65" y="59" font-size="9" fill="#1a1a2e" text-anchor="end">"...÷ by 4"</text>
              <rect x="70" y="50" width="32" height="12" rx="2" fill="#E8A838"/>
              <text x="107" y="59" font-size="8" fill="#666">9%</text>

              <text x="65" y="75" font-size="9" fill="#999" text-anchor="end">"= 14"</text>
              <rect x="70" y="66" width="4" height="12" rx="2" fill="#ccc"/>
              <text x="79" y="75" font-size="8" fill="#999">1%</text>

              <text x="65" y="91" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="82" width="20" height="12" rx="2" fill="#ccc" opacity="0.5"/>
            </g>

            <text x="105" y="210" text-anchor="middle" font-size="8" fill="#666" font-style="italic">Many valid completions</text>
          </g>

          <!-- Arrow: sees target output -->
          <g transform="translate(160, 120)">
            <path d="M 0 15 L 40 15" stroke="#D97757" stroke-width="2"/>
            <polygon points="45,15 37,10 37,20" fill="#D97757"/>
            <text x="22" y="40" text-anchor="middle" font-size="9" fill="#D97757" font-weight="600">Label: "68"</text>
          </g>

          <!-- Stage 2: After seeing example -->
          <g transform="translate(220, 10)">
            <text x="95" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">After 1 example</text>

            <!-- Updated probability bars - all bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" font-weight="600" text-anchor="end">"68"</text>
              <rect x="70" y="2" width="115" height="12" rx="2" fill="#D97757"/>
              <text x="190" y="11" font-size="8" fill="#666">92%</text>

              <text x="65" y="27" font-size="9" fill="#999" text-anchor="end">"...is even"</text>
              <rect x="70" y="18" width="6" height="12" rx="2" fill="#4A90D9" opacity="0.3"/>

              <text x="65" y="43" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="34" width="8" height="12" rx="2" fill="#ccc" opacity="0.3"/>
            </g>

            <!-- Insight box -->
            <rect x="5" y="160" width="180" height="50" rx="6" fill="#D97757" fill-opacity="0.1" stroke="#D97757"/>
            <text x="95" y="178" text-anchor="middle" font-size="9" fill="#1a1a2e" font-weight="600">"Oh! You want the numeric</text>
            <text x="95" y="192" text-anchor="middle" font-size="9" fill="#1a1a2e" font-weight="600">answer, not a description."</text>
            <text x="95" y="206" text-anchor="middle" font-size="8" fill="#666">Uncertainty collapsed</text>
          </g>

          <!-- Arrow: next example -->
          <g transform="translate(415, 120)">
            <path d="M 0 15 L 40 15" stroke="#50C878" stroke-width="2"/>
            <polygon points="45,15 37,10 37,20" fill="#50C878"/>
            <text x="22" y="40" text-anchor="middle" font-size="9" fill="#50C878">new prompt</text>
          </g>

          <!-- Stage 3: On new problem, immediately correct -->
          <g transform="translate(475, 10)">
            <text x="95" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">Prompt: "17 + 29 ="</text>

            <!-- New prompt box -->
            <rect x="25" y="22" width="140" height="32" rx="6" fill="#1a1a2e"/>
            <text x="95" y="43" text-anchor="middle" font-size="11" fill="white" font-family="monospace">17 + 29 =</text>

            <!-- Arrow down -->
            <path d="M 95 58 L 95 72" stroke="#666" stroke-width="1.5"/>
            <polygon points="95,76 91,68 99,68" fill="#666"/>

            <!-- Immediately correct distribution - bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" font-weight="600" text-anchor="end">"46"</text>
              <rect x="70" y="2" width="122" height="12" rx="2" fill="#50C878"/>
              <text x="197" y="11" font-size="8" fill="#666">98%</text>

              <text x="65" y="27" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="18" width="3" height="12" rx="2" fill="#ccc" opacity="0.3"/>
            </g>

            <!-- Success indicator -->
            <g transform="translate(15, 160)">
              <rect x="0" y="0" width="160" height="50" rx="6" fill="#50C878"/>
              <text x="80" y="22" text-anchor="middle" font-size="13" fill="white" font-weight="600">"46" ✓</text>
              <text x="80" y="40" text-anchor="middle" font-size="9" fill="white">One example was enough!</text>
            </g>
          </g>

          <!-- Stage 4: Diminishing returns -->
          <g transform="translate(695, 10)">
            <text x="95" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">After 10 examples</text>

            <!-- Nearly identical distribution - bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" font-weight="600" text-anchor="end">"[answer]"</text>
              <rect x="70" y="2" width="124" height="12" rx="2" fill="#50C878"/>
              <text x="199" y="11" font-size="8" fill="#666">99%</text>

              <text x="65" y="27" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="18" width="2" height="12" rx="2" fill="#ccc" opacity="0.3"/>
            </g>

            <!-- Diminishing returns box -->
            <rect x="5" y="160" width="180" height="50" rx="6" fill="#f0f0f0" stroke="#ccc"/>
            <text x="95" y="180" text-anchor="middle" font-size="9" fill="#666">Already at 98% → 99%</text>
            <text x="95" y="195" text-anchor="middle" font-size="9" fill="#666" font-weight="600">Diminishing returns!</text>
            <text x="95" y="210" text-anchor="middle" font-size="8" fill="#999">EDL/token decreases</text>
          </g>
        </svg>
        <p class="illustration-caption">Elicitation: The model knows many things about "23+45." The first example collapses uncertainty about which capability to use. Additional examples provide diminishing information because the distribution is already near the target.</p>
      </div>

      <p>This is the signature of elicitation: <em>diminishing returns to data</em>. Each example provides less marginal information than the previous one.</p>

      <h3>Teaching: Monotonically Increasing</h3>

      <p>When models learn new capabilities, EDL per token <em>increases</em> as we add examples.</p>

      <p>Early in training, the model lacks the representations to identify any pattern. Each example is an isolated data point, essentially noise. The model can extract almost no generalizable information. The complexity of the task (and the capabilities required for it) is vastly larger than the amount of information contained in the data received by the model so far.</p>

      <p>But as examples accumulate, the model begins to form useful representations. It starts to see the patterns in the data. Each new example makes the data more informative as a <em>whole</em>, because the model can now recognize patterns in earlier examples that it previously missed. The model is learning how to learn from this data.</p>

      <!-- Teaching cartoon: shapes and colors pattern learning with backfilling -->
      <div class="illustration">
        <svg viewBox="0 0 900 520" style="max-width: 900px; width: 100%; height: auto;">
          <!-- Task description -->
          <g transform="translate(450, 10)">
            <text x="0" y="0" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">Task: Learn to predict colors from shapes</text>
            <text x="0" y="14" text-anchor="middle" font-size="9" fill="#666">(True rule: curved → red, straight edges only → blue)</text>
          </g>

          <!-- Stage 1: One example -->
          <g transform="translate(15, 35)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#1a1a2e">Example 1</text>
            <rect x="10" y="10" width="140" height="55" rx="5" fill="#F0EDE8" stroke="#E0DCD5"/>
            <rect x="55" y="22" width="20" height="20" fill="#4A90D9" stroke="#2E6BA6"/>
            <text x="85" y="36" font-size="9" fill="#1a1a2e">→ blue</text>

            <rect x="10" y="72" width="140" height="40" rx="5" fill="#fff" stroke="#ccc"/>
            <text x="80" y="88" text-anchor="middle" font-size="8" fill="#666">Hypothesis:</text>
            <text x="80" y="102" text-anchor="middle" font-size="9" fill="#1a1a2e">"All shapes = blue"</text>
            <text x="80" y="125" text-anchor="middle" font-size="9" fill="#999">EDL: ~0 bits</text>
          </g>

          <!-- Arrow 1 -->
          <g transform="translate(165, 70)">
            <path d="M 0 0 L 25 0" stroke="#666" stroke-width="1.5"/>
            <polygon points="28,0 22,-4 22,4" fill="#666"/>
          </g>

          <!-- Stage 2: Two examples -->
          <g transform="translate(200, 35)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#1a1a2e">Example 2</text>
            <rect x="10" y="10" width="140" height="55" rx="5" fill="#F0EDE8" stroke="#E0DCD5"/>
            <rect x="30" y="25" width="16" height="16" fill="#4A90D9" stroke="#2E6BA6" opacity="0.5"/>
            <circle cx="100" cy="33" r="11" fill="#D97757" stroke="#B85A3C"/>
            <text x="120" y="37" font-size="9" fill="#1a1a2e">→ red</text>

            <rect x="10" y="72" width="140" height="40" rx="5" fill="#fff" stroke="#E8A838"/>
            <text x="80" y="88" text-anchor="middle" font-size="8" fill="#666">Hypothesis:</text>
            <text x="80" y="102" text-anchor="middle" font-size="9" fill="#1a1a2e">"Circles = red, else blue"</text>
            <text x="80" y="125" text-anchor="middle" font-size="9" fill="#E8A838">EDL: rising ↑</text>
          </g>

          <!-- Arrow 2 -->
          <g transform="translate(350, 70)">
            <path d="M 0 0 L 25 0" stroke="#666" stroke-width="1.5"/>
            <polygon points="28,0 22,-4 22,4" fill="#666"/>
          </g>

          <!-- Stage 3: Three examples with AHA moment -->
          <g transform="translate(385, 35)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#50C878">Example 3 - Aha!</text>
            <rect x="10" y="10" width="140" height="55" rx="5" fill="#F0EDE8" stroke="#50C878" stroke-width="2"/>
            <rect x="22" y="27" width="14" height="14" fill="#4A90D9" stroke="#2E6BA6" opacity="0.5"/>
            <circle cx="60" cy="34" r="9" fill="#D97757" stroke="#B85A3C" opacity="0.5"/>
            <ellipse cx="108" cy="34" rx="14" ry="9" fill="#D97757" stroke="#B85A3C"/>
            <text x="130" y="38" font-size="9" fill="#1a1a2e">→ red!</text>

            <rect x="10" y="72" width="140" height="40" rx="5" fill="#50C878" fill-opacity="0.1" stroke="#50C878" stroke-width="2"/>
            <text x="80" y="88" text-anchor="middle" font-size="8" fill="#1a1a2e" font-weight="600">Pattern found:</text>
            <text x="80" y="102" text-anchor="middle" font-size="9" fill="#1a1a2e">"Curved = red!"</text>
            <text x="80" y="125" text-anchor="middle" font-size="9" fill="#50C878" font-weight="600">EDL: peaks! ↑↑</text>
          </g>

          <!-- Arrow 3 -->
          <g transform="translate(535, 70)">
            <path d="M 0 0 L 25 0" stroke="#666" stroke-width="1.5"/>
            <polygon points="28,0 22,-4 22,4" fill="#666"/>
          </g>

          <!-- Stage 4: Pattern complete -->
          <g transform="translate(570, 35)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#1a1a2e">Generalized</text>
            <rect x="10" y="10" width="140" height="100" rx="5" fill="#50C878" fill-opacity="0.1" stroke="#50C878"/>
            <text x="80" y="30" text-anchor="middle" font-size="9" fill="#1a1a2e" font-weight="600">Learned rule:</text>
            <circle cx="45" cy="52" r="10" fill="#D97757" stroke="#B85A3C"/>
            <ellipse cx="85" cy="52" rx="12" ry="8" fill="#D97757" stroke="#B85A3C"/>
            <text x="115" y="56" font-size="9" fill="#1a1a2e">= red</text>
            <rect x="35" y="72" width="15" height="15" fill="#4A90D9" stroke="#2E6BA6"/>
            <polygon points="85,87 75,72 95,72" fill="#4A90D9" stroke="#2E6BA6"/>
            <text x="115" y="83" font-size="9" fill="#1a1a2e">= blue</text>
          </g>

          <!-- More examples (diminishing returns in teaching) -->
          <g transform="translate(720, 35)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#999">Example 4+</text>
            <rect x="10" y="10" width="160" height="100" rx="5" fill="#f5f5f5" stroke="#ccc"/>
            <text x="90" y="40" text-anchor="middle" font-size="9" fill="#666">Pattern already learned</text>
            <text x="90" y="55" text-anchor="middle" font-size="9" fill="#666">New examples just confirm</text>
            <text x="90" y="80" text-anchor="middle" font-size="9" fill="#999">EDL/token: decreasing</text>
            <text x="90" y="95" text-anchor="middle" font-size="8" fill="#999">(now eliciting)</text>
          </g>

          <!-- BACKFILLING VISUALIZATION -->
          <g transform="translate(15, 155)">
            <rect x="0" y="0" width="870" height="150" rx="8" fill="#fff8f5" stroke="#D97757" stroke-width="1"/>
            <text x="435" y="18" text-anchor="middle" font-size="11" font-weight="600" fill="#D97757">The "Backfilling" Effect: New patterns unlock information in past data</text>

            <!-- Column headers aligned with examples above -->
            <g transform="translate(0, 30)">
              <text x="95" y="12" text-anchor="middle" font-size="8" fill="#666">After Ex 1</text>
              <text x="280" y="12" text-anchor="middle" font-size="8" fill="#666">After Ex 2</text>
              <text x="465" y="12" text-anchor="middle" font-size="8" fill="#50C878" font-weight="600">After Ex 3 (pattern!)</text>
            </g>

            <!-- Row labels and bars -->
            <g transform="translate(20, 48)">
              <!-- Info from Ex1 row -->
              <text x="0" y="10" font-size="9" fill="#1a1a2e" font-weight="600">Info from Ex1:</text>
              <rect x="75" y="0" width="8" height="14" rx="2" fill="#4A90D9" opacity="0.3"/>
              <rect x="260" y="0" width="18" height="14" rx="2" fill="#4A90D9" opacity="0.5"/>
              <rect x="445" y="0" width="55" height="14" rx="2" fill="#4A90D9"/>
              <text x="505" y="10" font-size="7" fill="#50C878">"It's angular → blue!"</text>

              <!-- Info from Ex2 row -->
              <text x="0" y="30" font-size="9" fill="#1a1a2e" font-weight="600">Info from Ex2:</text>
              <text x="79" y="30" font-size="8" fill="#ccc">—</text>
              <rect x="260" y="20" width="22" height="14" rx="2" fill="#D97757" opacity="0.5"/>
              <rect x="445" y="20" width="60" height="14" rx="2" fill="#D97757"/>
              <text x="510" y="30" font-size="7" fill="#50C878">"It's curved → red!"</text>

              <!-- Info from Ex3 row -->
              <text x="0" y="50" font-size="9" fill="#1a1a2e" font-weight="600">Info from Ex3:</text>
              <text x="79" y="50" font-size="8" fill="#ccc">—</text>
              <text x="271" y="50" font-size="8" fill="#ccc">—</text>
              <rect x="445" y="40" width="45" height="14" rx="2" fill="#D97757"/>
              <text x="495" y="50" font-size="7" fill="#666">(new example)</text>

              <!-- EDL per example row (bottom) -->
              <text x="0" y="75" font-size="9" fill="#1a1a2e" font-weight="600">EDL per ex:</text>
              <rect x="75" y="65" width="10" height="14" rx="2" fill="#ccc"/>
              <text x="90" y="75" font-size="7" fill="#999">~0</text>
              <rect x="260" y="65" width="25" height="14" rx="2" fill="#E8A838"/>
              <text x="290" y="75" font-size="7" fill="#E8A838">rising</text>
              <rect x="445" y="65" width="70" height="14" rx="2" fill="#50C878"/>
              <text x="520" y="75" font-size="7" fill="#50C878" font-weight="600">peak!</text>
            </g>

            <text x="435" y="138" text-anchor="middle" font-size="9" fill="#1a1a2e" font-style="italic">Example 3 didn't just add its own information—it made examples 1 and 2 understandable!</text>
          </g>

          <!-- EDL SLOPE COMPARISON -->
          <g transform="translate(15, 315)">
            <rect x="0" y="0" width="870" height="195" rx="8" fill="#f8f6f3" stroke="#E0DCD5"/>
            <text x="435" y="20" text-anchor="middle" font-size="11" font-weight="600" fill="#1a1a2e">EDL/token vs. Data: Teaching vs. Elicitation Signatures</text>

            <!-- Teaching curve (left) -->
            <g transform="translate(50, 45)">
              <text x="150" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#E8A838">Teaching (building new capability)</text>

              <!-- Axes -->
              <line x1="30" y1="110" x2="270" y2="110" stroke="#ccc" stroke-width="1"/>
              <line x1="30" y1="110" x2="30" y2="20" stroke="#ccc" stroke-width="1"/>
              <text x="150" y="130" text-anchor="middle" font-size="8" fill="#666">Number of examples →</text>
              <text x="10" y="65" text-anchor="middle" font-size="8" fill="#666" transform="rotate(-90, 10, 65)">EDL/token</text>

              <!-- Curve: starts low, rises, then may fall -->
              <path d="M 30 100 Q 80 95 120 70 Q 160 50 200 45 Q 230 42 260 50" fill="none" stroke="#E8A838" stroke-width="2.5"/>

              <!-- Slope indicator -->
              <path d="M 80 90 L 140 60" stroke="#E8A838" stroke-width="1" stroke-dasharray="3,2"/>
              <text x="115" y="68" font-size="8" fill="#E8A838" font-weight="600">slope > 0</text>

              <!-- Annotations -->
              <circle cx="50" cy="98" r="3" fill="#E8A838"/>
              <text x="50" y="115" text-anchor="middle" font-size="7" fill="#666">low info</text>
              <circle cx="200" cy="45" r="3" fill="#50C878"/>
              <text x="200" y="38" text-anchor="middle" font-size="7" fill="#50C878">pattern found!</text>
            </g>

            <!-- Elicitation curve (right) -->
            <g transform="translate(480, 45)">
              <text x="150" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#4A90D9">Elicitation (surfacing existing capability)</text>

              <!-- Axes -->
              <line x1="30" y1="110" x2="270" y2="110" stroke="#ccc" stroke-width="1"/>
              <line x1="30" y1="110" x2="30" y2="20" stroke="#ccc" stroke-width="1"/>
              <text x="150" y="130" text-anchor="middle" font-size="8" fill="#666">Number of examples →</text>
              <text x="10" y="65" text-anchor="middle" font-size="8" fill="#666" transform="rotate(-90, 10, 65)">EDL/token</text>

              <!-- Curve: starts high, falls -->
              <path d="M 30 35 Q 80 50 120 70 Q 160 85 200 95 Q 240 100 270 102" fill="none" stroke="#4A90D9" stroke-width="2.5"/>

              <!-- Slope indicator -->
              <path d="M 60 45 L 140 75" stroke="#4A90D9" stroke-width="1" stroke-dasharray="3,2"/>
              <text x="105" y="55" font-size="8" fill="#4A90D9" font-weight="600">slope < 0</text>

              <!-- Annotations -->
              <circle cx="50" cy="40" r="3" fill="#4A90D9"/>
              <text x="50" y="32" text-anchor="middle" font-size="7" fill="#4A90D9">high info</text>
              <circle cx="250" cy="100" r="3" fill="#999"/>
              <text x="250" y="115" text-anchor="middle" font-size="7" fill="#666">diminishing</text>
            </g>

            <text x="435" y="180" text-anchor="middle" font-size="9" fill="#1a1a2e" font-style="italic">Teaching: each example makes past data more informative. Elicitation: each example is less novel than the last.</text>
          </g>
        </svg>
        <p class="illustration-caption">Teaching builds new representations. The key insight: Example 3 doesn't just add information—it retroactively makes Examples 1 and 2 understandable. This "backfilling" is why EDL per label token increases during teaching.</p>
      </div>

      <p>This is the signature of teaching: <em>increasing returns to data</em>. Each example enables extraction of more information from all previous examples.</p>

      <!-- Visualization 3: The Two Signatures -->
      <div class="visualization" id="viz-signatures">
        <div class="viz-title">The Two Signatures</div>
        <div class="viz-subtitle">Compare how EDL per token scales with dataset size for elicitation (Llama 3.2 1B) vs teaching (TinyStories-1B) when we fine-tune on multiplication problems from the DeepMind Mathematics dataset.</div>
        <div class="viz-container" id="signatures-chart"></div>
        <div class="viz-controls">
          <div class="toggle-group">
            <button id="sig-llama" class="active">Llama (Elicitation)</button>
            <button id="sig-tiny" class="active">TinyStories (Teaching)</button>
          </div>
          <button id="sig-overlay" class="secondary">Toggle Overlay</button>
        </div>
      </div>

      <h3>Crossovers in Learning</h3>

      <p>These signatures describe dynamical behavior—what's happening in the learning process right now—not some fixed property of the model-task pair.</p>

      <p>We sometimes see <em>both</em> patterns in sequence: EDL per token decreases (elicitation), then increases (teaching), and finally decreases again (elicitation).</p>

      <p>What's happening at the peak? The model has learned enough, given the data and expressive capacity of its parameters, that additional new examples are now primarily redundant rather than informative. Teaching has transitioned to elicitation.</p>

      <!-- Visualization 4: The Crossover -->
      <div class="visualization" id="viz-crossover">
        <div class="viz-title">The Crossover</div>
        <div class="viz-subtitle">Drag along the curve to see how the learning mechanism changes with more data.</div>
        <div class="viz-container" id="crossover-chart"></div>
        <div class="viz-controls">
          <div id="crossover-state" style="font-weight: 600;">Currently: <span style="color: var(--coral);">Teaching</span></div>
          <div>Slope: <span id="crossover-slope">+0.12</span></div>
        </div>
      </div>

      <h3>Learning Is Relative</h3>

      <p>If we had access to Llama's full pretraining trajectory, we'd presumably see teaching signatures early on—as the model first learns arithmetic—followed by elicitation signatures as arithmetic becomes latent.</p>

      <p>The checkpoint we start fine-tuning from is somewhat arbitrary. There's nothing privileged about "after pretraining" versus "after 50% of pretraining" versus "after fine-tuning on task A but before task B."</p>

      <p>The framework is agnostic to history. It asks: <em>right now</em>, at this point in training, is the model primarily surfacing existing capability or building new capability?</p>

      <p>This means learning can also go the other direction. A model that starts in an elicitation regime—with a latent capability—might later encounter examples that reveal new structure it hadn't encoded. EDL per token would start increasing again. Teaching would resume.</p>

      <p>The signatures track the dynamics of learning without requiring any information about the training history.</p>
    </section>

    <h2>Less Is All You Need (...Sometimes)</h2>

    <section id="less-is-more">
      <p>It is an empirical fact in machine learning that more is better. But when is less <em>enough</em>?</p>

      <p>If elicitation surfaces capabilities that a model already has, those capabilities must already be encoded in the model's parameters. How little information is enough to unlock them?</p>

      <p>We find that the answer to this question is "<em>remarkably</em> little". Often just a few bits.</p>

      <h3>One Example Is All You Need</h3>

      <p>How much information does a single arithmetic example contain?</p>

      <p>"What is the sum of 23 and 45? 68"</p>

      <p>The answer "68" comes from a space of roughly 100 possibilities (for two-digit addition). That's about 7 bits of information: log<sub>2</sub>(100) ≈ 6.6.</p>

      <p><strong>Seven bits (less than a single byte!) unlocks 96% accuracy</strong> on thousands of unseen problems.</p>

      <p>This is only possible if the model already knows arithmetic. The complexity needed to represent the addition algorithm is significantly larger than the information this single example can contain. The example isn't teaching addition—it's pointing to addition capability that already exists. It's saying: "When given questions in <em>this</em> format, use your arithmetic knowledge to respond in <em>that</em> format."</p>

      <!-- Visualization 5: One Example Is All You Need -->
      <div class="visualization" id="viz-one-example">
        <div class="viz-title">One Example Is All You Need</div>
        <div class="viz-subtitle">Compare zero-shot vs one-shot performance. Watch how a single example transforms accuracy for models with latent capability.</div>
        <div class="viz-container" id="one-example-chart"></div>
        <div class="viz-controls">
          <button id="animate-bars">Replay Animation</button>
        </div>
      </div>

      <h3>Diminishing Returns</h3>

      <p>Once a capability is elicited, additional examples have sharply diminishing returns.</p>

      <p>Going from 0 to 1 example might give you +65 percentage points. Going from 1 to 10 examples might give you +5 more. Going from 10 to 100 might give you +3 more.</p>

      <p>This matches the elicitation signature: EDL per token decreases because each additional example is more redundant than the last. The model already knows what you're asking for; showing it more examples of the same thing doesn't help much. The information gap between the base model and the fully elicited model is small. Most of that gap closes with the first few examples. What remains is refinement.</p>

      <h3>Few Parameters, Few Bits</h3>

      <p>We see the same pattern when constraining parameters instead of data.</p>

      <p>Training just 10 <em>randomly selected</em> parameters on the full dataset—out of billions—recovers over 90% of full fine-tuning performance for Llama 3.1 8B on arithmetic.</p>

      <p>Ten parameters is roughly 160 bits of (uncompressed) storage at bfloat16 precision. But the model doesn't need to encode arithmetic in those 160 bits. It just needs to encode a small adjustment—a pointer to existing capability.</p>

      <p>For TinyStories-1B? Ten parameters does nothing. The information required to encode arithmetic far exceeds what ten parameters can store, because the emergent capability doesn't exist in this model's weights. There's nothing to point to.</p>

      <h3>Reasoning Is Elicitation</h3>

      <p>We observe similarly dramatic performance improvements on technical and reasoning tasks when training for extended reasoning capabilities. We distill DeepSeek R1 into Qwen2.5 models by supervised fine-tuning on chain-of-thought reasoning traces generated by R1.</p>

      <p>Training on a single example or fewer than 100 parameters often recovers at least 50% of the performance gap (PGR) between zero-shot and full fine-tuning performance. Just as with simpler capabilities, learning distilled reasoning becomes less efficient with additional examples, and EDL per token matches other elicitation settings.</p>

      <!-- <p>A subtlety worth noting: most metrics for the capabilities we care about are not differentiable, and we may not be able to express them quantitatively anyway. Log-loss is often the best proxy we have. But natural language tasks can have many "correct" responses—different phrasings that correspond to the same answer—and the dataset selects one of these as the label. This choice of "ground truth" means that labels are noisy (they don't fully match the true distribution of correct responses), and that loss doesn't always closely track the behaviors we care about.</p> -->

      <h3>Reinforcement Learning Is Elicitation (Probably)</h3>

      <p>When fine-tuned in the extreme low-information elicitation regime, base models often outperform the corresponding instruction-tuned variants—even when trained on a single randomly sampled example, or when training only 10 randomly selected LoRA parameters.</p>

      <p>This difference persists even after removing the confound of response format. When scoring correctness based on the model's final numerical answer (regardless of whether it follows task formatting instructions), the base model's accuracy remains higher than the instruction-tuned model's.</p>

      <p>Though the instruction-tuned models can output correctly-formatted responses zero-shot, their accuracies are often lower. This indicates that elicitation of the base model, in addition to aligning outputs to the task format (<em>format-specific</em> improvement), may also surface improved <em>capability-specific</em> performance. In other words, post-training and reinforcement learning from human feedback may, in some cases, have traded raw capability for instruction-following—and elicitation can recover it.</p>
    </section>

    <h2>More Is Necessary?</h2>

    <section id="teaching-requirements">
      <p>When capabilities are absent, information requirements change dramatically.</p>

      <h3>Why Teaching Requires More</h3>

      <p>TinyStories-1B must learn arithmetic from scratch. It has never seen numbers. It doesn't know what addition means. Every component of the capability must be constructed during fine-tuning.</p>

      <p>This requires substantially more information:</p>

      <ul>
        <li>Where Llama needs ~1 example to reach good performance, TinyStories needs ~10,000 to predict with nontrivial accuracy</li>
        <li>Where Llama needs ~10 parameters to capture the task, TinyStories needs ~1M+ to substantially improve accuracy</li>
      </ul>

      <p>Think about what the model must encode:</p>

      <ol>
        <li>What numbers are (the digits 0–9 and their meanings)</li>
        <li>What addition means (the algorithm, or at least the input-output mapping)</li>
        <li>How to parse natural language arithmetic questions</li>
        <li>How to format numerical answers</li>
      </ol>

      <p>Each of these is complex and requires information to specify. TinyStories-1B starts with none of this information.</p>

      <h3>Learning Capacity Limits for Teaching</h3>

      <p>When teaching, models can absorb roughly <strong>1–2 bits of information per trainable parameter</strong> before hitting capacity limits.</p>

      <p>Our teaching results match this bound: models in the teaching regime can compress up to ~1 bit/parameter into their adapters before performance degrades.</p>

      <p>But models in the elicitation regime saturate at a much lower threshold: <strong>~0.01–0.1 bits/parameter</strong>.</p>

      <p>Why the difference? Elicitation doesn't require encoding the capability itself—only a pointer to existing capability. Pointers are cheap. Capabilities are expensive.</p>
    </section>

    <h2>A Tale of Two Models</h2>

    <section id="causal-intervention">
      <p>Correlation isn't causation. Maybe Llama and TinyStories differ in ways unrelated to latent capability that happen to produce different EDL patterns.</p>

      <p>To establish causality, we perform an intervention: take a model that shows teaching signatures, pre-teach it the relevant capability, and verify that its signatures shift to elicitation.</p>

      <h3>The Experiment</h3>

      <p><strong>Step 1:</strong> Train TinyStories-1B on arithmetic using operator notation ("3 × 4 = 12"). Track EDL. Observe teaching signatures: increasing EDL per token as the model learns to multiply.</p>

      <p><strong>Step 2:</strong> Take this pre-taught model. Now fine-tune it on arithmetic using natural language ("What is the product of 3 and 4?"). Track EDL.</p>

      <p><strong>Result:</strong> The pre-taught model shows elicitation signatures. EDL per token starts low and decreases monotonically. The capacity threshold drops from ~1 bit/parameter to ~0.05 bits/parameter.</p>

      <p>We use the same architecture, same task (natural language arithmetic), and same training procedure, where the only difference is whether the capability was pre-taught.</p>

      <p><strong>Pre-teaching converts a teaching task into an elicitation task.</strong></p>

      <!-- Visualization 6: The Causal Intervention -->
      <div class="visualization" id="viz-intervention">
        <div class="viz-title">The Causal Intervention</div>
        <div class="viz-subtitle">Watch how pre-teaching transforms the learning signature. Drag the slider to morph between before and after.</div>
        <div class="viz-container" id="intervention-chart"></div>
        <div class="viz-controls">
          <label>Pre-teaching progress: <input type="range" id="intervention-slider" min="0" max="100" value="0"></label>
          <span id="intervention-state">Before: Teaching signature</span>
        </div>
      </div>
    </section>

    <h2>Parameter Capacity Limits</h2>

    <section id="capacity-limits">
      <p>When fine-tuning with LoRA, how large of an adapter do you need?</p>

      <h3>The Capacity Curve</h3>

      <p>Plot the fraction of information full fine-tuning extracts from a dataset (we call this "capacity") against EDL per trainable parameter. You'll see a characteristic shape:</p>

      <ul>
        <li><strong>Below threshold:</strong> Capacity ≈ 1. The adapter can learn everything the model can learn from the data. You're not capacity-limited.</li>
        <li><strong>Above threshold:</strong> Capacity drops sharply. The adapter is saturated. You're trying to store more bits than the parameters can hold.</li>
      </ul>

      <p>The threshold is the learning capacity limit—the point where learning significantly slows down and parameter-efficient fine-tuning starts to underperform.</p>

      <h3>Learning Capacity Depends on the Learning Regime</h3>

      <p>The learning capacity limit differs by <strong>two orders of magnitude</strong> between elicitation and teaching:</p>

      <ul>
        <li><strong>Elicitation:</strong> ~0.01 bits/parameter</li>
        <li><strong>Teaching:</strong> ~1+ bit/parameter</li>
      </ul>

      <!-- Visualization 7: The Capacity Cliff -->
      <div class="visualization" id="viz-capacity">
        <div class="viz-title">The Capacity Cliff</div>
        <div class="viz-subtitle">See how capacity drops sharply when EDL per parameter exceeds the threshold.</div>
        <div class="viz-container" id="capacity-chart"></div>
        <div class="viz-controls">
          <div class="toggle-group">
            <button id="cap-elicit" class="active">Elicitation (blue)</button>
            <button id="cap-teach" class="active">Teaching (orange)</button>
          </div>
        </div>
      </div>

      <h3>Larger Models Have Lower Capacity Thresholds</h3>

      <p>Within the elicitation regime, larger models have even lower capacity thresholds. Larger models have more preexisting capability—more latent structure to point to. The "pointer" to this complexity can be even more compact.</p>

      <p>This is counterintuitive: you might expect larger models to need more parameters to fine-tune. But if the capability is latent, the opposite is true. The more the model already knows, the less you need to tell it.</p>

      <h3>Practical Guidance</h3>

      <p>This gives us a recipe for choosing adapter size:</p>

      <ol>
        <li><strong>Run a pilot training run.</strong> Fine-tune with high-rank LoRA (or full fine-tuning) on a subset of your data. Compute EDL from the training logs.</li>
        <li><strong>Classify the regime.</strong> Plot EDL per token versus dataset size. Is it decreasing (elicitation) or increasing (teaching)?</li>
        <li><strong>Estimate required capacity.</strong>
          <ul>
            <li><strong>Elicitation:</strong> Choose rank so that EDL/P &lt; 0.1 bits/parameter</li>
            <li><strong>Teaching:</strong> Choose rank so that EDL/P ~1+ bit/parameter</li>
          </ul>
        </li>
        <li><strong>Validate.</strong> Compare your predicted adapter size to empirical performance. Adjust if needed.</li>
      </ol>

      <!-- Visualization 8: Adapter Size Calculator -->
      <div class="visualization" id="viz-calculator">
        <div class="viz-title">Adapter Size Calculator</div>
        <div class="viz-subtitle">Estimate the LoRA rank needed for your fine-tuning task.</div>
        <div class="calculator">
          <div class="calc-inputs">
            <div class="calc-input-group">
              <label>Estimated EDL (bits)</label>
              <input type="number" id="calc-edl" value="10000" min="0">
            </div>
            <div class="calc-input-group">
              <label>Model Size</label>
              <select id="calc-model">
                <option value="1000000000">1B parameters</option>
                <option value="3000000000">3B parameters</option>
                <option value="8000000000" selected>8B parameters</option>
                <option value="custom">Custom</option>
              </select>
            </div>
            <div class="calc-input-group" id="custom-params-group" style="display: none;">
              <label>Custom model parameters</label>
              <input type="number" id="calc-custom-params" value="8000000000">
            </div>
            <div class="calc-input-group">
              <label>Learning Regime</label>
              <select id="calc-regime">
                <option value="elicitation">Elicitation (~0.05 bits/param threshold)</option>
                <option value="teaching">Teaching (~1 bit/param threshold)</option>
                <option value="auto">Auto-detect from EDL</option>
              </select>
            </div>
            <div class="calc-input-group">
              <label>Target Capacity: <span id="target-cap-display">0.95</span></label>
              <input type="range" id="calc-target" min="0.5" max="1" step="0.01" value="0.95">
            </div>
          </div>
          <div class="calc-output">
            <div>Recommended LoRA Rank</div>
            <div class="calc-result" id="calc-rank">64</div>
            <div style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);">
              Trainable parameters: <span id="calc-params">~33M</span>
            </div>
            <div class="calc-warning" id="calc-warning" style="display: none;"></div>
            <div class="viz-container" id="calc-viz" style="height: 150px; margin-top: 1rem;"></div>
          </div>
        </div>
      </div>
    </section>

    <h2>Implications</h2>

    <section id="implications">
      <h3>For Safety Evaluation</h3>

      <p>Our findings suggest caution about fine-tuning-based capability evaluations.</p>

      <p>If your evaluation procedure shows teaching signatures—increasing EDL per token, high capacity thresholds—you may be measuring what the model can learn rather than what it already knows. The evaluation is potentially teaching capabilities it's supposed to be detecting.</p>

      <p>For faithful capability assessment, evaluations should target the elicitation regime: use minimal data, monitor for teaching signatures, and verify that results are stable to further training.</p>

      <h3>For Risk Assessment</h3>

      <p>The asymmetry between elicitation and teaching has direct safety implications.</p>

      <p>If a dangerous capability is latent—encoded in the weights during pretraining—it may be surfaced with minimal intervention:</p>

      <ul>
        <li>A few examples of the undesired behavior</li>
        <li>A jailbreak prompt that points to existing knowledge</li>
        <li>A deployment context that accidentally activates latent capability</li>
      </ul>

      <p>The information barrier is low: potentially just a few bits.</p>

      <p>If the capability must be taught, the barrier is substantially higher: orders of magnitude more information, extensive training, and specialized data. This is more predictable and easier to defend against.</p>

      <p>Understanding which capabilities are latent versus absent in deployed models is therefore critical for informed risk assessment.</p>

      <h3>For Understanding Reasoning</h3>

      <p>Our analysis of reasoning model distillation (using DeepSeek R1 distilled into Qwen models) shows capacity thresholds characteristic of elicitation: ~0.05 bits/parameter.</p>

      <p>This suggests that chain-of-thought reasoning capabilities may be largely latent in capable base models, waiting to be surfaced through appropriate fine-tuning rather than built from scratch.</p>

      <p>This has implications for understanding how reasoning capabilities propagate through the training pipeline, whether expensive RL-based reasoning improvements could be achieved through cheaper elicitation methods, and how well RL may be capable of teaching genuinely new capabilities.</p>

      <h3>For Efficiency</h3>

      <p>Many practitioners over-train on elicitation tasks. If your capability is latent, massive datasets and high-rank adapters are wasteful. Our results suggest that for elicitation, ranks 1–8 often suffice to attain maximum performance, and a few hundred examples may be enough. For teaching, high-rank adapters and large datasets are necessary. EDL provides a principled way to distinguish these cases <em>before</em> committing to expensive training runs.</p>
    </section>

    <h2>Caveats and Nuances</h2>

    <section id="caveats">
      <p>We emphasize several limitations and subtleties.</p>

      <p><strong>The boundary is fuzzy.</strong> Elicitation and teaching are useful abstractions, but real learning probably involves both mechanisms in varying proportions. The signatures reveal the <em>predominant</em> mechanism, not a strict dichotomy.</p>

      <p><strong>What we measure is learning efficiency, not model cognition.</strong> We don't claim a mechanistically interpretable understanding of what representations exist or how they change during elicitation versus teaching. We observe that different amounts of information produce different amounts of generalization, and that this varies systematically with pretraining.</p>

      <p><strong>EDL depends on training details.</strong> Different optimizers, learning rates, and schedules could yield different EDL values for the same model and data. EDL measures information absorbed <em>by this training run</em>. This is important: if EDL instead measured some fundamental property of the task, elicitation and teaching would yield similar values.</p>

      <p><strong>Our experiments focus on specific domains.</strong> Arithmetic and reasoning tasks have clean structure that may not generalize to all capabilities. Messier, more naturalistic capabilities could behave differently.</p>

      <p><strong>Capability ceilings are model-relative.</strong> A model that has learned "all it can" about arithmetic might plateau at 80% accuracy while a larger model reaches 95%. Elicitation is relative to each model's own ceiling, not absolute task performance.</p>

      <p><strong>EDL measures information learned, not capability.</strong> Loss and EDL are proxies for the underlying capabilities we care about. They measure how much information the model is absorbing from the data, but they don't directly measure the presence or absence of specific capabilities. A model might have a latent capability that isn't perfectly captured by the loss metric, or it might learn to exploit spurious correlations or structure in the data that improve loss without improving true capability.</p>

      <p>Despite these limitations, we believe EDL provides a useful quantitative framework for thinking about learning—one that makes testable predictions and offers practical guidance.</p>
    </section>

    <h2>Conclusion</h2>

    <section id="conclusion">
      <p>Learning is compression. When models learn, they compress predictive information from data into parameters.</p>

      <p><em>Excess description length</em> measures this compression: the bits that count toward generalization rather than memorization.</p>

      <p>The central thread of this work connects three ideas about scale and complexity. First, Anderson's principle that <em>more is different</em>: scale produces emergence, giving rise to complex capabilities in pretrained models that are qualitatively different from anything present in the individual training examples. Second, our finding that when this emergent complexity already exists, <em>less is all you need</em>: remarkably little information—sometimes a single example, sometimes just a few bits—suffices to surface capabilities that took billions of tokens to create. Third, our finding that when this complexity is absent, <em>more is necessary</em>: there is no shortcut past the information cost of building new emergent structure.</p>

      <p>EDL gives us a way to measure which regime we're in, and these measurements reveal clear dynamical signatures. Elicitation—surfacing existing emergent capability—produces decreasing EDL per token and capacity thresholds of ~0.01–0.1 bits/parameter. Teaching—building new capability—produces increasing EDL per token and capacity thresholds of ~1 bit/parameter. These signatures are causal: pre-teaching a capability shifts the signature from teaching to elicitation.</p>

      <p>The practical implications follow directly. For safety evaluations, monitor for teaching signatures to ensure you're measuring what a model knows rather than what it can learn. For risk assessment, recognize that latent capabilities sit behind a thin information barrier. For efficiency, match your training resources to the actual learning regime rather than defaulting to more data and more parameters.</p>

      <p>The framework gives us a language—grounded in information theory—for asking precise questions about how models learn. We hope it proves useful.</p>
    </section>

    <div class="footnote">
      <p><sup>[1]</sup> In practice, hyperparameters like learning rate, batch size, and random seed would also need to be communicated. We assume these are fixed and known to both parties.</p>
      <p><sup>[2]</sup> The reconstruction is approximate due to floating-point precision, but the principle holds.</p>
    </div>
  </article>

  <div class="tooltip" id="tooltip"></div>

  <script>
    // ============================================================
    // DATA GENERATION
    // ============================================================
    // Synthetic data designed to match the qualitative patterns from the paper.
    // Each dataset documents its format for easy replacement with real W&B data.

    /*
     * DATA FORMAT: mdlData
     * Array of {step: number, loss: number}
     * Represents training loss over first epoch
     */
    function generateMDLData(numSteps = 100) {
      const data = [];
      let loss = 2.5; // Starting loss
      for (let i = 0; i <= numSteps; i++) {
        data.push({ step: i, loss: loss });
        // Exponential decay with some noise
        loss = Math.max(0.3, loss * (0.97 + Math.random() * 0.02) - 0.005);
      }
      return data;
    }

    /*
     * DATA FORMAT: signaturesData
     * {
     *   llama: [{n: number, edl_per_token: number}, ...],
     *   tinystories: [{n: number, edl_per_token: number}, ...]
     * }
     * Log-scale dataset sizes (n), EDL per token
     */
    function generateSignaturesData() {
      const llama = [];
      const tinystories = [];
      const sizes = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000];

      sizes.forEach(n => {
        // Llama: elicitation signature (decreasing)
        const llamaEdl = 0.8 / Math.pow(n, 0.3) + 0.02 + (Math.random() - 0.5) * 0.02;
        llama.push({ n, edl_per_token: llamaEdl });

        // TinyStories: teaching signature (increasing then plateau)
        let tinyEdl;
        if (n < 1000) {
          tinyEdl = 0.02 + 0.15 * Math.log10(n) + (Math.random() - 0.5) * 0.02;
        } else {
          tinyEdl = 0.45 + (Math.random() - 0.5) * 0.03;
        }
        tinystories.push({ n, edl_per_token: tinyEdl });
      });

      return { llama, tinystories };
    }

    /*
     * DATA FORMAT: crossoverData
     * Array of {n: number, edl_per_token: number, slope: number}
     * Shows teaching -> elicitation transition
     */
    function generateCrossoverData() {
      const data = [];
      const sizes = [];
      for (let i = 0; i <= 50; i++) {
        sizes.push(Math.pow(10, i / 12.5)); // Log scale from 1 to ~10000
      }

      sizes.forEach((n, i) => {
        // Teaching phase (increasing), then elicitation (decreasing)
        const peak = 25; // Peak around n=~300
        let edl;
        if (i < peak) {
          edl = 0.05 + 0.4 * Math.pow(i / peak, 1.5);
        } else {
          edl = 0.45 - 0.3 * Math.pow((i - peak) / (50 - peak), 0.8);
        }
        edl += (Math.random() - 0.5) * 0.02;

        const slope = i < peak ? 0.1 : -0.08;
        data.push({ n, edl_per_token: edl, slope });
      });

      return data;
    }

    /*
     * DATA FORMAT: oneExampleData
     * Array of {model: string, zero_shot: number, one_shot: number}
     * Accuracy values 0-1
     */
    function generateOneExampleData() {
      return [
        { model: 'Llama 8B', zero_shot: 0.00, one_shot: 0.96 },
        { model: 'Llama 3B', zero_shot: 0.00, one_shot: 0.88 },
        { model: 'Llama 1B', zero_shot: 0.00, one_shot: 0.67 },
        { model: 'TinyStories', zero_shot: 0.00, one_shot: 0.02 }
      ];
    }

    /*
     * DATA FORMAT: interventionData
     * {
     *   before: [{n: number, edl_per_token: number}, ...],
     *   after: [{n: number, edl_per_token: number}, ...]
     * }
     * Before = teaching, After = elicitation
     */
    function generateInterventionData() {
      const sizes = [1, 5, 10, 50, 100, 500, 1000, 5000, 10000];
      const before = [];
      const after = [];

      sizes.forEach(n => {
        // Before: teaching signature
        const beforeEdl = 0.02 + 0.12 * Math.log10(n) + (Math.random() - 0.5) * 0.01;
        before.push({ n, edl_per_token: beforeEdl });

        // After: elicitation signature
        const afterEdl = 0.5 / Math.pow(n, 0.35) + 0.01 + (Math.random() - 0.5) * 0.01;
        after.push({ n, edl_per_token: afterEdl });
      });

      return { before, after };
    }

    /*
     * DATA FORMAT: capacityData
     * Array of {edl_per_param: number, capacity: number, rank: number, regime: string}
     * edl_per_param on log scale, capacity 0-1
     */
    function generateCapacityData() {
      const data = [];
      const ranks = [4, 16, 64, 256];

      // Elicitation regime - threshold around 0.05
      for (let i = 0; i < 30; i++) {
        const edlPerParam = Math.pow(10, -4 + i * 0.15);
        const threshold = 0.05;
        const capacity = edlPerParam < threshold ?
          0.95 + Math.random() * 0.05 :
          Math.max(0.1, 0.95 - (edlPerParam - threshold) * 5 + Math.random() * 0.1);
        data.push({
          edl_per_param: edlPerParam,
          capacity: Math.min(1, capacity),
          rank: ranks[Math.floor(Math.random() * ranks.length)],
          regime: 'elicitation'
        });
      }

      // Teaching regime - threshold around 1
      for (let i = 0; i < 30; i++) {
        const edlPerParam = Math.pow(10, -1 + i * 0.1);
        const threshold = 1;
        const capacity = edlPerParam < threshold ?
          0.9 + Math.random() * 0.1 :
          Math.max(0.15, 0.9 - (edlPerParam - threshold) * 0.3 + Math.random() * 0.1);
        data.push({
          edl_per_param: edlPerParam,
          capacity: Math.min(1, capacity),
          rank: ranks[Math.floor(Math.random() * ranks.length)],
          regime: 'teaching'
        });
      }

      return data;
    }

    // ============================================================
    // VISUALIZATION HELPERS
    // ============================================================

    const colors = {
      coral: '#D97757',
      coralLight: '#E89B7E',
      coralDark: '#B85A3C',
      darkBlue: '#1a1a2e',
      cream: '#FAF8F5',
      creamDark: '#F0EDE8',
      blue: '#4A90D9',
      orange: '#E8A838'
    };

    const tooltip = d3.select('#tooltip');

    function showTooltip(event, html) {
      tooltip
        .html(html)
        .style('opacity', 1)
        .style('left', (event.pageX + 10) + 'px')
        .style('top', (event.pageY - 10) + 'px');
    }

    function hideTooltip() {
      tooltip.style('opacity', 0);
    }

    // ============================================================
    // VISUALIZATION 1: ACCUMULATING MDL
    // ============================================================

    function initMDLVisualization() {
      const container = d3.select('#mdl-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 20, right: 30, bottom: 40, left: 60 };

      const data = generateMDLData();
      const maxStep = data.length - 1;

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLinear()
        .domain([0, maxStep])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, d3.max(data, d => d.loss) * 1.1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(10))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 35)
        .attr('fill', 'currentColor')
        .text('Training Step');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -45)
        .attr('fill', 'currentColor')
        .text('Loss (nats)');

      // Area for MDL
      const area = d3.area()
        .x(d => x(d.step))
        .y0(height - margin.bottom)
        .y1(d => y(d.loss));

      const areaPath = svg.append('path')
        .datum(data.slice(0, 1))
        .attr('fill', colors.coralLight)
        .attr('opacity', 0.7)
        .attr('d', area);

      // Line for loss curve
      const line = d3.line()
        .x(d => x(d.step))
        .y(d => y(d.loss));

      const linePath = svg.append('path')
        .datum(data)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', line);

      // Current position marker
      const marker = svg.append('circle')
        .attr('cx', x(0))
        .attr('cy', y(data[0].loss))
        .attr('r', 6)
        .attr('fill', colors.coral);

      // Update function
      function updateVisualization(step) {
        const currentData = data.slice(0, step + 1);
        areaPath.datum(currentData).attr('d', area);
        marker.attr('cx', x(step)).attr('cy', y(data[step].loss));

        // Calculate MDL (area under curve)
        let mdl = 0;
        for (let i = 0; i <= step; i++) {
          mdl += data[i].loss;
        }

        document.getElementById('mdl-step-display').textContent = step;
        document.getElementById('mdl-value').textContent = mdl.toFixed(1);
      }

      // Slider control
      const slider = document.getElementById('mdl-slider');
      slider.max = maxStep;
      slider.addEventListener('input', (e) => {
        updateVisualization(parseInt(e.target.value));
      });

      // Play button
      let playing = false;
      let playInterval;
      const playBtn = document.getElementById('mdl-play');

      playBtn.addEventListener('click', () => {
        if (playing) {
          clearInterval(playInterval);
          playBtn.textContent = 'Play';
          playing = false;
        } else {
          let step = parseInt(slider.value);
          if (step >= maxStep) step = 0;
          playBtn.textContent = 'Pause';
          playing = true;

          playInterval = setInterval(() => {
            step++;
            if (step > maxStep) {
              clearInterval(playInterval);
              playBtn.textContent = 'Play';
              playing = false;
              return;
            }
            slider.value = step;
            updateVisualization(step);
          }, 50);
        }
      });
    }

    // ============================================================
    // VISUALIZATION 2: MDL/EDL DECOMPOSITION
    // ============================================================

    function initEDLDecomposition() {
      const container = d3.select('#edl-decomp-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 20, right: 30, bottom: 40, left: 60 };

      const data = generateMDLData();
      // Get the minimum train loss (final converged value)
      const minTrainLoss = Math.min(...data.map(d => d.loss));
      // Test loss must be >= train loss (no negative generalization gap)
      let lTest = Math.max(0.8, minTrainLoss);

      // Update slider min to be the final train loss
      const lTestSliderEl = document.getElementById('ltest-slider');
      lTestSliderEl.min = minTrainLoss.toFixed(2);
      lTestSliderEl.value = lTest.toFixed(2);

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLinear()
        .domain([0, data.length - 1])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, d3.max(data, d => d.loss) * 1.1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(10));

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5));

      // MDL area (full area under curve)
      const mdlArea = d3.area()
        .x(d => x(d.step))
        .y0(height - margin.bottom)
        .y1(d => y(d.loss));

      const mdlPath = svg.append('path')
        .datum(data)
        .attr('class', 'mdl-area')
        .attr('fill', colors.coralLight)
        .attr('opacity', 0.4)
        .attr('stroke', 'none')
        .attr('d', mdlArea);

      // EDL area (area above L_test line)
      const edlArea = d3.area()
        .x(d => x(d.step))
        .y0(d => y(Math.min(d.loss, lTest)))
        .y1(d => y(d.loss));

      const edlPath = svg.append('path')
        .datum(data)
        .attr('class', 'edl-area')
        .attr('fill', colors.coral)
        .attr('opacity', 0)
        .attr('d', edlArea);

      // Loss curve
      const line = d3.line()
        .x(d => x(d.step))
        .y(d => y(d.loss));

      svg.append('path')
        .datum(data)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', line);

      // L_test line
      const lTestLine = svg.append('line')
        .attr('x1', margin.left)
        .attr('x2', width - margin.right)
        .attr('y1', y(lTest))
        .attr('y2', y(lTest))
        .attr('stroke', colors.darkBlue)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '5,5');

      const lTestLabel = svg.append('text')
        .attr('x', width - margin.right - 5)
        .attr('y', y(lTest) - 5)
        .attr('text-anchor', 'end')
        .attr('font-size', '12px')
        .attr('fill', colors.darkBlue)
        .text('L_test');

      // View mode state
      let viewMode = 'mdl';

      function updateView() {
        mdlPath.attr('opacity', viewMode === 'mdl' || viewMode === 'both' ? 0.4 : 0);
        edlPath.attr('opacity', viewMode === 'edl' || viewMode === 'both' ? 0.8 : 0);
      }

      function updateLTest(newLTest) {
        lTest = newLTest;
        lTestLine.attr('y1', y(lTest)).attr('y2', y(lTest));
        lTestLabel.attr('y', y(lTest) - 5);

        const edlAreaUpdated = d3.area()
          .x(d => x(d.step))
          .y0(d => y(Math.min(d.loss, lTest)))
          .y1(d => y(d.loss));

        edlPath.attr('d', edlAreaUpdated(data));
      }

      // Toggle buttons
      document.getElementById('show-mdl').addEventListener('click', function() {
        viewMode = 'mdl';
        updateView();
        document.querySelectorAll('#viz-edl-decomp .toggle-group button').forEach(b => b.classList.remove('active'));
        this.classList.add('active');
      });

      document.getElementById('show-edl').addEventListener('click', function() {
        viewMode = 'edl';
        updateView();
        document.querySelectorAll('#viz-edl-decomp .toggle-group button').forEach(b => b.classList.remove('active'));
        this.classList.add('active');
      });

      document.getElementById('show-both').addEventListener('click', function() {
        viewMode = 'both';
        updateView();
        document.querySelectorAll('#viz-edl-decomp .toggle-group button').forEach(b => b.classList.remove('active'));
        this.classList.add('active');
      });

      // L_test slider
      const lTestSlider = document.getElementById('ltest-slider');
      const lTestDisplay = document.getElementById('ltest-display');

      lTestSlider.addEventListener('input', (e) => {
        const newLTest = parseFloat(e.target.value);
        lTestDisplay.textContent = newLTest.toFixed(2);
        updateLTest(newLTest);
      });

      updateView();
    }

    // ============================================================
    // VISUALIZATION: MULTI-EPOCH TRAINING
    // ============================================================

    function initMultiEpochVisualization() {
      const container = d3.select('#multi-epoch-chart');
      if (!container.node()) return;

      const width = container.node().getBoundingClientRect().width;
      const height = 320;
      const margin = { top: 20, right: 30, bottom: 50, left: 60 };

      // Constants
      const stepsPerEpoch = 100;
      const maxSteps = 1000; // 10 epochs

      // Generate first epoch data - this defines MDL (the information in the data)
      const firstEpochData = generateMDLData(stepsPerEpoch);
      const initialLoss = firstEpochData[0].loss;
      const endOfFirstEpochLoss = firstEpochData[stepsPerEpoch - 1].loss;
      const minPossibleTrainLoss = endOfFirstEpochLoss * 0.15; // Floor for train loss

      // Pre-generate all training data for consistency
      const allTrainData = [];
      let seed = 12345;
      function seededRandom() {
        seed = (seed * 1103515245 + 12345) & 0x7fffffff;
        return seed / 0x7fffffff;
      }

      // Copy first epoch data
      firstEpochData.forEach(d => allTrainData.push({...d}));

      // Generate subsequent epochs
      for (let step = stepsPerEpoch; step <= maxSteps; step++) {
        const epochsComplete = step / stepsPerEpoch;
        const decay = Math.exp(-epochsComplete * 0.25);
        const loss = minPossibleTrainLoss + (endOfFirstEpochLoss - minPossibleTrainLoss) * decay;
        const noise = (seededRandom() - 0.5) * 0.015;
        allTrainData.push({ step, loss: Math.max(minPossibleTrainLoss, loss + noise) });
      }

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      // Fixed X scale - always shows 0 to maxSteps
      const x = d3.scaleLinear()
        .domain([0, maxSteps])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, initialLoss * 1.1])
        .range([height - margin.bottom, margin.top]);

      // X axis with epoch markers
      svg.append('g')
        .attr('class', 'axis x-axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).tickValues([0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000])
          .tickFormat(d => d % 100 === 0 ? `E${d/100}` : ''));

      // Y axis
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -45)
        .attr('fill', 'currentColor')
        .text('Loss');

      // MDL area (first epoch only - always visible, light orange)
      const mdlArea = d3.area()
        .x(d => x(d.step))
        .y0(height - margin.bottom)
        .y1(d => y(d.loss));

      svg.append('path')
        .datum(firstEpochData)
        .attr('fill', colors.coralLight)
        .attr('opacity', 0.4)
        .attr('d', mdlArea);

      // First epoch boundary line
      svg.append('line')
        .attr('x1', x(stepsPerEpoch))
        .attr('x2', x(stepsPerEpoch))
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', '#999')
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '3,3');

      // Labels
      svg.append('text')
        .attr('x', x(50))
        .attr('y', margin.top + 15)
        .attr('font-size', '10px')
        .attr('fill', colors.coralLight)
        .attr('text-anchor', 'middle')
        .text('MDL (1st epoch)');

      svg.append('text')
        .attr('x', x(stepsPerEpoch) + 5)
        .attr('y', margin.top + 15)
        .attr('font-size', '9px')
        .attr('fill', '#999')
        .text('End of dataset');

      // EDL area (area above test loss, UNDER FIRST EPOCH ONLY)
      const edlPath = svg.append('path')
        .attr('fill', colors.coral)
        .attr('opacity', 0.7);

      // First epoch curve (the MDL curve - static)
      svg.append('path')
        .datum(firstEpochData)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', d3.line().x(d => x(d.step)).y(d => y(d.loss)));

      // Train loss curve (continues past first epoch)
      const trainPath = svg.append('path')
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2);

      // Test loss line (horizontal, decreases with more training)
      const testLossLine = svg.append('line')
        .attr('stroke', colors.darkBlue)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '5,5');

      const testLossLabel = svg.append('text')
        .attr('font-size', '11px')
        .attr('fill', colors.darkBlue);

      // Current position marker
      const positionMarker = svg.append('g');
      positionMarker.append('circle')
        .attr('r', 5)
        .attr('fill', colors.coral);
      positionMarker.append('line')
        .attr('y1', 0)
        .attr('y2', height - margin.bottom - margin.top)
        .attr('stroke', colors.coral)
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '2,2')
        .attr('opacity', 0.5);

      // Calculate test loss based on training step
      // Test loss tracks train loss at end of first epoch, then improves
      function getTestLoss(currentStep) {
        if (currentStep <= stepsPerEpoch) {
          // During first epoch, test loss = current train loss
          return allTrainData[Math.min(currentStep, stepsPerEpoch - 1)].loss;
        }
        // After first epoch, test loss improves significantly
        // It should be clearly lower than end-of-first-epoch train loss
        const epochsAfterFirst = (currentStep - stepsPerEpoch) / stepsPerEpoch;
        const improvement = 1 - Math.exp(-epochsAfterFirst * 0.5);
        const currentTrainLoss = allTrainData[currentStep].loss;
        // Test loss starts at end of first epoch loss, drops toward a value above train loss
        const testFloor = currentTrainLoss * 1.05; // Small generalization gap
        const testLoss = endOfFirstEpochLoss - improvement * (endOfFirstEpochLoss - testFloor);
        return Math.max(testFloor, testLoss);
      }

      // Calculate totals
      function calculateTotals(currentStep) {
        // MDL is always the sum of losses in first epoch
        let mdl = 0;
        for (let i = 0; i < firstEpochData.length; i++) {
          mdl += firstEpochData[i].loss;
        }

        // EDL = area above test loss in first epoch ONLY
        const testLoss = getTestLoss(currentStep);
        let edl = 0;
        for (let i = 0; i < firstEpochData.length; i++) {
          if (firstEpochData[i].loss > testLoss) {
            edl += (firstEpochData[i].loss - testLoss);
          }
        }

        return { mdl: mdl.toFixed(0), edl: edl.toFixed(0) };
      }

      function updateVisualization(currentStep) {
        const testLoss = getTestLoss(currentStep);
        const currentTrainLoss = allTrainData[currentStep].loss;

        // Update EDL area - area above test loss under FIRST EPOCH ONLY
        const edlAreaGen = d3.area()
          .x(d => x(d.step))
          .y0(y(testLoss))
          .y1(d => y(Math.max(d.loss, testLoss)));

        edlPath.datum(firstEpochData.filter(d => d.loss > testLoss))
          .attr('d', edlAreaGen);

        // Update train curve (show up to current step)
        if (currentStep > stepsPerEpoch) {
          const trainLine = d3.line()
            .x(d => x(d.step))
            .y(d => y(d.loss));
          trainPath.datum(allTrainData.slice(stepsPerEpoch, currentStep + 1)).attr('d', trainLine);
        } else {
          trainPath.datum([]).attr('d', '');
        }

        // Update position marker
        positionMarker
          .attr('transform', `translate(${x(currentStep)}, ${y(currentTrainLoss)})`);
        positionMarker.select('line')
          .attr('y2', height - margin.bottom - y(currentTrainLoss));

        // Update test loss line
        testLossLine
          .attr('x1', margin.left)
          .attr('x2', x(maxSteps))
          .attr('y1', y(testLoss))
          .attr('y2', y(testLoss));

        testLossLabel
          .attr('x', x(maxSteps) - 5)
          .attr('y', y(testLoss) - 5)
          .attr('text-anchor', 'end')
          .text(`L_test = ${testLoss.toFixed(2)}`);

        // Update totals and display
        const totals = calculateTotals(currentStep);
        document.getElementById('mdl-total').textContent = totals.mdl;
        document.getElementById('edl-total').textContent = totals.edl;
        document.getElementById('step-display').textContent = currentStep;
      }

      // Controls
      const slider = document.getElementById('step-slider');
      slider.addEventListener('input', (e) => {
        updateVisualization(parseInt(e.target.value));
      });

      // Play button
      let playing = false;
      let playInterval;
      const playBtn = document.getElementById('epoch-play');

      playBtn.addEventListener('click', () => {
        if (playing) {
          clearInterval(playInterval);
          playBtn.textContent = 'Play Training';
          playing = false;
        } else {
          let step = 0;
          slider.value = 0;
          updateVisualization(0);
          playBtn.textContent = 'Pause';
          playing = true;

          playInterval = setInterval(() => {
            step += 10;
            if (step > maxSteps) {
              clearInterval(playInterval);
              playBtn.textContent = 'Play Training';
              playing = false;
              return;
            }
            slider.value = step;
            updateVisualization(step);
          }, 50);
        }
      });

      // Initial render
      updateVisualization(0);
    }

    // ============================================================
    // VISUALIZATION 3: THE TWO SIGNATURES
    // ============================================================

    function initSignaturesVisualization() {
      const container = d3.select('#signatures-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 350;
      const margin = { top: 30, right: 30, bottom: 50, left: 70 };

      const data = generateSignaturesData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([1, 10000])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 0.6])
        .range([height - margin.bottom, margin.top]);

      // Grid
      svg.append('g')
        .attr('class', 'grid')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5).tickSize(-(height - margin.top - margin.bottom)).tickFormat(''));

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '~s'))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 40)
        .attr('fill', 'currentColor')
        .text('Number of training examples');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(6))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -50)
        .attr('fill', 'currentColor')
        .text('EDL per token');

      // Lines
      const line = d3.line()
        .x(d => x(d.n))
        .y(d => y(d.edl_per_token));

      const llamaPath = svg.append('path')
        .datum(data.llama)
        .attr('class', 'llama-line')
        .attr('fill', 'none')
        .attr('stroke', colors.blue)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      const tinyPath = svg.append('path')
        .datum(data.tinystories)
        .attr('class', 'tiny-line')
        .attr('fill', 'none')
        .attr('stroke', colors.orange)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      // Points
      const llamaPoints = svg.selectAll('.llama-point')
        .data(data.llama)
        .join('circle')
        .attr('class', 'llama-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.blue)
        .on('mouseover', (event, d) => {
          showTooltip(event, `n=${d.n}<br>EDL/token=${d.edl_per_token.toFixed(3)}`);
        })
        .on('mouseout', hideTooltip);

      const tinyPoints = svg.selectAll('.tiny-point')
        .data(data.tinystories)
        .join('circle')
        .attr('class', 'tiny-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.orange)
        .on('mouseover', (event, d) => {
          showTooltip(event, `n=${d.n}<br>EDL/token=${d.edl_per_token.toFixed(3)}`);
        })
        .on('mouseout', hideTooltip);

      // Annotations
      svg.append('text')
        .attr('x', x(3))
        .attr('y', y(0.55))
        .attr('font-size', '12px')
        .attr('fill', colors.blue)
        .text('Llama (Elicitation)');

      svg.append('text')
        .attr('x', x(500))
        .attr('y', y(0.48))
        .attr('font-size', '12px')
        .attr('fill', colors.orange)
        .text('TinyStories (Teaching)');

      // Toggle visibility
      let showLlama = true;
      let showTiny = true;

      function updateVisibility() {
        llamaPath.attr('opacity', showLlama ? 1 : 0);
        llamaPoints.attr('opacity', showLlama ? 1 : 0);
        tinyPath.attr('opacity', showTiny ? 1 : 0);
        tinyPoints.attr('opacity', showTiny ? 1 : 0);
      }

      document.getElementById('sig-llama').addEventListener('click', function() {
        showLlama = !showLlama;
        this.classList.toggle('active', showLlama);
        updateVisibility();
      });

      document.getElementById('sig-tiny').addEventListener('click', function() {
        showTiny = !showTiny;
        this.classList.toggle('active', showTiny);
        updateVisibility();
      });
    }

    // ============================================================
    // VISUALIZATION 4: THE CROSSOVER
    // ============================================================

    function initCrossoverVisualization() {
      const container = d3.select('#crossover-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 30, right: 30, bottom: 40, left: 60 };

      const data = generateCrossoverData();
      // Find the GLOBAL maximum (not local maximum, which can be thrown off by noise)
      let peakIdx = 0;
      let maxEdl = data[0].edl_per_token;
      for (let i = 1; i < data.length; i++) {
        if (data[i].edl_per_token > maxEdl) {
          maxEdl = data[i].edl_per_token;
          peakIdx = i;
        }
      }

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([d3.min(data, d => d.n), d3.max(data, d => d.n)])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, d3.max(data, d => d.edl_per_token) * 1.1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '~s'));

      // X axis label
      svg.append('text')
        .attr('x', width / 2)
        .attr('y', height - 5)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('Training examples');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5));

      // Y axis label
      svg.append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', 15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('EDL per token');

      // Teaching region (before peak)
      const teachingArea = d3.area()
        .x(d => x(d.n))
        .y0(height - margin.bottom)
        .y1(d => y(d.edl_per_token));

      svg.append('path')
        .datum(data.slice(0, peakIdx + 1))
        .attr('fill', colors.orange)
        .attr('opacity', 0.2)
        .attr('d', teachingArea);

      // Elicitation region (after peak)
      svg.append('path')
        .datum(data.slice(peakIdx))
        .attr('fill', colors.blue)
        .attr('opacity', 0.2)
        .attr('d', teachingArea);

      // Line
      const line = d3.line()
        .x(d => x(d.n))
        .y(d => y(d.edl_per_token))
        .curve(d3.curveMonotoneX);

      svg.append('path')
        .datum(data)
        .attr('fill', 'none')
        .attr('stroke', colors.darkBlue)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      // Peak marker
      svg.append('text')
        .attr('x', x(data[peakIdx].n))
        .attr('y', y(data[peakIdx].edl_per_token) - 15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '16px')
        .text('★');

      svg.append('text')
        .attr('x', x(data[peakIdx].n))
        .attr('y', y(data[peakIdx].edl_per_token) - 30)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', colors.darkBlue)
        .text('Capability acquired');

      // Draggable cursor
      const cursor = svg.append('g')
        .attr('class', 'cursor');

      cursor.append('line')
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '4,4');

      cursor.append('circle')
        .attr('r', 8)
        .attr('fill', colors.coral)
        .attr('cursor', 'ew-resize');

      let currentIdx = 10;

      function updateCursor(idx) {
        currentIdx = Math.max(0, Math.min(data.length - 1, idx));
        const d = data[currentIdx];

        cursor.attr('transform', `translate(${x(d.n)}, 0)`);
        cursor.select('circle').attr('cy', y(d.edl_per_token));

        const isTeaching = currentIdx < peakIdx;
        document.getElementById('crossover-state').innerHTML =
          `Currently: <span style="color: ${isTeaching ? colors.orange : colors.blue};">${isTeaching ? 'Teaching' : 'Eliciting'}</span>`;

        const slope = currentIdx > 0 ?
          (d.edl_per_token - data[currentIdx - 1].edl_per_token) /
          (Math.log10(d.n) - Math.log10(data[currentIdx - 1].n)) : 0;
        document.getElementById('crossover-slope').textContent =
          (slope >= 0 ? '+' : '') + slope.toFixed(3);
      }

      // Drag behavior
      const drag = d3.drag()
        .on('drag', function(event) {
          const mouseX = event.x;
          const n = x.invert(mouseX);
          const idx = data.findIndex(d => d.n >= n);
          updateCursor(idx >= 0 ? idx : data.length - 1);
        });

      cursor.call(drag);

      // Click to position
      svg.on('click', function(event) {
        const [mouseX] = d3.pointer(event);
        if (mouseX >= margin.left && mouseX <= width - margin.right) {
          const n = x.invert(mouseX);
          const idx = data.findIndex(d => d.n >= n);
          updateCursor(idx >= 0 ? idx : data.length - 1);
        }
      });

      updateCursor(10);
    }

    // ============================================================
    // VISUALIZATION 5: ONE EXAMPLE IS ALL YOU NEED
    // ============================================================

    function initOneExampleVisualization() {
      const container = d3.select('#one-example-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 30, right: 30, bottom: 60, left: 60 };

      const data = generateOneExampleData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x0 = d3.scaleBand()
        .domain(data.map(d => d.model))
        .range([margin.left, width - margin.right])
        .padding(0.3);

      const x1 = d3.scaleBand()
        .domain(['zero_shot', 'one_shot'])
        .range([0, x0.bandwidth()])
        .padding(0.1);

      const y = d3.scaleLinear()
        .domain([0, 1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x0))
        .selectAll('text')
        .attr('transform', 'rotate(-15)')
        .style('text-anchor', 'end');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).tickFormat(d3.format('.0%')));

      // Legend
      const legend = svg.append('g')
        .attr('transform', `translate(${width - margin.right - 150}, ${margin.top})`);

      legend.append('rect').attr('x', 0).attr('y', 0).attr('width', 15).attr('height', 15).attr('fill', '#ccc');
      legend.append('text').attr('x', 20).attr('y', 12).attr('font-size', '11px').text('Zero-shot');

      legend.append('rect').attr('x', 0).attr('y', 22).attr('width', 15).attr('height', 15).attr('fill', colors.coral);
      legend.append('text').attr('x', 20).attr('y', 34).attr('font-size', '11px').text('One-shot');

      // Bars
      const groups = svg.selectAll('.bar-group')
        .data(data)
        .join('g')
        .attr('class', 'bar-group')
        .attr('transform', d => `translate(${x0(d.model)}, 0)`);

      // Zero-shot bars
      groups.append('rect')
        .attr('class', 'zero-bar')
        .attr('x', x1('zero_shot'))
        .attr('y', y(0))
        .attr('width', x1.bandwidth())
        .attr('height', 0)
        .attr('fill', '#ccc');

      // One-shot bars
      groups.append('rect')
        .attr('class', 'one-bar')
        .attr('x', x1('one_shot'))
        .attr('y', y(0))
        .attr('width', x1.bandwidth())
        .attr('height', 0)
        .attr('fill', colors.coral);

      // Delta annotations
      const deltas = groups.append('text')
        .attr('class', 'delta-label')
        .attr('x', x1('one_shot') + x1.bandwidth() / 2)
        .attr('y', y(0) - 5)
        .attr('text-anchor', 'middle')
        .attr('font-size', '12px')
        .attr('font-weight', 'bold')
        .attr('fill', colors.coral)
        .attr('opacity', 0)
        .text(d => d.one_shot > 0.05 ? `+${Math.round(d.one_shot * 100)}pp` : '');

      function animateBars() {
        // Reset
        svg.selectAll('.zero-bar')
          .attr('y', y(0))
          .attr('height', 0);

        svg.selectAll('.one-bar')
          .attr('y', y(0))
          .attr('height', 0);

        deltas.attr('opacity', 0);

        // Animate zero-shot (stays at 0)
        svg.selectAll('.zero-bar')
          .data(data)
          .transition()
          .duration(500)
          .attr('y', d => y(d.zero_shot))
          .attr('height', d => y(0) - y(d.zero_shot));

        // Animate one-shot
        svg.selectAll('.one-bar')
          .data(data)
          .transition()
          .delay(600)
          .duration(800)
          .attr('y', d => y(d.one_shot))
          .attr('height', d => y(0) - y(d.one_shot));

        // Show deltas
        deltas
          .transition()
          .delay(1400)
          .duration(300)
          .attr('y', d => y(d.one_shot) - 8)
          .attr('opacity', 1);
      }

      // Intersection observer for scroll-triggered animation
      const observer = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            animateBars();
            observer.unobserve(entry.target);
          }
        });
      }, { threshold: 0.5 });

      observer.observe(container.node());

      // Replay button
      document.getElementById('animate-bars').addEventListener('click', animateBars);
    }

    // ============================================================
    // VISUALIZATION 6: THE CAUSAL INTERVENTION
    // ============================================================

    function initInterventionVisualization() {
      const container = d3.select('#intervention-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 30, right: 30, bottom: 40, left: 60 };

      const data = generateInterventionData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([1, 10000])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 0.6])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '~s'));

      // X axis label
      svg.append('text')
        .attr('x', width / 2)
        .attr('y', height - 5)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('Training examples');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5));

      // Y axis label
      svg.append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', 15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('EDL per token');

      const line = d3.line()
        .x(d => x(d.n))
        .y(d => y(d.edl_per_token))
        .curve(d3.curveMonotoneX);

      // Before line (teaching)
      const beforePath = svg.append('path')
        .datum(data.before)
        .attr('fill', 'none')
        .attr('stroke', colors.orange)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      // After line (elicitation)
      const afterPath = svg.append('path')
        .datum(data.after)
        .attr('fill', 'none')
        .attr('stroke', colors.blue)
        .attr('stroke-width', 2.5)
        .attr('opacity', 0)
        .attr('d', line);

      // Before points
      const beforePoints = svg.selectAll('.before-point')
        .data(data.before)
        .join('circle')
        .attr('class', 'before-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.orange);

      // After points
      const afterPoints = svg.selectAll('.after-point')
        .data(data.after)
        .join('circle')
        .attr('class', 'after-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.blue)
        .attr('opacity', 0);

      // Labels
      const beforeLabel = svg.append('text')
        .attr('x', x(100))
        .attr('y', y(data.before[4].edl_per_token) - 10)
        .attr('font-size', '12px')
        .attr('fill', colors.orange)
        .text('Before: Teaching');

      const afterLabel = svg.append('text')
        .attr('x', x(100))
        .attr('y', y(data.after[4].edl_per_token) + 20)
        .attr('font-size', '12px')
        .attr('fill', colors.blue)
        .attr('opacity', 0)
        .text('After: Elicitation');

      // Threshold indicators
      const beforeThreshold = svg.append('line')
        .attr('x1', margin.left)
        .attr('x2', width - margin.right)
        .attr('y1', y(0.4))
        .attr('y2', y(0.4))
        .attr('stroke', colors.orange)
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '5,5')
        .attr('opacity', 0.5);

      const afterThreshold = svg.append('line')
        .attr('x1', margin.left)
        .attr('x2', width - margin.right)
        .attr('y1', y(0.1))
        .attr('y2', y(0.1))
        .attr('stroke', colors.blue)
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '5,5')
        .attr('opacity', 0);

      // Interpolation function
      function interpolateData(t) {
        return data.before.map((b, i) => ({
          n: b.n,
          edl_per_token: b.edl_per_token * (1 - t) + data.after[i].edl_per_token * t
        }));
      }

      // Slider control
      const slider = document.getElementById('intervention-slider');
      const stateLabel = document.getElementById('intervention-state');

      slider.addEventListener('input', (e) => {
        const t = e.target.value / 100;

        // Interpolate curve
        const interpolated = interpolateData(t);

        // Update paths
        beforePath.attr('opacity', 1 - t);
        afterPath.attr('opacity', t);

        // Update points
        beforePoints
          .data(interpolated)
          .attr('cy', d => y(d.edl_per_token))
          .attr('fill', d3.interpolateRgb(colors.orange, colors.blue)(t));

        afterPoints.attr('opacity', t);

        // Update labels
        beforeLabel.attr('opacity', 1 - t);
        afterLabel.attr('opacity', t);

        // Update thresholds
        beforeThreshold.attr('opacity', 0.5 * (1 - t));
        afterThreshold.attr('opacity', 0.5 * t);

        // Update state text
        if (t < 0.5) {
          stateLabel.textContent = 'Before: Teaching signature';
          stateLabel.style.color = colors.orange;
        } else {
          stateLabel.textContent = 'After: Elicitation signature';
          stateLabel.style.color = colors.blue;
        }
      });
    }

    // ============================================================
    // VISUALIZATION 7: THE CAPACITY CLIFF
    // ============================================================

    function initCapacityVisualization() {
      const container = d3.select('#capacity-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 350;
      const margin = { top: 30, right: 30, bottom: 50, left: 60 };

      let data = generateCapacityData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([0.0001, 10])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 1.05])
        .range([height - margin.bottom, margin.top]);

      // Color by regime: blue for elicitation, orange for teaching
      const regimeColor = (regime) => regime === 'elicitation' ? colors.blue : colors.orange;

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '.0e'))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 40)
        .attr('fill', 'currentColor')
        .text('EDL / trainable parameters (bits/param)');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).tickFormat(d3.format('.0%')))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -45)
        .attr('fill', 'currentColor')
        .text('Capacity');

      // Threshold lines
      svg.append('line')
        .attr('class', 'threshold elicit-threshold')
        .attr('x1', x(0.05))
        .attr('x2', x(0.05))
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', colors.blue)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '5,5');

      svg.append('text')
        .attr('x', x(0.05) + 5)
        .attr('y', margin.top + 15)
        .attr('font-size', '11px')
        .attr('fill', colors.blue)
        .text('Elicitation threshold (~0.05)');

      svg.append('line')
        .attr('class', 'threshold teach-threshold')
        .attr('x1', x(1))
        .attr('x2', x(1))
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', colors.orange)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '5,5');

      svg.append('text')
        .attr('x', x(1) + 5)
        .attr('y', margin.top + 30)
        .attr('font-size', '11px')
        .attr('fill', colors.orange)
        .text('Teaching threshold (~1)');

      // Points colored by regime (blue = elicitation, orange = teaching)
      const points = svg.selectAll('.cap-point')
        .data(data)
        .join('circle')
        .attr('class', 'cap-point')
        .attr('cx', d => x(d.edl_per_param))
        .attr('cy', d => y(d.capacity))
        .attr('r', 6)
        .attr('fill', d => regimeColor(d.regime))
        .attr('opacity', 0.7)
        .attr('stroke', 'white')
        .attr('stroke-width', 1)
        .on('mouseover', (event, d) => {
          showTooltip(event,
            `EDL/P: ${d.edl_per_param.toFixed(4)}<br>` +
            `Capacity: ${(d.capacity * 100).toFixed(1)}%<br>` +
            `Regime: ${d.regime}`
          );
        })
        .on('mouseout', hideTooltip);

      // Legend
      const legend = svg.append('g')
        .attr('transform', `translate(${width - margin.right - 80}, ${height - margin.bottom - 100})`);

      // Legend for regime colors
      const regimes = [
        { name: 'Elicitation', color: colors.blue },
        { name: 'Teaching', color: colors.orange }
      ];
      regimes.forEach((regime, i) => {
        legend.append('circle')
          .attr('cx', 0)
          .attr('cy', i * 20)
          .attr('r', 5)
          .attr('fill', regime.color);
        legend.append('text')
          .attr('x', 10)
          .attr('y', i * 20 + 4)
          .attr('font-size', '11px')
          .text(regime.name);
      });

      // Filters
      let showElicit = true;
      let showTeach = true;

      function updatePoints() {
        points
          .attr('opacity', d => {
            const regimeMatch = (d.regime === 'elicitation' && showElicit) ||
                               (d.regime === 'teaching' && showTeach);
            return regimeMatch ? 0.7 : 0.05;
          });
      }

      document.getElementById('cap-elicit').addEventListener('click', function() {
        showElicit = !showElicit;
        this.classList.toggle('active', showElicit);
        updatePoints();
      });

      document.getElementById('cap-teach').addEventListener('click', function() {
        showTeach = !showTeach;
        this.classList.toggle('active', showTeach);
        updatePoints();
      });
    }

    // ============================================================
    // VISUALIZATION 8: ADAPTER SIZE CALCULATOR
    // ============================================================

    function initCalculator() {
      const container = d3.select('#calc-viz');
      const width = container.node().getBoundingClientRect().width;
      const height = 150;
      const margin = { top: 20, right: 20, bottom: 30, left: 50 };

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([0.001, 10])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(4, '.0e'));

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(3).tickFormat(d3.format('.0%')));

      // Capacity curve
      const curveData = [];
      for (let i = -3; i <= 1; i += 0.1) {
        const edlP = Math.pow(10, i);
        const threshold = 0.05;
        const capacity = edlP < threshold ? 0.95 : Math.max(0.1, 0.95 - (edlP - threshold) * 3);
        curveData.push({ edlP, capacity });
      }

      const line = d3.line()
        .x(d => x(d.edlP))
        .y(d => y(d.capacity))
        .curve(d3.curveMonotoneX);

      svg.append('path')
        .datum(curveData)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', line);

      // "You are here" marker
      const marker = svg.append('g')
        .attr('class', 'marker');

      marker.append('circle')
        .attr('r', 8)
        .attr('fill', colors.darkBlue);

      marker.append('text')
        .attr('y', -15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '10px')
        .attr('fill', colors.darkBlue)
        .text('You are here');

      function updateCalculator() {
        const edl = parseFloat(document.getElementById('calc-edl').value) || 10000;
        const modelSelect = document.getElementById('calc-model');
        let modelParams;

        if (modelSelect.value === 'custom') {
          modelParams = parseFloat(document.getElementById('calc-custom-params').value) || 8e9;
          document.getElementById('custom-params-group').style.display = 'block';
        } else {
          modelParams = parseFloat(modelSelect.value);
          document.getElementById('custom-params-group').style.display = 'none';
        }

        const regime = document.getElementById('calc-regime').value;
        const targetCap = parseFloat(document.getElementById('calc-target').value);

        document.getElementById('target-cap-display').textContent = targetCap.toFixed(2);

        // Determine threshold based on regime
        let threshold;
        if (regime === 'elicitation') {
          threshold = 0.05;
        } else if (regime === 'teaching') {
          threshold = 1.0;
        } else {
          // Auto-detect: use elicitation if EDL is small relative to model
          threshold = edl / modelParams < 0.1 ? 0.05 : 1.0;
        }

        // Calculate required parameters
        const requiredParams = edl / (threshold * targetCap);

        // Estimate LoRA rank (assuming roughly 2 * hidden_dim * rank * num_layers trainable params)
        // For 8B model: hidden_dim ~4096, num_layers ~32, so params ≈ rank * 524288
        const paramsPerRank = modelParams / 30000; // rough estimate
        let rank = Math.ceil(requiredParams / paramsPerRank);
        rank = Math.max(1, Math.min(1024, Math.pow(2, Math.ceil(Math.log2(rank)))));

        const actualParams = rank * paramsPerRank;
        const actualEdlP = edl / actualParams;

        // Update display
        document.getElementById('calc-rank').textContent = rank;
        document.getElementById('calc-params').textContent =
          actualParams >= 1e9 ? `~${(actualParams / 1e9).toFixed(1)}B` :
          actualParams >= 1e6 ? `~${(actualParams / 1e6).toFixed(1)}M` :
          `~${(actualParams / 1e3).toFixed(1)}K`;

        // Warning
        const warning = document.getElementById('calc-warning');
        if (requiredParams > modelParams * 0.1) {
          warning.style.display = 'block';
          warning.textContent = 'Warning: Required capacity exceeds typical LoRA limits. Consider full fine-tuning or a larger model.';
        } else if (rank > 256) {
          warning.style.display = 'block';
          warning.textContent = 'Note: High rank recommended. This approaches full fine-tuning efficiency.';
        } else {
          warning.style.display = 'none';
        }

        // Update marker
        const clampedEdlP = Math.max(0.001, Math.min(10, actualEdlP));
        const capacity = clampedEdlP < threshold ? 0.95 : Math.max(0.1, 0.95 - (clampedEdlP - threshold) * 3);

        marker
          .attr('transform', `translate(${x(clampedEdlP)}, ${y(Math.min(1, capacity))})`);
      }

      // Event listeners
      ['calc-edl', 'calc-model', 'calc-custom-params', 'calc-regime', 'calc-target'].forEach(id => {
        document.getElementById(id).addEventListener('input', updateCalculator);
        document.getElementById(id).addEventListener('change', updateCalculator);
      });

      updateCalculator();
    }

    // ============================================================
    // INITIALIZE ALL VISUALIZATIONS
    // ============================================================

    document.addEventListener('DOMContentLoaded', () => {
      initMDLVisualization();
      initEDLDecomposition();
      initMultiEpochVisualization();
      initSignaturesVisualization();
      initCrossoverVisualization();
      initOneExampleVisualization();
      initInterventionVisualization();
      initCapacityVisualization();
      initCalculator();
    });
  </script>
</body>
</html>
