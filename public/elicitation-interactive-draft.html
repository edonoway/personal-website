<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Bits That Count: Quantifying and Predicting Emergent Capabilities in Language Models</title>
  <script src="https://d3js.org/d3.v7.min.js"></script>
  <style>
    :root {
      --coral: #D97757;
      --coral-light: #E89B7E;
      --coral-dark: #B85A3C;
      --dark-blue: #1a1a2e;
      --cream: #FAF8F5;
      --cream-dark: #F0EDE8;
      --text: #2D2D2D;
      --text-light: #666;
      --border: #E0DCD5;
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      line-height: 1.7;
      color: var(--text);
      background: var(--cream);
    }

    article {
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem 1.5rem 4rem;
    }

    header {
      text-align: left;
      margin-bottom: 3rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid var(--border);
    }

    h1 {
      font-size: 2.2rem;
      font-weight: 700;
      color: var(--dark-blue);
      margin-bottom: 1rem;
      line-height: 1.2;
    }

    .authors {
      font-size: 1rem;
      color: var(--text-light);
      margin-bottom: 1rem;
    }

    .summary {
      font-style: italic;
      color: var(--text-light);
      /* font-weight: 700; */
      /* max-width: 600px; */
      /* margin: 0 auto; */
    }

    h2 {
      font-size: 1.6rem;
      font-weight: 600;
      color: var(--dark-blue);
      margin: 3rem 0 1.5rem;
      padding-top: 1rem;
      border-top: 1px solid var(--border);
    }

    h3 {
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--dark-blue);
      margin: 2rem 0 1rem;
    }

    p {
      margin-bottom: 1.25rem;
      max-width: 700px;
    }

    strong {
      color: var(--dark-blue);
    }

    .highlight {
      background: linear-gradient(180deg, transparent 60%, rgba(217, 119, 87, 0.2) 60%);
    }

    .formula {
      font-family: 'Georgia', serif;
      font-size: 1.1rem;
      text-align: center;
      padding: 1.5rem;
      background: var(--cream-dark);
      border-radius: 8px;
      margin: 1.5rem 0;
      border-left: 4px solid var(--coral);
    }

    ul, ol {
      margin: 1rem 0 1.5rem 1.5rem;
      max-width: 700px;
    }

    li {
      margin-bottom: 0.5rem;
    }

    /* Visualization containers */
    .visualization {
      background: white;
      border-radius: 12px;
      padding: 1.5rem;
      margin: 2rem 0;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
      border: 1px solid var(--border);
    }

    .viz-title {
      font-size: 1.1rem;
      font-weight: 600;
      color: var(--dark-blue);
      margin-bottom: 0.5rem;
    }

    .viz-subtitle {
      font-size: 0.9rem;
      color: var(--text-light);
      margin-bottom: 1rem;
    }

    .viz-container {
      position: relative;
      width: 100%;
      min-height: 300px;
    }

    .viz-controls {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      align-items: center;
      margin-top: 1rem;
      padding-top: 1rem;
      border-top: 1px solid var(--border);
    }

    .viz-controls label {
      font-size: 0.85rem;
      color: var(--text-light);
    }

    .viz-controls input[type="range"] {
      width: 200px;
      accent-color: var(--coral);
    }

    .viz-controls button {
      background: var(--coral);
      color: white;
      border: none;
      padding: 0.5rem 1rem;
      border-radius: 6px;
      cursor: pointer;
      font-size: 0.85rem;
      transition: background 0.2s;
    }

    .viz-controls button:hover {
      background: var(--coral-dark);
    }

    .viz-controls button.secondary {
      background: var(--cream-dark);
      color: var(--text);
    }

    .viz-controls button.secondary:hover {
      background: var(--border);
    }

    .viz-controls button.active {
      background: var(--dark-blue);
    }

    .toggle-group {
      display: flex;
      gap: 0.25rem;
    }

    .toggle-group button {
      border-radius: 0;
      background: var(--cream-dark);
      color: var(--text);
    }

    .toggle-group button:hover {
      background: var(--border);
    }

    .toggle-group button.active {
      background: var(--coral);
      color: white;
    }

    .toggle-group button:first-child {
      border-radius: 6px 0 0 6px;
    }

    .toggle-group button:last-child {
      border-radius: 0 6px 6px 0;
    }

    .metric-display {
      font-family: 'SF Mono', 'Monaco', 'Consolas', monospace;
      font-size: 1.5rem;
      color: var(--coral);
      font-weight: 600;
    }

    /* SVG styles */
    svg {
      display: block;
      width: 100%;
      height: auto;
    }

    .axis text {
      font-size: 11px;
      fill: var(--text-light);
    }

    .axis line, .axis path {
      stroke: var(--border);
    }

    .grid line {
      stroke: var(--cream-dark);
      stroke-dasharray: 2, 2;
    }

    .annotation {
      font-size: 12px;
      fill: var(--text-light);
    }

    .annotation-box {
      fill: white;
      stroke: var(--border);
      rx: 4;
    }

    /* Calculator styles */
    .calculator {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
    }

    .calc-inputs {
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .calc-input-group {
      display: flex;
      flex-direction: column;
      gap: 0.25rem;
    }

    .calc-input-group label {
      font-size: 0.85rem;
      font-weight: 500;
      color: var(--text-light);
    }

    .calc-input-group input,
    .calc-input-group select {
      padding: 0.5rem;
      border: 1px solid var(--border);
      border-radius: 6px;
      font-size: 1rem;
    }

    .calc-output {
      background: var(--cream-dark);
      padding: 1.5rem;
      border-radius: 8px;
    }

    .calc-result {
      font-size: 2rem;
      font-weight: 700;
      color: var(--coral);
    }

    .calc-warning {
      color: var(--coral-dark);
      font-size: 0.9rem;
      margin-top: 0.5rem;
      padding: 0.5rem;
      background: rgba(217, 119, 87, 0.1);
      border-radius: 4px;
    }

    /* Tooltip */
    .tooltip {
      position: absolute;
      background: var(--dark-blue);
      color: white;
      padding: 0.5rem 0.75rem;
      border-radius: 6px;
      font-size: 0.8rem;
      pointer-events: none;
      opacity: 0;
      transition: opacity 0.15s;
      z-index: 100;
    }

    /* Illustrations */
    .illustration {
      background: white;
      border-radius: 12px;
      padding: 1.5rem;
      margin: 2rem 0;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
      border: 1px solid var(--border);
      text-align: center;
    }

    .illustration svg {
      display: block;
      margin: 0 auto;
    }

    .illustration-caption {
      font-size: 0.9rem;
      color: var(--text-light);
      margin-top: 1rem;
      margin-bottom: 0;
      font-style: italic;
      max-width: 600px;
      margin-left: auto;
      margin-right: auto;
    }

    /* Footnotes */
    .footnote {
      font-size: 0.85rem;
      color: var(--text-light);
      border-top: 1px solid var(--border);
      margin-top: 3rem;
      padding-top: 1rem;
    }

    .footnote p {
      margin-bottom: 0.5rem;
    }

    sup {
      color: var(--coral);
      font-weight: 500;
    }

    /* Responsive */
    @media (max-width: 768px) {
      h1 { font-size: 1.75rem; }
      h2 { font-size: 1.4rem; }
      .calculator { grid-template-columns: 1fr; }
      .viz-controls { flex-direction: column; align-items: flex-start; }
    }

    /* Backfill visualization */
    .backfill-viz .bf-slider-container {
      text-align: center;
      margin-bottom: 1rem;
      padding: 0.75rem 1.25rem;
      background: var(--cream-dark);
      border-radius: 8px;
    }
    .backfill-viz .bf-slider-container label {
      font-size: 0.9rem;
      font-weight: 500;
      color: #444;
    }
    .backfill-viz .bf-slider-container input[type="range"] {
      width: 260px;
      margin: 0 10px;
      vertical-align: middle;
    }
    .backfill-viz .bf-slider-container .bf-count {
      font-weight: 700;
      font-size: 1.05rem;
      color: var(--dark-blue);
      min-width: 2ch;
      display: inline-block;
    }
    .backfill-viz .bf-panels {
      display: flex;
      gap: 20px;
      margin-bottom: 1rem;
    }
    .backfill-viz .bf-panel {
      flex: 1;
      background: #fff;
      border-radius: 10px;
      padding: 1rem;
      border: 1px solid var(--border);
    }
    .backfill-viz .bf-panel h4 {
      font-size: 0.9rem;
      font-weight: 600;
      text-align: center;
      margin-bottom: 0.5rem;
    }
    .backfill-viz .bf-panel.teaching h4 { color: #6a3d9a; }
    .backfill-viz .bf-panel.elicitation h4 { color: #1a8a6a; }
    .backfill-viz .bf-panel svg {
      width: 100%;
      height: auto;
      display: block;
    }
    .backfill-viz .bf-metrics {
      display: flex;
      justify-content: space-around;
      margin-top: 0.6rem;
      padding-top: 0.6rem;
      border-top: 1px solid #eee;
    }
    .backfill-viz .bf-metric {
      text-align: center;
      font-size: 0.78rem;
      color: #666;
    }
    .backfill-viz .bf-metric .bf-value {
      display: block;
      font-size: 0.95rem;
      font-weight: 700;
      color: var(--dark-blue);
      margin-top: 2px;
    }
    .backfill-viz .bf-metric .bf-trend {
      font-size: 0.72rem;
      margin-top: 1px;
    }
    .backfill-viz .bf-metric .bf-trend.up { color: #6a3d9a; }
    .backfill-viz .bf-metric .bf-trend.down { color: #1a8a6a; }
    .backfill-viz .bf-legend {
      display: flex;
      justify-content: center;
      gap: 1.25rem;
      font-size: 0.78rem;
      color: #555;
      flex-wrap: wrap;
    }
    .backfill-viz .bf-legend-item {
      display: flex;
      align-items: center;
      gap: 5px;
    }
    .backfill-viz .bf-legend-swatch {
      width: 13px;
      height: 13px;
      border-radius: 2px;
      flex-shrink: 0;
    }
    .backfill-viz .bf-axis-line { stroke: #ccc; stroke-width: 1; }
    .backfill-viz .bf-tick-label { font-size: 9px; fill: #999; }
    .backfill-viz .bf-axis-title { font-size: 11px; fill: #666; font-weight: 500; }
    .backfill-viz .bf-floor-line { stroke: #aaa; stroke-width: 1; stroke-dasharray: 2,2; opacity: 0.6; }
    .backfill-viz .bf-test-loss-label { font-size: 9px; fill: #888; }
    @media (max-width: 700px) {
      .backfill-viz .bf-panels { flex-direction: column; }
    }
  </style>
</head>
<body>
  <article>
    <header>
      <h1>Bits That Count: Quantifying and Predicting Emergent Capabilities in Language Models</h1>
      <!-- <h2><em>When more is different, sometimes less is all you need.</em></h2> -->
      <p class="authors">Elizabeth Donoway, Hailey Joren, Michael R. DeWeese, Ethan Perez, John Schulman, Fabien Roger, Jan Leike</p>
      <p class="summary">Quantifying and predicting what language models know, how much they (can) learn, and how they learn it.</p>
    </header>

    <section id="introduction">
      <!-- <p>It's unclear what models know.</p>

      <p>It's hard to get them to show us—they don't just tell us (yet), and we often don't even know the right questions to ask.</p> -->

      <p>Language models are pretrained on vast amounts of diverse data, acquiring capabilities that may remain hidden until the right prompt or training signal surfaces them. We can't enumerate all the capabilities a model might have, and sometimes we can't even anticipate them. Though we've made significant progress—and it's hard to dispute the many practical successes of AI that have been achieved anyway—we still have much to learn about what models know, how they learn, and how capable they might be.</p>

      <p>This uncertainty has practical consequences.</p>

      <p><strong>For safety:</strong> If a dangerous capability is latent, it can sometimes be surfaced with minimal intervention—a few examples, a clever prompt, an unexpected deployment context. If the capability must be taught from scratch, the information barrier is higher and more predictable. Knowing which regime we're in changes how we assess risk.</p>

      <p><strong>For evaluation:</strong> When we fine-tune models to assess their capabilities, are we measuring what they already know, or inadvertently teaching them something new? If our elicitation procedure crosses into teaching, we're no longer evaluating the model that will be deployed—we're evaluating a different model, one that learned during the evaluation itself.</p>

      <p><strong>For efficiency:</strong> Training is expensive. If a capability is already latent, massive datasets and high-rank adapters are wasteful. If it must be taught, insufficient data wastes time. Knowing the learning regime in advance lets us allocate resources appropriately.</p>

      <p><strong>For science:</strong> We largely lack formal descriptions of how models learn. We have heuristics and intuitions, but these are difficult to make predictions from. A quantitative framework for learning dynamics would let us ask—and answer—questions we currently can't even formulate precisely.</p>

      <p>We develop such a framework here, introducing <span class="highlight"><strong>Excess Description Length</strong></span> (EDL) as an operational metric for the generalizable information a model learns from its training data. EDL distinguishes teaching from elicitation, tracks transitions between learning processes, and predicts parameter capacity limits for fine-tuning.</p>

      <!-- <p>EDL offers a more comprehensive framework for evaluating model capabilities and learning, one that also aligns closely with our understanding of human learning and cognition.</p> -->
    </section>

    <h2>Learning as Compression</h2>

    <section id="alice-bob">
      <h3>Alice and Bob Learn to Communicate</h3>

      <p>Imagine Alice has fine-tuned a language model and wants to share it with Bob. Bob already has the same base model and the same training inputs, but not the labels. Instead of sending gigabytes of weight differences, Alice could just send the labels along with instructions describing exactly how to replicate her training procedure.<sup>[1]</sup> She can even use the base model itself to communicate the labels to Bob. Bob trains his copy on them and reconstructs her model exactly.<sup>[2]</sup></p>

      <!-- Alice and Bob diagram: Two scenarios comparison -->
      <div class="illustration">
        <svg viewBox="0 0 800 380" style="max-width: 800px; width: 100%; height: auto;">
          <!-- Scenario 1: Sending weights (bad) -->
          <g transform="translate(0, 0)">
            <rect x="10" y="10" width="380" height="160" rx="8" fill="#fef6f6" stroke="#c66" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="200" y="30" text-anchor="middle" font-size="12" font-weight="600" fill="#c66">Option 1: Send the weights</text>

            <!-- Alice -->
            <g transform="translate(40, 50)">
              <circle cx="25" cy="25" r="20" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">A</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Alice</text>
            </g>

            <!-- Huge file -->
            <g transform="translate(120, 45)">
              <rect x="0" y="0" width="120" height="70" rx="4" fill="#1a1a2e"/>
              <text x="60" y="25" text-anchor="middle" font-size="9" fill="white">Weight Diff</text>
              <text x="60" y="42" text-anchor="middle" font-size="14" fill="#D97757" font-weight="bold">4.2 GB</text>
              <text x="60" y="58" text-anchor="middle" font-size="8" fill="#999">billions of floats</text>
            </g>

            <!-- Arrow -->
            <path d="M 250 80 L 300 80" stroke="#c66" stroke-width="2"/>
            <polygon points="300,80 290,74 290,86" fill="#c66"/>

            <!-- Bob -->
            <g transform="translate(320, 50)">
              <circle cx="25" cy="25" r="20" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">B</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Bob</text>
            </g>

            <!-- X mark -->
            <text x="200" y="145" text-anchor="middle" font-size="11" fill="#c66">Slow! Takes hours to transfer...</text>
          </g>

          <!-- Scenario 2: Sending data (good) -->
          <g transform="translate(410, 0)">
            <rect x="0" y="10" width="380" height="160" rx="8" fill="#f6fef6" stroke="#5a5" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="190" y="30" text-anchor="middle" font-size="12" font-weight="600" fill="#5a5">Option 2: Send the training data</text>

            <!-- Alice -->
            <g transform="translate(30, 50)">
              <circle cx="25" cy="25" r="20" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">A</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Alice</text>
            </g>

            <!-- Small file -->
            <g transform="translate(110, 55)">
              <rect x="0" y="0" width="80" height="50" rx="4" fill="#50C878"/>
              <text x="40" y="20" text-anchor="middle" font-size="9" fill="white">Labels</text>
              <text x="40" y="38" text-anchor="middle" font-size="12" fill="white" font-weight="bold">~2 MB</text>
            </g>

            <!-- Plus recipe -->
            <g transform="translate(200, 60)">
              <text x="0" y="20" font-size="14" fill="#666">+</text>
              <rect x="15" y="0" width="60" height="40" rx="4" fill="#F0EDE8" stroke="#E0DCD5"/>
              <text x="45" y="15" text-anchor="middle" font-size="8" fill="#666">Recipe:</text>
              <text x="45" y="28" text-anchor="middle" font-size="7" fill="#666">lr, epochs...</text>
            </g>

            <!-- Arrow -->
            <path d="M 280 80 L 310 80" stroke="#5a5" stroke-width="2"/>
            <polygon points="310,80 300,74 300,86" fill="#5a5"/>

            <!-- Bob trains -->
            <g transform="translate(320, 45)">
              <circle cx="25" cy="25" r="20" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="25" y="30" text-anchor="middle" font-size="16">B</text>
              <text x="25" y="60" text-anchor="middle" font-size="10" fill="#1a1a2e">Bob</text>
              <text x="25" y="75" text-anchor="middle" font-size="8" fill="#4A90D9">trains locally</text>
            </g>

            <!-- Check mark -->
            <text x="190" y="145" text-anchor="middle" font-size="11" fill="#5a5">Fast! Same result, way less data.</text>
          </g>

          <!-- Speech bubble from Alice -->
          <g transform="translate(100, 180)">
            <path d="M 0 30 Q 0 0 30 0 L 570 0 Q 600 0 600 30 L 600 70 Q 600 100 570 100 L 100 100 L 80 130 L 90 100 L 30 100 Q 0 100 0 70 Z" fill="#FAF8F5" stroke="#E0DCD5" stroke-width="1"/>
            <text x="300" y="35" text-anchor="middle" font-size="11" fill="#1a1a2e" font-style="italic">"The model diff is huge and would take forever to send!</text>
            <text x="300" y="52" text-anchor="middle" font-size="11" fill="#1a1a2e" font-style="italic">What if I just sent you the dataset I used instead? It's only 10,000 examples.</text>
            <text x="300" y="69" text-anchor="middle" font-size="11" fill="#1a1a2e" font-style="italic">You can train your own copy—took me 30 minutes with this recipe."</text>
            <text x="300" y="90" text-anchor="middle" font-size="10" fill="#666">— Alice</text>
          </g>

          <!-- Key insight -->
          <g transform="translate(150, 320)">
            <rect x="0" y="0" width="500" height="45" rx="6" fill="#D97757" opacity="0.1" stroke="#D97757"/>
            <text x="250" y="20" text-anchor="middle" font-size="12" fill="#1a1a2e" font-weight="600">Key insight: Sending the training data is equivalent to sending the weight update.</text>
            <text x="250" y="38" text-anchor="middle" font-size="11" fill="#666">The information content is the same—but the data is much smaller!</text>
          </g>
        </svg>
        <p class="illustration-caption">Alice can share her fine-tuned model by sending training data instead of weights. Both contain the same information, but the data is far more compact.</p>
      </div>

      <p>How many bits does Alice need to send?</p>

      <p>This is the <strong>minimum description length</strong> (MDL) of the training data—the shortest message that lets Bob reconstruct the fine-tuned model given what he already knows.</p>

      <p>To minimize the description length—that is, the file size—Alice can compress the labels. But she and Bob need to use the same compression algorithm so that Bob can decompress them. Here, the model itself becomes the compression algorithm. If the model already predicts a label well, Alice needs very few bits to communicate it. Saying "the answer is 68" to a model that already thinks "68" is likely requires almost no information. But if the model expects "14" when the answer is actually "68", Alice needs more bits to convey the surprise. Better predictions mean shorter messages.</p>

      <p>If Alice sends labels sequentially, she and Bob can use an optimizer—say, SGD—to iteratively improve (train) their shared model as it compresses. They each update<sup>[3]</sup> their copy after each batch Bob receives, using only the labels Bob has received so far. This keeps the compression algorithm identical on both ends, so Bob can always decompress.</p>

      <p>Over time, the model's predictions improve, so Alice can send each new batch of labels using progressively smaller files. Once every label in the dataset has been received by Bob, he has all the information necessary to recreate Alice's fine-tuned model.<sup>[4]</sup></p>
    </section>

    <section id="computing-mdl">
      <h3>Computing MDL from a Training Run</h3>

      <p>MDL is simply the sum of log-losses on each training label, computed <em>before</em> the model updates on that label. It measures how many bits the model needed to receive to encode all the training labels once. In terms of training, this is the total log-loss accumulated over the first epoch.</p>

      <!-- Visualization 1: Accumulating MDL -->
      <div class="visualization" id="viz-mdl">
        <div class="viz-title">Accumulating MDL</div>
        <div class="viz-subtitle">Watch the model accumulate bits as it processes training data. The shaded area represents the total MDL.</div>
        <div class="viz-container" id="mdl-chart"></div>
        <div class="viz-controls">
          <button id="mdl-play">Play</button>
          <label>Training step: <span id="mdl-step-display">0</span></label>
          <input type="range" id="mdl-slider" min="0" max="100" value="0">
          <div class="metric-display">MDL = <span id="mdl-value">0</span> bits</div>
        </div>
      </div>
    </section>

    <section id="mdl-to-edl">
      <h3>From MDL to EDL</h3>

      <p>MDL tells us how much information the model received. But how much did it actually <em>learn</em>? How much structure did it extract about patterns that generalize to new data?</p>

      <p>After training (potentially for multiple epochs), we evaluate the model on held-out test data. The test loss represents the model's remaining uncertainty—the information it <em>couldn't</em> compress into its parameters.</p>

      <p>If the model learned nothing generalizable, its test loss would be as high as its initial training loss. MDL would equal n × L<sub>test</sub>, and there would be no "excess."</p>

      <p>If the model learned perfectly, its test loss would be zero. Everything in MDL would be "excess"—information that got compressed into the weights.</p>

      <p><strong>Excess description length</strong> is the difference:</p>

      <div class="formula">
        <strong>EDL = MDL − n × L<sub>test</sub></strong>
      </div>

      <p>This is the information that was "excess" during training—bits the model needed to receive early on but wouldn't need anymore after learning. It's the information that got absorbed into the parameters. <em>The bits that count toward generalization.</em></p>

      <!-- EDL intuition diagram -->
      <div class="illustration">
        <svg viewBox="0 0 800 320" style="max-width: 800px; width: 100%; height: auto;">
          <!-- Scenario 1: Bob without trained model -->
          <g transform="translate(20, 20)">
            <rect x="0" y="0" width="360" height="130" rx="8" fill="#fef6f6" stroke="#c66" stroke-width="1"/>
            <text x="180" y="25" text-anchor="middle" font-size="12" font-weight="600" fill="#c66">Scenario A: Bob has only the base model</text>

            <!-- Alice sends MDL -->
            <g transform="translate(20, 45)">
              <circle cx="20" cy="20" r="16" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">A</text>
            </g>

            <!-- Big message -->
            <g transform="translate(80, 40)">
              <rect x="0" y="0" width="140" height="50" rx="4" fill="#D97757"/>
              <text x="70" y="22" text-anchor="middle" font-size="10" fill="white">Compressed labels</text>
              <text x="70" y="38" text-anchor="middle" font-size="14" fill="white" font-weight="bold">MDL bits</text>
            </g>

            <!-- Arrow -->
            <path d="M 230 65 L 270 65" stroke="#c66" stroke-width="2"/>
            <polygon points="270,65 260,59 260,71" fill="#c66"/>

            <!-- Bob base -->
            <g transform="translate(285, 45)">
              <circle cx="20" cy="20" r="16" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">B</text>
              <text x="20" y="50" text-anchor="middle" font-size="8" fill="#666">Base model</text>
            </g>

            <text x="180" y="115" text-anchor="middle" font-size="10" fill="#666">Bob needs ALL the information to reconstruct Alice's model</text>
          </g>

          <!-- Scenario 2: Bob WITH trained model -->
          <g transform="translate(410, 20)">
            <rect x="0" y="0" width="360" height="130" rx="8" fill="#f6fef6" stroke="#5a5" stroke-width="1"/>
            <text x="180" y="25" text-anchor="middle" font-size="12" font-weight="600" fill="#5a5">Scenario B: Bob already has the trained model</text>

            <!-- Alice sends less -->
            <g transform="translate(20, 45)">
              <circle cx="20" cy="20" r="16" fill="#E89B7E" stroke="#D97757" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">A</text>
            </g>

            <!-- Small message -->
            <g transform="translate(80, 45)">
              <rect x="0" y="0" width="100" height="40" rx="4" fill="#50C878"/>
              <text x="50" y="18" text-anchor="middle" font-size="9" fill="white">Just residuals</text>
              <text x="50" y="32" text-anchor="middle" font-size="12" fill="white" font-weight="bold">n × L<tspan baseline-shift="sub" font-size="8">test</tspan></text>
            </g>

            <!-- Arrow -->
            <path d="M 195 65 L 270 65" stroke="#5a5" stroke-width="2"/>
            <polygon points="270,65 260,59 260,71" fill="#5a5"/>

            <!-- Bob trained -->
            <g transform="translate(285, 40)">
              <circle cx="20" cy="20" r="16" fill="#B8D4E8" stroke="#4A90D9" stroke-width="2"/>
              <text x="20" y="25" text-anchor="middle" font-size="14">B</text>
              <rect x="-5" y="42" width="50" height="20" rx="3" fill="#1a1a2e"/>
              <text x="20" y="56" text-anchor="middle" font-size="7" fill="white">Trained</text>
            </g>

            <text x="180" y="115" text-anchor="middle" font-size="10" fill="#666">Bob only needs residual uncertainty—he already learned the patterns!</text>
          </g>

          <!-- The difference = EDL -->
          <g transform="translate(100, 165)">
            <rect x="0" y="0" width="600" height="140" rx="8" fill="#D97757" opacity="0.08" stroke="#D97757"/>
            <text x="300" y="25" text-anchor="middle" font-size="14" font-weight="600" fill="#1a1a2e">The Difference = EDL</text>

            <!-- Visual equation -->
            <g transform="translate(50, 50)">
              <!-- MDL box -->
              <rect x="0" y="0" width="100" height="60" rx="4" fill="#D97757" opacity="0.7"/>
              <text x="50" y="25" text-anchor="middle" font-size="11" fill="white">MDL</text>
              <text x="50" y="45" text-anchor="middle" font-size="10" fill="white">(all bits sent)</text>

              <!-- Minus -->
              <text x="130" y="35" font-size="24" fill="#1a1a2e">−</text>

              <!-- n*L_test box -->
              <rect x="160" y="10" width="100" height="40" rx="4" fill="#50C878"/>
              <text x="210" y="35" text-anchor="middle" font-size="11" fill="white">n × L<tspan baseline-shift="sub" font-size="8">test</tspan></text>

              <!-- Equals -->
              <text x="290" y="35" font-size="24" fill="#1a1a2e">=</text>

              <!-- EDL box -->
              <rect x="320" y="0" width="160" height="60" rx="4" fill="#D97757"/>
              <text x="400" y="25" text-anchor="middle" font-size="14" fill="white" font-weight="bold">EDL</text>
              <text x="400" y="45" text-anchor="middle" font-size="10" fill="white">(bits that generalize)</text>
            </g>

            <text x="300" y="125" text-anchor="middle" font-size="11" fill="#666" font-style="italic">EDL = the information the model actually learned—what it couldn't have predicted without training</text>
          </g>
        </svg>
        <p class="illustration-caption">EDL measures the difference: how many bits Alice needs to send to Bob without the trained model vs. with it. This difference is exactly what the model learned.</p>
      </div>

      <!-- Visualization 2: MDL/EDL Decomposition -->
      <div class="visualization" id="viz-edl-decomp">
        <div class="viz-title">The MDL/EDL Decomposition</div>
        <div class="viz-subtitle">See how MDL decomposes into EDL (learned information) and residual (test loss × n).</div>
        <div class="viz-container" id="edl-decomp-chart"></div>
        <div class="viz-controls">
          <div class="toggle-group">
            <button id="show-mdl" class="active">Show MDL</button>
            <button id="show-edl">Show EDL</button>
            <button id="show-both">Show Both</button>
          </div>
          <label>Adjust L<sub>test</sub>: <input type="range" id="ltest-slider" min="0.1" max="3" step="0.05" value="0.8"></label>
          <span id="ltest-display">0.80</span>
        </div>
      </div>

      <!-- Visualization: Multi-epoch training -->
      <div class="visualization" id="viz-multi-epoch">
        <div class="viz-title">Training as Information Extraction</div>
        <div class="viz-subtitle">The dataset is an information source (MDL). Training extracts generalizable information (EDL). More epochs can increase extraction, but can't add information beyond what's in the data.</div>
        <div style="display: flex; justify-content: center; gap: 3rem; margin: 0.75rem 0; padding: 0.6rem 1.5rem; background: #f8f6f3; border-radius: 8px;">
          <div style="text-align: center;">
            <div style="font-size: 0.8rem; color: #888; text-transform: uppercase; letter-spacing: 0.05em;">MDL (bits in data)</div>
            <div style="display: flex; align-items: center; justify-content: center; gap: 0.4rem; margin-top: 0.2rem;">
              <span style="display: inline-block; width: 14px; height: 14px; background: rgba(232, 155, 126, 0.5); border-radius: 2px;"></span>
              <span id="mdl-total" style="font-size: 1.6rem; font-weight: 600; color: #c07050; font-variant-numeric: tabular-nums;">0</span>
            </div>
          </div>
          <div style="text-align: center;">
            <div style="font-size: 0.8rem; color: #888; text-transform: uppercase; letter-spacing: 0.05em;">EDL (bits learned)</div>
            <div style="display: flex; align-items: center; justify-content: center; gap: 0.4rem; margin-top: 0.2rem;">
              <span style="display: inline-block; width: 14px; height: 14px; background: #D97757; border-radius: 2px;"></span>
              <span id="edl-total" style="font-size: 1.6rem; font-weight: 600; color: #D97757; font-variant-numeric: tabular-nums;">0</span>
            </div>
          </div>
        </div>
        <div class="viz-container" id="multi-epoch-chart"></div>
        <div class="viz-controls">
          <button id="epoch-play">Play Training</button>
          <label>Step: <span id="step-display">0</span> / 500</label>
          <input type="range" id="step-slider" min="0" max="500" value="0" step="5">
        </div>
      </div>
    </section>

    <section id="why-this-works">
      <h3>Why This Works</h3>

      <p>Learning is compression. When a model learns a pattern, it can predict future instances of that pattern with lower loss, meaning fewer bits needed to encode them.</p>

      <p>A model that has learned "numbers sum according to arithmetic" can encode "23 + 45 = 68" very cheaply. A model that treats each arithmetic fact as an arbitrary association needs many bits per fact.</p>

      <p>EDL captures exactly this: it measures how much the model's predictions improved through learning, expressed in the natural currency of information theory—bits.</p>
      
      <p>EDL also captures the learning dynamics. As the model learns, its predictions improve, so the bits needed to encode new labels decrease. The rate of this decrease reflects how quickly the model is learning generalizable patterns.</p>

      <p>Crucially, EDL separates generalization from memorization. A model that memorizes the training set achieves low training loss but high test loss, so EDL remains small because L<sub>test</sub> is large. Only patterns that transfer to held-out data contribute to EDL.</p>

      <p>In this way, EDL provides a more nuanced view of model performance and learning than traditional metrics. It highlights the importance of generalization and the ability to apply learned knowledge to new situations, rather than simply memorizing the training data. It emphasizes that efficient learners achieve better compression by leveraging learned complexity—existing knowledge—to reduce the bits needed for learning.</p>
    </section>

    <section id="note-on-loss">
      <h3>A Note on Loss</h3>

      <p>Log-loss is a natural choice for measuring the information content of training data and the learning process. It has a clear interpretation in terms of bits, and it directly reflects the model's uncertainty about the training labels.</p>

      <p>However, it's important to recognize that log-loss is not a perfect proxy for all capabilities we care about. Most metrics we might want to use are not differentiable, and we may not even be able to express them quantitatively, anyway. Log-loss is often the best proxy we have.</p>

      <p>Natural language tasks can have many "correct" responses—different phrasings that correspond to the same answer—and the dataset selects one of these as the label. For tasks with multiple valid responses, the dataset's choice of "ground truth" can introduce noise, meaning that low loss doesn't always correspond to high performance on the underlying task—or the actual capability we want to assess. In such cases, EDL may not perfectly capture the emergence of capabilities that are not well-aligned with the specific labels used during training.</p>

      <!-- <p>Natural language tasks can have many "correct" responses—different phrasings that correspond to the same answer—and the dataset selects one of these as the label. This choice of "ground truth" means that labels are noisy (they don't fully match the true distribution of correct responses), and that loss doesn't always closely track the behaviors we care about.</p> -->

      <p>We want to emphasize that loss and EDL, respectively, measure <em>information</em> and <em>information learned</em> (compression) with respect to a <em>specific distribution</em>; they are not direct measures of <em>capability itself</em>. We measure loss (and EDL) because we hope it tracks well with metrics we <em>do</em> care about for meaningful capability learned, not because it <em>is</em> the metric we care about.</p>

      <p>Despite these limitations, log-loss and EDL remain valuable tools for quantifying learning dynamics and generalization in language models. They provide a consistent framework for measuring how much information a model has absorbed from its training data, even if it doesn't capture every nuance of capability development.</p>


    <h2>More Is Different</h2>

    <section id="emergence">
      <p>In 1972, Philip Anderson argued that the reductionist program in physics—explaining everything by decomposing it into fundamental parts—misses something essential. "The ability to reduce everything to simple fundamental laws," he wrote, "does not imply the ability to start from those laws and reconstruct the universe." At every level of scale and organization, new properties appear that are qualitatively different from anything present at the level below. Superfluidity cannot be predicted from the quantum mechanics of individual helium atoms. Consciousness does not follow from neuron firing rates. The whole is not merely the sum of its parts—<em>more is different</em>.</p>

      <p>This insight—that complexity at one scale gives rise to qualitatively new phenomena at another—is the principle of <strong>emergence</strong>. And it turns out to be central to understanding what language models learn.</p>

      <h3>Emergence in Language Models</h3>

      <p>Emergence is the process by which scale produces complexity. As a model processes more data, it can develop more complex internal representations. These representations can capture abstract patterns and algorithms that are not fully encapsulated in any single training example but emerge from the collective of many different ones.</p>

      <p>Consider what happens during pretraining. A model processes billions of tokens, each one a local observation: a word following other words. No single token teaches the model arithmetic. No single paragraph teaches it to reason about code, or to translate between languages, or to write poetry. But collectively, at scale, these local patterns give rise to capabilities that are qualitatively different from anything present in any individual training example. The model develops internal representations that capture abstract structure: algorithms, conceptual relationships, reasoning strategies. These are emergent phenomena of the training process—they arise from the collective interaction of vast amounts of data with the model's parameters, and they cannot be understood by examining any single component in isolation.</p>

      <p>This is Anderson's principle, instantiated in a neural network. <em>More is different</em>: more data, more parameters, more layers, more computation produce capabilities that are not simply "more of the same" but something qualitatively new.</p>

      <h3>The Complexity of Capabilities</h3>

      <p>In algorithmic information theory, the <em>complexity</em> of a system is the length of its shortest description. More complex systems require longer descriptions—more bits to specify.</p>

      <p>We can evaluate any system in terms of its complexity, regardless of what that system is or how it manifests. Functions, computer programs, humans, rocks, the universe, and—most relevant for our experiments here—models and capabilities all<sup>[5]</sup> have their own respective complexities, determined by what components they're composed of and how those components interact.<sup>[6]</sup></p>

      <p>As a visual example, consider the complexities of systems with two degrees of freedom, shape and color:</p>

      <!-- Complexity comparison diagram -->
      <div class="illustration">
        <svg viewBox="0 0 800 220" style="max-width: 900px; width: 100%; height: auto;">
          <!-- System A: 25 blue circles -->
          <g transform="translate(20, 10)">
            <rect x="0" y="0" width="350" height="200" rx="8" fill="#f6f9fe" stroke="#4A90D9" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="175" y="25" text-anchor="middle" font-size="13" font-weight="600" fill="#1a1a2e">System A: 25 blue circles</text>

            <!-- 5x5 grid of blue circles -->
            <g transform="translate(30, 40)">
              <!-- Row 1 -->
              <circle cx="0" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="0" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="0" r="10" fill="#4A90D9"/>
              <!-- Row 2 -->
              <circle cx="0" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="28" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="28" r="10" fill="#4A90D9"/>
              <!-- Row 3 -->
              <circle cx="0" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="56" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="56" r="10" fill="#4A90D9"/>
              <!-- Row 4 -->
              <circle cx="0" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="84" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="84" r="10" fill="#4A90D9"/>
              <!-- Row 5 -->
              <circle cx="0" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="28" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="56" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="84" cy="112" r="10" fill="#4A90D9"/>
              <circle cx="112" cy="112" r="10" fill="#4A90D9"/>
            </g>

            <!-- Arrow -->
            <path d="M 170 100 L 210 100" stroke="#666" stroke-width="2"/>
            <polygon points="210,100 200,94 200,106" fill="#666"/>

            <!-- Compressed description -->
            <g transform="translate(225, 65)">
              <rect x="0" y="0" width="100" height="70" rx="6" fill="#F0EDE8" stroke="#E0DCD5"/>
              <circle cx="30" cy="35" r="14" fill="#4A90D9"/>
              <text x="55" y="40" font-size="16" fill="#1a1a2e" font-weight="500">× 25</text>
            </g>
            <text x="275" y="160" text-anchor="middle" font-size="11" fill="#50C878" font-weight="500">Short description</text>
          </g>

          <!-- System B: Four different shapes -->
          <g transform="translate(400, 10)">
            <rect x="0" y="0" width="380" height="200" rx="8" fill="#fef9f6" stroke="#D97757" stroke-width="1" stroke-dasharray="4,2"/>
            <text x="190" y="25" text-anchor="middle" font-size="13" font-weight="600" fill="#1a1a2e">System B: 4 distinct shapes</text>

            <!-- Four shapes in a row -->
            <g transform="translate(40, 50)">
              <!-- Red square -->
              <rect x="0" y="8" width="28" height="28" rx="2" fill="#D97757"/>
              <!-- Blue circle -->
              <circle cx="80" cy="22" r="16" fill="#4A90D9"/>
              <!-- Green triangle -->
              <polygon points="145,38 160,6 175,38" fill="#50C878"/>
              <!-- Yellow rhombus -->
              <polygon points="235,6 255,22 235,38 215,22" fill="#E8A838"/>
            </g>

            <!-- Arrow down -->
            <path d="M 190 100 L 190 120" stroke="#666" stroke-width="2"/>
            <polygon points="190,120 184,110 196,110" fill="#666"/>

            <!-- Long description -->
            <g transform="translate(50, 130)">
              <rect x="0" y="0" width="280" height="50" rx="6" fill="#F0EDE8" stroke="#E0DCD5"/>
              <text x="140" y="22" text-anchor="middle" font-size="10" fill="#1a1a2e">red square, blue circle,</text>
              <text x="140" y="38" text-anchor="middle" font-size="10" fill="#1a1a2e">green triangle, yellow rhombus</text>
            </g>
            <text x="190" y="198" text-anchor="middle" font-size="11" fill="#c66" font-weight="500">Long description</text>
          </g>
        </svg>
        <p class="illustration-caption">System A contains more objects but has a shorter description—it is less complex. System B requires specifying each shape and color individually.</p>
      </div>

      <p>System A contains more objects but is less complex.<sup>[7]</sup> We can say "25 blue circles" instead of describing each one—we can compress it so that its description is shorter. System B contains fewer objects, but we have to specify each shape and color individually—we can't compress it further. It's more complex.</p>
      
      <p>The complexity of a system is not just about how many components it has, but how those components are structured and how much information is needed to describe them.</p>

      <p>The same principle applies to capabilities. A model that has learned the algorithm for addition has a compact representation that covers infinitely many arithmetic facts. A model that sees addition as individual facts to memorize needs a separate entry for each one—incompressible, high complexity.</p>

      <p>When capabilities emerge during training, the associated complexity gets encoded in the model's parameters. There's a “no free lunch” principle at work: models cannot acquire capabilities without, at some point, paying the information cost to encode them.</p>

      <p>This cost might be paid during pretraining, during fine-tuning or RLHF, or during in-context learning. But it must be paid somewhere.</p>

      <h3>Where Emergence Meets Elicitation</h3>

      <p>Here is where Anderson's principle connects to the central question of this work.</p>

      <p>During pretraining, "more is different": scale and complexity produce emergent capabilities—complex internal representations that couldn't exist in a smaller model, a simpler architecture, or with less data. These emergent capabilities have a measurable <em>complexity</em>, an information cost that was paid during pretraining.</p>

      <p>The question we ask is: <em>what happens when we fine-tune?</em> Is the model surfacing complexity that already exists in its weights, or is it building new complexity from scratch?</p>

      <p>When the relevant complexity is already present—when the capability is emergent—the model doesn't need to reconstruct it. It only needs a small signal that says, in effect, "use <em>this</em> capability for <em>this</em> task." This is <em><strong>elicitation</strong></em>: adapting emergent structure that already exists. The information cost is low, because the complexity was already paid for.</p>

      <p>When the relevant complexity is absent—when the capability never emerged during pretraining—the model must build it during fine-tuning. It must pay the full information cost of constructing new representations. This is <em><strong>teaching</strong></em>: creating complexity that doesn't yet exist. The information cost is high, because emergence hasn't happened yet.</p>

      <p>Our section titles are a nod to the interplay between these ideas. Anderson's "more is different" describes how scale creates emergence. The scaling-era mantra, "scale is all you need,"<sup>[*]</sup> emphasizes the power of more data, more parameters, and more compute. We find that both need qualification. When emergent complexity already exists, <strong>"less is all you need"</strong>—remarkably little information suffices to surface it. When it doesn't, <strong>"more is necessary"</strong>—you can't shortcut the information cost of building complexity from scratch.</p>

      <p>EDL measures this cost. And the scaling of EDL with data reveals which learning mechanism—elicitation or teaching—governs the dynamics we observe.</p>

      <p>In the sections that follow, we frame our findings through the lens of two learning mechanisms: elicitation (surfacing existing capability) and teaching (building new capability). These map naturally onto the way practitioners and safety researchers think about fine-tuning today, and they serve as useful intuition pumps for the kinds of capabilities and models we study here. But we want to be upfront: we think this dichotomy, taken literally, is probably not the fundamental distinction. What ultimately matters is not why a model needs a certain amount of information to demonstrate a capability, but how much information it needs. The teaching/elicitation framework is a useful lens for understanding today's models. The information-theoretic measurement—EDL, expressed in bits—is what will generalize to tomorrow's.</p>

      <div class="scale-footnote">
        <p><sup>[*]</sup> Originally "Attention Is All You Need," now a template applied to whatever the speaker believes is the key ingredient.</p>
      </div>
    </section>

    <h2>Dynamical Signatures of Elicitation and Teaching</h2>

    <section id="signatures">
      <p>When we plot EDL per token against the number of training examples, we see qualitatively different patterns depending on the dominant learning process at a given dataset size. These patterns tell us something more fundamental than which mechanism of learning is occurring. They tell us how the information economics of learning are changing—whether additional data are becoming more or less valuable at each point in training.</p>

      <h3>Elicitation: Monotonically Decreasing</h3>

      <p>For models with latent capabilities, EDL per token decreases monotonically as we add training examples.</p>

      <p>The first example may be highly informative, aligning a model's outputs to the desired response format and reducing uncertainty about which of its capabilities are relevant for the task. ("Oh, you want me to output numbers in this format for arithmetic problems.") But subsequent examples add less and less. The model already knows arithmetic; additional examples just confirm what it already knows. There is no new algorithmic information to be learned.</p>

      <!-- Elicitation cartoon: uncertainty collapse with specific hypotheses -->
      <div class="illustration">
        <svg viewBox="0 0 920 300" style="max-width: 920px; width: 100%; height: auto;">
          <!-- Stage 1: Prompt with many possible responses -->
          <g transform="translate(15, 10)">
            <text x="105" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">Prompt: "23 + 45 ="</text>

            <!-- Prompt box -->
            <rect x="35" y="22" width="140" height="32" rx="6" fill="#1a1a2e"/>
            <text x="105" y="43" text-anchor="middle" font-size="11" fill="white" font-family="monospace">23 + 45 =</text>

            <!-- Arrow down -->
            <path d="M 105 58 L 105 72" stroke="#666" stroke-width="1.5"/>
            <polygon points="105,76 101,68 109,68" fill="#666"/>

            <!-- Model considering hypotheses label -->
            <text x="105" y="92" text-anchor="middle" font-size="9" fill="#666">Model's output distribution:</text>

            <!-- Hypothesis bars - all bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" text-anchor="end">"68"</text>
              <rect x="70" y="2" width="65" height="12" rx="2" fill="#D97757"/>
              <text x="140" y="11" font-size="8" fill="#666">18%</text>

              <text x="65" y="27" font-size="9" fill="#1a1a2e" text-anchor="end">"...is even"</text>
              <rect x="70" y="18" width="50" height="12" rx="2" fill="#4A90D9"/>
              <text x="125" y="27" font-size="8" fill="#666">14%</text>

              <text x="65" y="43" font-size="9" fill="#1a1a2e" text-anchor="end">"...problem"</text>
              <rect x="70" y="34" width="40" height="12" rx="2" fill="#50C878"/>
              <text x="115" y="43" font-size="8" fill="#666">11%</text>

              <text x="65" y="59" font-size="9" fill="#1a1a2e" text-anchor="end">"...÷ by 4"</text>
              <rect x="70" y="50" width="32" height="12" rx="2" fill="#E8A838"/>
              <text x="107" y="59" font-size="8" fill="#666">9%</text>

              <text x="65" y="75" font-size="9" fill="#999" text-anchor="end">"= 14"</text>
              <rect x="70" y="66" width="4" height="12" rx="2" fill="#ccc"/>
              <text x="79" y="75" font-size="8" fill="#999">1%</text>

              <text x="65" y="91" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="82" width="20" height="12" rx="2" fill="#ccc" opacity="0.5"/>
            </g>

            <text x="105" y="210" text-anchor="middle" font-size="8" fill="#666" font-style="italic">Many valid completions</text>
          </g>

          <!-- Arrow: sees target output -->
          <g transform="translate(160, 120)">
            <path d="M 0 15 L 40 15" stroke="#D97757" stroke-width="2"/>
            <polygon points="45,15 37,10 37,20" fill="#D97757"/>
            <text x="22" y="40" text-anchor="middle" font-size="9" fill="#D97757" font-weight="600">Label: "68"</text>
          </g>

          <!-- Stage 2: After seeing example -->
          <g transform="translate(220, 10)">
            <text x="95" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">After 1 example</text>

            <!-- Updated probability bars - all bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" font-weight="600" text-anchor="end">"68"</text>
              <rect x="70" y="2" width="115" height="12" rx="2" fill="#D97757"/>
              <text x="190" y="11" font-size="8" fill="#666">92%</text>

              <text x="65" y="27" font-size="9" fill="#999" text-anchor="end">"...is even"</text>
              <rect x="70" y="18" width="6" height="12" rx="2" fill="#4A90D9" opacity="0.3"/>

              <text x="65" y="43" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="34" width="8" height="12" rx="2" fill="#ccc" opacity="0.3"/>
            </g>

            <!-- Insight box -->
            <rect x="5" y="160" width="180" height="50" rx="6" fill="#D97757" fill-opacity="0.1" stroke="#D97757"/>
            <text x="95" y="176" text-anchor="middle" font-size="9" fill="#1a1a2e" font-weight="600">"Oh! You want the numeric</text>
            <text x="95" y="189" text-anchor="middle" font-size="9" fill="#1a1a2e" font-weight="600">answer, not a description."</text>
            <text x="95" y="202" text-anchor="middle" font-size="8" fill="#666">Uncertainty collapsed</text>
          </g>

          <!-- Arrow: next example -->
          <g transform="translate(415, 120)">
            <path d="M 0 15 L 40 15" stroke="#50C878" stroke-width="2"/>
            <polygon points="45,15 37,10 37,20" fill="#50C878"/>
            <text x="22" y="40" text-anchor="middle" font-size="9" fill="#50C878">new prompt</text>
          </g>

          <!-- Stage 3: On new problem, immediately correct -->
          <g transform="translate(475, 10)">
            <text x="95" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">Prompt: "17 + 29 ="</text>

            <!-- New prompt box -->
            <rect x="25" y="22" width="140" height="32" rx="6" fill="#1a1a2e"/>
            <text x="95" y="43" text-anchor="middle" font-size="11" fill="white" font-family="monospace">17 + 29 =</text>

            <!-- Arrow down -->
            <path d="M 95 58 L 95 72" stroke="#666" stroke-width="1.5"/>
            <polygon points="95,76 91,68 99,68" fill="#666"/>

            <!-- Immediately correct distribution - bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" font-weight="600" text-anchor="end">"46"</text>
              <rect x="70" y="2" width="122" height="12" rx="2" fill="#50C878"/>
              <text x="197" y="11" font-size="8" fill="#666">98%</text>

              <text x="65" y="27" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="18" width="3" height="12" rx="2" fill="#ccc" opacity="0.3"/>
            </g>

            <!-- Success indicator -->
            <g transform="translate(15, 160)">
              <rect x="0" y="0" width="160" height="50" rx="6" fill="#50C878"/>
              <text x="80" y="22" text-anchor="middle" font-size="13" fill="white" font-weight="600">"46" ✓</text>
              <text x="80" y="40" text-anchor="middle" font-size="9" fill="white">One example was enough!</text>
            </g>
          </g>

          <!-- Stage 4: Diminishing returns -->
          <g transform="translate(695, 10)">
            <text x="95" y="12" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">After 10 examples</text>

            <!-- Nearly identical distribution - bars left-justified at x=70 -->
            <g transform="translate(0, 100)">
              <text x="65" y="11" font-size="9" fill="#1a1a2e" font-weight="600" text-anchor="end">"[answer]"</text>
              <rect x="70" y="2" width="124" height="12" rx="2" fill="#50C878"/>
              <text x="199" y="11" font-size="8" fill="#666">99%</text>

              <text x="65" y="27" font-size="9" fill="#999" text-anchor="end">other</text>
              <rect x="70" y="18" width="2" height="12" rx="2" fill="#ccc" opacity="0.3"/>
            </g>

            <!-- Diminishing returns box -->
            <rect x="5" y="160" width="180" height="50" rx="6" fill="#f0f0f0" stroke="#ccc"/>
            <text x="95" y="175" text-anchor="middle" font-size="9" fill="#666">Already at 98% → 99%</text>
            <text x="95" y="189" text-anchor="middle" font-size="9" fill="#666" font-weight="600">Diminishing returns!</text>
            <text x="95" y="202" text-anchor="middle" font-size="8" fill="#999">EDL/token decreases</text>
          </g>
        </svg>
        <p class="illustration-caption">Elicitation: The model knows many things about "23+45." The first example collapses uncertainty about which capability to use. Additional examples provide diminishing information because the distribution is already near the target.</p>
      </div>

      <p>This EDL signature of diminishing returns is associated with elicitation: each example provides less marginal information than the last. The data are redundant—each new example is approximately interchangeable with any other, and the sum of their contributions is well-approximated by any small subset.</p>

      <h3>Teaching: Monotonically Increasing</h3>

      <p>When models learn new capabilities—when emergence is happening during fine-tuning—EDL per token <em>increases</em> as we add examples.</p>

      <p>Early in training, the model lacks the representations to identify any pattern. Each example is an isolated data point, essentially noise. The model can extract almost no generalizable information. The complexity of the task (and the capabilities required for it) is vastly larger than the amount of information contained in the data the model has received so far.</p>

      <p>But as examples accumulate, the model begins to form useful representations. It starts to see structure in the data. Each new example doesn't just add one more fact—it makes the entire dataset more informative as a <em>whole</em>, because the model can now recognize patterns in earlier examples that it previously missed. The model is learning how to learn from this data.</p>

      <p>This EDL signature of increasing returns is associated with teaching: each example enables the extraction of more information from all previous examples. The data are <em>synergistic</em>—the collective dataset is more informative than the sum of its individual examples, and each new example amplifies the value of the whole. This is emergence at the level of how data informs learning: the whole is different than the sum of its parts.</p>

      <p>What matters here is not the label "teaching" per se, but the measurable fact that each example effectively compresses more bits of the training dataset than the last. The information cost of this capability is being paid incrementally as increasing complexity is absorbed from the data.</p>

      <!-- Teaching cartoon: shapes and colors pattern learning with backfilling -->
      <div class="illustration">
        <svg viewBox="0 0 900 540" style="max-width: 900px; width: 100%; height: auto;">
          <!-- Task description -->
          <g transform="translate(450, 10)">
            <text x="0" y="0" text-anchor="middle" font-size="12" font-weight="600" fill="#1a1a2e">Task: Learn to predict colors from shapes</text>
            <text x="0" y="14" text-anchor="middle" font-size="9" fill="#666">(True rule: curved → red, straight edges only → blue)</text>
          </g>

          <!-- Stage 1: One example -->
          <g transform="translate(15, 40)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#1a1a2e">Example 1</text>
            <rect x="10" y="10" width="140" height="55" rx="5" fill="#F0EDE8" stroke="#E0DCD5"/>
            <rect x="55" y="28" width="20" height="20" fill="#4A90D9" stroke="#2E6BA6"/>
            <text x="85" y="42" font-size="9" fill="#1a1a2e">→ blue</text>

            <rect x="10" y="72" width="140" height="40" rx="5" fill="#fff" stroke="#ccc"/>
            <text x="80" y="88" text-anchor="middle" font-size="8" fill="#666">Hypothesis:</text>
            <text x="80" y="102" text-anchor="middle" font-size="9" fill="#1a1a2e">"All shapes = blue"</text>
            <text x="80" y="125" text-anchor="middle" font-size="9" fill="#999">EDL: ~0 bits</text>
          </g>

          <!-- Arrow 1 -->
          <g transform="translate(165, 75)">
            <path d="M 0 0 L 25 0" stroke="#666" stroke-width="1.5"/>
            <polygon points="28,0 22,-4 22,4" fill="#666"/>
          </g>

          <!-- Stage 2: Two examples -->
          <g transform="translate(200, 40)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#1a1a2e">Example 2</text>
            <rect x="10" y="10" width="140" height="55" rx="5" fill="#F0EDE8" stroke="#E0DCD5"/>
            <rect x="30" y="30" width="16" height="16" fill="#4A90D9" stroke="#2E6BA6" opacity="0.5"/>
            <circle cx="100" cy="38" r="10" fill="#D97757" stroke="#B85A3C"/>
            <text x="120" y="42" font-size="9" fill="#1a1a2e">→ red</text>

            <rect x="10" y="72" width="140" height="40" rx="5" fill="#fff" stroke="#E8A838"/>
            <text x="80" y="88" text-anchor="middle" font-size="8" fill="#666">Hypothesis:</text>
            <text x="80" y="102" text-anchor="middle" font-size="9" fill="#1a1a2e">"Circles = red, else blue"</text>
            <text x="80" y="125" text-anchor="middle" font-size="9" fill="#E8A838">EDL: rising ↑</text>
          </g>

          <!-- Arrow 2 -->
          <g transform="translate(350, 75)">
            <path d="M 0 0 L 25 0" stroke="#666" stroke-width="1.5"/>
            <polygon points="28,0 22,-4 22,4" fill="#666"/>
          </g>

          <!-- Stage 3: Three examples with AHA moment -->
          <g transform="translate(385, 40)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#50C878">Example 3 - Aha!</text>
            <rect x="10" y="10" width="140" height="55" rx="5" fill="#F0EDE8" stroke="#50C878" stroke-width="2"/>
            <rect x="22" y="27" width="14" height="14" fill="#4A90D9" stroke="#2E6BA6" opacity="0.5"/>
            <circle cx="60" cy="34" r="9" fill="#D97757" stroke="#B85A3C" opacity="0.5"/>
            <ellipse cx="95" cy="34" rx="14" ry="9" fill="#D97757" stroke="#B85A3C"/>
            <text x="116" y="38" font-size="9" fill="#1a1a2e">→ red!</text>

            <rect x="10" y="72" width="140" height="40" rx="5" fill="#50C878" fill-opacity="0.1" stroke="#50C878" stroke-width="2"/>
            <text x="80" y="88" text-anchor="middle" font-size="8" fill="#1a1a2e" font-weight="600">Pattern found:</text>
            <text x="80" y="102" text-anchor="middle" font-size="9" fill="#1a1a2e">"Curved = red!"</text>
            <text x="80" y="125" text-anchor="middle" font-size="9" fill="#50C878" font-weight="600">EDL: peaks! ↑↑</text>
          </g>

          <!-- Arrow 3 -->
          <g transform="translate(535, 75)">
            <path d="M 0 0 L 25 0" stroke="#666" stroke-width="1.5"/>
            <polygon points="28,0 22,-4 22,4" fill="#666"/>
          </g>

          <!-- Stage 4: Pattern complete -->
          <g transform="translate(570, 40)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#1a1a2e">Generalized</text>
            <rect x="10" y="10" width="140" height="100" rx="5" fill="#50C878" fill-opacity="0.1" stroke="#50C878"/>
            <text x="80" y="30" text-anchor="middle" font-size="9" fill="#1a1a2e" font-weight="600">Learned rule:</text>
            <circle cx="45" cy="52" r="10" fill="#D97757" stroke="#B85A3C"/>
            <ellipse cx="85" cy="52" rx="12" ry="8" fill="#D97757" stroke="#B85A3C"/>
            <text x="115" y="56" font-size="9" fill="#1a1a2e">= red</text>
            <rect x="35" y="72" width="15" height="15" fill="#4A90D9" stroke="#2E6BA6"/>
            <polygon points="85,87 75,72 95,72" fill="#4A90D9" stroke="#2E6BA6"/>
            <text x="115" y="83" font-size="9" fill="#1a1a2e">= blue</text>
          </g>

          <!-- More examples (diminishing returns in teaching) -->
          <g transform="translate(720, 40)">
            <text x="80" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#999">Example 4+</text>
            <rect x="10" y="10" width="160" height="100" rx="5" fill="#f5f5f5" stroke="#ccc"/>
            <text x="90" y="40" text-anchor="middle" font-size="9" fill="#666">Pattern already learned</text>
            <text x="90" y="55" text-anchor="middle" font-size="9" fill="#666">New examples just confirm</text>
            <text x="90" y="80" text-anchor="middle" font-size="9" fill="#999">EDL/token: decreasing</text>
            <text x="90" y="95" text-anchor="middle" font-size="8" fill="#999">(now eliciting)</text>
          </g>

          <!-- BACKFILLING VISUALIZATION -->
          <!-- Examples above are at: Ex1@80, Ex2@265, Ex3@450 (relative to this g which is at x=15) -->
          <g transform="translate(15, 175)">
            <rect x="0" y="0" width="870" height="150" rx="8" fill="#fff8f5" stroke="#D97757" stroke-width="1"/>
            <text x="435" y="18" text-anchor="middle" font-size="11" font-weight="600" fill="#D97757">The "Backfilling" Effect: New patterns unlock information in past data</text>

            <!-- Column headers aligned with examples above -->
            <g transform="translate(0, 30)">
              <text x="80" y="12" text-anchor="middle" font-size="8" fill="#666">After Ex 1</text>
              <text x="265" y="12" text-anchor="middle" font-size="8" fill="#666">After Ex 2</text>
              <text x="450" y="12" text-anchor="middle" font-size="8" fill="#50C878" font-weight="600">After Ex 3 (pattern!)</text>
            </g>

            <!-- Row labels and bars - columns centered at 80, 265, 450 -->
            <g transform="translate(0, 48)">
              <!-- Info from Ex1 row -->
              <text x="10" y="10" font-size="9" fill="#1a1a2e" font-weight="600">Info from Ex1:</text>
              <rect x="75" y="0" width="10" height="14" rx="2" fill="#4A90D9" opacity="0.3"/>
              <rect x="240" y="0" width="22" height="14" rx="2" fill="#4A90D9" opacity="0.5"/>
              <text x="265" y="10" font-size="6" fill="#666">"square→blue"</text>
              <rect x="425" y="0" width="55" height="14" rx="2" fill="#4A90D9"/>
              <text x="485" y="10" font-size="6" fill="#50C878">"angular → blue!"</text>

              <!-- Info from Ex2 row -->
              <text x="10" y="30" font-size="9" fill="#1a1a2e" font-weight="600">Info from Ex2:</text>
              <text x="80" y="30" font-size="8" fill="#ccc">—</text>
              <rect x="240" y="20" width="25" height="14" rx="2" fill="#D97757" opacity="0.5"/>
              <text x="270" y="30" font-size="6" fill="#666">"circle→red"</text>
              <rect x="425" y="20" width="60" height="14" rx="2" fill="#D97757"/>
              <text x="490" y="30" font-size="6" fill="#50C878">"curved → red!"</text>

              <!-- Info from Ex3 row -->
              <text x="10" y="50" font-size="9" fill="#1a1a2e" font-weight="600">Info from Ex3:</text>
              <text x="80" y="50" font-size="8" fill="#ccc">—</text>
              <text x="265" y="50" font-size="8" fill="#ccc">—</text>
              <rect x="425" y="40" width="45" height="14" rx="2" fill="#D97757"/>
              <text x="475" y="50" font-size="6" fill="#666">(new example)</text>

              <!-- EDL per example row (bottom) -->
              <text x="10" y="75" font-size="9" fill="#1a1a2e" font-weight="600">EDL per ex:</text>
              <rect x="75" y="65" width="10" height="14" rx="2" fill="#ccc"/>
              <text x="90" y="75" font-size="7" fill="#999">~0</text>
              <rect x="240" y="65" width="30" height="14" rx="2" fill="#E8A838"/>
              <text x="275" y="75" font-size="7" fill="#E8A838">rising</text>
              <rect x="425" y="65" width="70" height="14" rx="2" fill="#50C878"/>
              <text x="500" y="75" font-size="7" fill="#50C878" font-weight="600">peak!</text>
            </g>

            <text x="435" y="142" text-anchor="middle" font-size="9" fill="#1a1a2e" font-style="italic">Example 3 didn't just add its own information—it made examples 1 and 2 understandable!</text>
          </g>

          <!-- EDL SLOPE COMPARISON -->
          <g transform="translate(15, 335)">
            <rect x="0" y="0" width="870" height="200" rx="8" fill="#f8f6f3" stroke="#E0DCD5"/>
            <text x="435" y="20" text-anchor="middle" font-size="11" font-weight="600" fill="#1a1a2e">EDL/token vs. Data: Teaching vs. Elicitation Signatures</text>

            <!-- Teaching curve (left) -->
            <g transform="translate(50, 45)">
              <text x="150" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#E8A838">Teaching (building new capability)</text>

              <!-- Axes -->
              <line x1="30" y1="110" x2="270" y2="110" stroke="#ccc" stroke-width="1"/>
              <line x1="30" y1="110" x2="30" y2="20" stroke="#ccc" stroke-width="1"/>
              <text x="150" y="130" text-anchor="middle" font-size="8" fill="#666">Number of examples →</text>
              <text x="10" y="65" text-anchor="middle" font-size="8" fill="#666" transform="rotate(-90, 10, 65)">EDL/token</text>

              <!-- Curve: starts low, rises, then may fall -->
              <path d="M 30 100 Q 80 95 120 70 Q 160 50 200 45 Q 230 42 260 50" fill="none" stroke="#E8A838" stroke-width="2.5"/>

              <!-- Slope indicator -->
              <path d="M 80 90 L 140 60" stroke="#E8A838" stroke-width="1" stroke-dasharray="3,2"/>
              <text x="90" y="60" font-size="8" fill="#E8A838" font-weight="600">slope > 0</text>

              <!-- Annotations -->
              <circle cx="50" cy="97" r="3" fill="#E8A838"/>
              <text x="50" y="90" text-anchor="middle" font-size="7" fill="#E8A838">low info</text>
              <circle cx="200" cy="45" r="3" fill="#50C878"/>
              <text x="200" y="38" text-anchor="middle" font-size="7" fill="#50C878">pattern found!</text>
            </g>

            <!-- Elicitation curve (right) -->
            <g transform="translate(480, 45)">
              <text x="150" y="0" text-anchor="middle" font-size="10" font-weight="600" fill="#4A90D9">Elicitation (surfacing existing capability)</text>

              <!-- Axes -->
              <line x1="30" y1="110" x2="270" y2="110" stroke="#ccc" stroke-width="1"/>
              <line x1="30" y1="110" x2="30" y2="20" stroke="#ccc" stroke-width="1"/>
              <text x="150" y="130" text-anchor="middle" font-size="8" fill="#666">Number of examples →</text>
              <text x="10" y="65" text-anchor="middle" font-size="8" fill="#666" transform="rotate(-90, 10, 65)">EDL/token</text>

              <!-- Curve: starts high, falls -->
              <path d="M 30 35 Q 80 50 120 70 Q 160 85 200 95 Q 240 100 270 102" fill="none" stroke="#4A90D9" stroke-width="2.5"/>

              <!-- Slope indicator -->
              <path d="M 60 45 L 140 75" stroke="#4A90D9" stroke-width="1" stroke-dasharray="3,2"/>
              <text x="105" y="55" font-size="8" fill="#4A90D9" font-weight="600">slope < 0</text>

              <!-- Annotations -->
              <circle cx="50" cy="40" r="3" fill="#4A90D9"/>
              <text x="50" y="32" text-anchor="middle" font-size="7" fill="#4A90D9">high info</text>
              <circle cx="250" cy="100" r="3" fill="#999"/>
              <text x="250" y="115" text-anchor="middle" font-size="7" fill="#666">diminishing</text>
            </g>

            <text x="435" y="190" text-anchor="middle" font-size="9" fill="#1a1a2e" font-style="italic">Teaching: each example makes past data more informative. Elicitation: each example is less novel than the last.</text>
          </g>
        </svg>
        <p class="illustration-caption">Teaching builds new representations. The key insight: Example 3 doesn't just add information—it retroactively makes Examples 1 and 2 understandable. This "backfilling" is why EDL per label token increases during teaching.</p>
      </div>

      <!-- <p>This is the EDL signature of teaching: <em>increasing returns to data</em>. Each example enables extraction of more information from all previous examples.</p> -->

            <!-- Visualization 3: The Two Signatures -->
      <div class="visualization" id="viz-signatures">
        <div class="viz-title">The Two Signatures</div>
        <div class="viz-subtitle">Compare how EDL per token scales with dataset size for elicitation (Llama 3.2 1B) vs teaching (TinyStories-1B) when we fine-tune on multiplication problems from the DeepMind Mathematics dataset.</div>
        <div class="viz-container" id="signatures-chart"></div>
        <div class="viz-controls">
          <div class="toggle-group">
            <button id="sig-llama" class="active">Llama (Elicitation)</button>
            <button id="sig-tiny" class="active">TinyStories (Teaching)</button>
          </div>

        </div>
      </div>

      <h3>Visualizing the Backfilling Effect</h3>

      <p>The geometry behind synergistic and redundant learning is surprisingly simple.</p>

      <p>EDL at any point in training equals the area between what the model paid (the train loss on each example before the update) and what the model would pay now (the current test loss, applied to all examples). Think of this as a set of bars—one per training example—each extending from the test loss floor up to the train loss the model incurred on that example.</p>

      <p>When the model learns from a new example and test loss drops, something notable happens: <em>the floor drops for all previous examples simultaneously</em>. Every previous bar extends, not just the new one. This retroactive extension is the backfilling effect, and it's why EDL can grow faster than linearly.</p>

      <div class="visualization backfill-viz" id="viz-backfill">
        <div class="viz-title">The Backfilling Effect</div>
        <div class="viz-subtitle">Each bar represents one training example. When new learning drops the test loss floor, all previous bars extend retroactively. Drag the slider to add examples and watch the bars grow.</div>
        <div class="bf-slider-container">
          <label>
            Training examples:
            <input type="range" id="bf-slider" min="0" max="20" value="0" step="1">
            <span class="bf-count" id="bf-count">0</span> / 20
          </label>
        </div>
        <div class="bf-panels">
          <div class="bf-panel teaching">
            <h4>Synergistic Learning (Teaching)</h4>
            <svg id="bf-svg-teaching" viewBox="0 0 480 320"></svg>
            <div class="bf-metrics">
              <div class="bf-metric">
                <span>Total EDL</span>
                <span class="bf-value" id="bf-edl-teaching">0.00 bits</span>
              </div>
              <div class="bf-metric">
                <span>EDL / token</span>
                <span class="bf-value" id="bf-edl-per-token-teaching">—</span>
                <span class="bf-trend up" id="bf-trend-teaching"></span>
              </div>
              <div class="bf-metric">
                <span>Marginal EDL</span>
                <span class="bf-value" id="bf-marginal-teaching">—</span>
              </div>
            </div>
          </div>
          <div class="bf-panel elicitation">
            <h4>Redundant Learning (Elicitation)</h4>
            <svg id="bf-svg-elicitation" viewBox="0 0 480 320"></svg>
            <div class="bf-metrics">
              <div class="bf-metric">
                <span>Total EDL</span>
                <span class="bf-value" id="bf-edl-elicitation">0.00 bits</span>
              </div>
              <div class="bf-metric">
                <span>EDL / token</span>
                <span class="bf-value" id="bf-edl-per-token-elicitation">—</span>
                <span class="bf-trend down" id="bf-trend-elicitation"></span>
              </div>
              <div class="bf-metric">
                <span>Marginal EDL</span>
                <span class="bf-value" id="bf-marginal-elicitation">—</span>
              </div>
            </div>
          </div>
        </div>
        <div class="bf-legend">
          <div class="bf-legend-item">
            <div class="bf-legend-swatch" style="background: #2d9c6f;"></div>
            <span>Direct compression</span>
          </div>
          <div class="bf-legend-item">
            <div class="bf-legend-swatch" style="background: #6a3d9a;"></div>
            <span>Marginal backfill (this step)</span>
          </div>
          <div class="bf-legend-item">
            <div class="bf-legend-swatch" style="background: #c4b0e0;"></div>
            <span>Accumulated backfill (previous)</span>
          </div>
          <div class="bf-legend-item">
            <div class="bf-legend-swatch" style="background: none; border: 1.5px dashed #888; width: 18px; height: 0; border-radius: 0; align-self: center;"></div>
            <span>Test loss floor</span>
          </div>
        </div>
        <div style="margin-top: 0.75rem; font-size: 0.82rem; line-height: 1.55; color: #555;">
          <p style="margin-bottom: 0.5rem;"><strong style="color: #6a3d9a;">Synergistic learning (<em>left</em>):</strong> When the model learns from a new example and the test loss floor drops, <em>all previous bars extend simultaneously</em>. The dark purple band shows the marginal backfill from the most recent step — it appears on every previous bar at once. The light purple shows accumulated backfill from all prior steps. Retroactive compression dominates: the collective dataset is more informative than the sum of its parts. Once again, <em>more</em> is <em>different.</em></p>
          <p style="margin-bottom: 0.5rem;"><strong style="color: #1a8a6a;">Redundant learning (<em>right</em>):</strong> The floor drops rapidly at first, then barely at all. The marginal backfill band shrinks quickly — later examples barely extend previous bars. Each example is approximately independent.</p>
          <p><em>In both cases, EDL equals the total shaded area. The backfilling effect—the retroactive extension of all previous bars when new learning occurs—is why EDL can grow superlinearly, and why each new example can contribute more effective information than it itself contains.</em></p>
        </div>
      </div>

      <p>In synergistic learning, the floor drops at a steady rate, so the backfill on each previous example grows with every new example—and there are more previous examples to backfill onto with each step. The marginal contribution to EDL from the <em>m</em>-th example is not just the compression of that example, but the retroactive improvement on all <em>m–1</em> previous examples. Total EDL grows superlinearly.</p>

      <p>In redundant learning, the floor drops rapidly at first and then barely at all. Early examples produce large backfills, but later examples produce almost none. The marginal contribution to EDL shrinks. Total EDL grows but decelerates.</p>

      <!-- Visualization 3: The Two Signatures
      <div class="visualization" id="viz-signatures">
        <div class="viz-title">The Two Signatures</div>
        <div class="viz-subtitle">Compare how EDL per token scales with dataset size for elicitation (Llama 3.2 1B) vs teaching (TinyStories-1B) when we fine-tune on multiplication problems from the DeepMind Mathematics dataset.</div>
        <div class="viz-container" id="signatures-chart"></div>
        <div class="viz-controls">
          <div class="toggle-group">
            <button id="sig-llama" class="active">Llama (Elicitation)</button>
            <button id="sig-tiny" class="active">TinyStories (Teaching)</button>
          </div>

        </div>
      </div> -->

      <h3>Crossovers in Learning</h3>

      <p>These signatures describe dynamical behavior—what's happening in the learning process right now—not some fixed property of the model-task pair.</p>

      <p>We sometimes see <em>both</em> patterns in sequence: EDL per token decreases (elicitation), then increases (teaching), and finally decreases again (elicitation).</p>

      <p>What's happening at the peak? The model has learned enough, given the data and expressive capacity of its parameters, that additional new examples are now primarily redundant rather than informative. Teaching has transitioned to elicitation.</p>

      <p>The model isn't necessarily achieving maximum possible performance in absolute terms. It might plateau at 80% accuracy on a task where full fine-tuning reaches 95%. But it has reached its own capability ceiling given its architecture, pretraining, and the patterns available in this data.</p>

      <p>This is why we distinguish <em>learning mechanisms</em> (what governs the dynamics at each point in training, revealed by the derivative of EDL per token) from <em>learning regimes</em> (the overall character of learning on a task, determined by the dominant mechanism).</p>

      <p>A model that starts in the elicitation regime may never need teaching if the full capability was latent from the start. A model that shows teaching signatures must build new capability, but eventually crosses over to elicitation once that capability exists. And a model that initially shows elicitation signatures may later cross into the teaching regime if it learns structure beyond what was captured in its pretrained weights.</p>

      <!-- Visualization 4: The Crossover -->
      <div class="visualization" id="viz-crossover">
        <div class="viz-title">The Crossover</div>
        <div class="viz-subtitle">Drag along the curve to see how the learning mechanism changes with more data.</div>
        <div class="viz-container" id="crossover-chart"></div>
        <div class="viz-controls">
          <div id="crossover-state" style="font-weight: 600;">Currently: <span style="color: var(--coral);">Teaching</span></div>
          <div>Slope: <span id="crossover-slope">+0.12</span></div>
        </div>
      </div>

      <h3>Learning Is Relative</h3>

      <p>If we had access to Llama's full pretraining trajectory, we'd presumably see teaching signatures early on—as the model first learns arithmetic—followed by elicitation signatures as arithmetic becomes sufficiently represented.</p>

      <p>The checkpoint we start fine-tuning from is somewhat arbitrary. There's nothing privileged about "after pretraining" versus "after 50% of pretraining" versus "after fine-tuning on task A but before task B."</p>

      <p>The framework is agnostic to history. It asks: <em>right now</em>, at this point in training, is the model primarily surfacing existing capability or building new capability?</p>

      <p>This means learning can also go the other direction. A model that starts in an elicitation regime—with a latent capability—might later encounter examples that reveal new structure it hadn't encoded. EDL per token would start increasing again. Teaching would resume.</p>

      <p>The signatures track the dynamics of learning without requiring any information about the model's previous training history. And this relativity is one reason why the teaching/elicitation distinction, taken as a hard binary, can be misleading. What remains invariant across all these framings is the information measurement: how much does the model's generalization improve per bit of information received? This is what EDL tracks, and it is well-defined regardless of the reference point or what we call the learning process—whether that's "elicitation", "teaching", or something in between.</p>
    </section>

    <h2>Less Is All You Need (...<em>Sometimes</em>)</h2>

    <section id="less-is-more">
      <p>It is an empirical fact in machine learning that more is better. But when is less <em>enough</em>?</p>

      <p>If elicitation surfaces capabilities that a model already has, those capabilities must already be encoded in the model's parameters. How little information is enough to unlock them?</p>

      <p>We find that the answer to this question is "<em>remarkably</em> little". Often just a few bits.</p>

      <h3>One Example Is All You Need</h3>

      <p>How much information does a single arithmetic example contain?</p>

      <p>"What is the sum of 23 and 45? 68"</p>

      <p>The answer "68" comes from a space of roughly 100 possibilities (for two-digit addition). That's about 7 bits of information: log<sub>2</sub>(100) ≈ 6.6.</p>

      <p><strong>Seven bits (less than a single byte!) unlocks 96% accuracy</strong><sup>[8]</sup> on thousands of unseen problems.</p>

      <p>This is only possible if the model already knows arithmetic. The complexity needed to represent the addition algorithm is significantly larger than the information this single example can contain. The example isn't teaching addition—it's pointing to addition capability that already exists. It's saying: "When given questions in <em>this</em> format, use your arithmetic knowledge and respond in <em>that</em> format."</p>

      <!-- Visualization 5: One Example Is All You Need -->
      <div class="visualization" id="viz-one-example">
        <div class="viz-title">One Example Is All You Need</div>
        <div class="viz-subtitle">Compare zero-shot vs one-shot performance. Watch how a single example transforms accuracy on addition/subtraction problems for models with latent capability.</div>
        <div class="viz-container" id="one-example-chart"></div>
        <div class="viz-controls">
          <button id="animate-bars">Replay Animation</button>
        </div>
      </div>

      <h3>Diminishing Returns</h3>

      <p>Once a capability is elicited, additional examples have sharply diminishing returns.</p>

      <p>Going from 0 to 1 example might give you +67 percentage points. Going from 1 to 10 examples might give you +5 more. Going from 10 to 100 might give you +3 more.</p>

      <p>This matches the elicitation signature: EDL per token decreases because each additional example is more redundant than the last. The model already knows what you're asking for; showing it more examples of the same thing doesn't help much. The information gap between the base model and the fully elicited model is small. Most of that gap closes with the first few examples. What remains is refinement.</p>

      <h3>Few Parameters, Few Bits</h3>

      <p>We see the same pattern when constraining parameters instead of data.</p>

      <p>Training just 10 <em>randomly selected</em> parameters on the full dataset—out of billions—recovers over 90% of full fine-tuning performance for Llama 3.1 8B on addition/subtraction arithmetic problems.</p>

      <p>Ten parameters is roughly 160 bits<sup>[9]</sup> of uncompressed storage at bfloat16 precision<sup>[10]</sup>—and available storage is substantially lower. But the model doesn't need to encode arithmetic in those 160 bits. It just needs to encode a small adjustment—a pointer to existing capability.</p>

      <p>For TinyStories-1B? Ten parameters does nothing. The information required to encode arithmetic far exceeds what ten parameters can store, because the emergent capability doesn't exist in this model's weights. There's nothing to point to.</p>

      <h3>Reasoning Is Elicitation</h3>

      <p>We observe similarly dramatic performance improvements on technical and reasoning tasks when training for extended reasoning capabilities. We distill DeepSeek R1 into Qwen2.5 models by supervised fine-tuning on chain-of-thought reasoning traces generated by R1.</p>

      <p>Training on a single example or fewer than 100 parameters often recovers at least 50% of the performance gap (PGR) between zero-shot and full fine-tuning performance. Just as with simpler capabilities, learning distilled reasoning becomes less efficient with additional examples, and EDL per token matches other elicitation settings.</p>

      <!-- <p>A subtlety worth noting: most metrics for the capabilities we care about are not differentiable, and we may not be able to express them quantitatively anyway. Log-loss is often the best proxy we have. But natural language tasks can have many "correct" responses—different phrasings that correspond to the same answer—and the dataset selects one of these as the label. This choice of "ground truth" means that labels are noisy (they don't fully match the true distribution of correct responses), and that loss doesn't always closely track the behaviors we care about.</p> -->

      <h3>Reinforcement Learning Is Elicitation (Probably)</h3>

      <!-- <p>When trained with supervised fine-tuning (SFT) in the extreme low-information elicitation regime, base models often outperform their RLHF-instruction-tuned counterparts—even when trained on a single randomly sampled example, or when training only 10 randomly selected LoRA parameters.</p> -->

      <p>Our results may also shed light on a question that has attracted significant recent attention: what information does reinforcement learning (RL) contribute during post-training?</p>
       <!-- Is it possible that compute-heavy RL approaches are primarily serving an elicitation role, rather than instilling new capabilities? -->

      <p>Across tasks where RL-based post-training is typically credited with improving model behavior—including format adherence, instruction following, and refusal—we find that fine-tuning base models with remarkably small SFT datasets (in some cases, a single example) or very few trainable parameters (~10–10,000) is sufficient to match or exceed the performance of the corresponding instruction-tuned models. By EDL, these interventions fall squarely in the elicitation regime: the information required to close the behavioral gap between the base model and its post-trained counterpart is negligible relative to the model's total parametric capacity.</p>

      <!-- For tasks with unique and verifiable ground-truth solutions -->
      <p>This difference persists even after removing the confound of response format. When scoring correctness based on the model's final answer (regardless of whether it follows task formatting instructions), the elicited base model's accuracy remains higher than the corresponding instruction-tuned model's. Though the instruction-tuned models can output correctly-formatted responses zero-shot, their accuracies are often lower. This suggests that elicitation of the base model, in addition to aligning outputs to the task format (<em>format-specific</em> improvement), may also surface improved <em>capability-specific</em> performance. In other words, post-training and reinforcement learning from human feedback (RLHF) may, in some cases, have traded raw capability for instruction-following—and elicitation can recover it.</p>

      <p>This pattern extends to reasoning tasks. When we fine-tune base models on extended chain-of-thought traces, we again observe that very small amounts of supervised data suffice to elicit strong reasoning performance and significant accuracy improvements. This suggests that the capacity for step-by-step reasoning may already be substantially present in the pretrained model, with post-training serving primarily to surface and format it rather than to instill it.</p>

      <p>These observations are consistent with a simple bandwidth argument: RL provides at most ~1 bit of information per episode (for binary rewards), which is significantly less than the per-token supervisory signal available in SFT. If SFT can reproduce RL's behavioral effects while operating well within the elicitation regime, it is difficult to see how RL, with its far more constrained information channel, could be doing anything beyond elicitation.</p>

      <p>We emphasize that this is suggestive rather than conclusive. A rigorous information-theoretic treatment of RL post-training would require defining an analog of prequential MDL for the reinforcement learning setting—an open problem, since RL lacks the prediction-observation structure that gives MDL its coding-theoretic interpretation. We believe developing such a framework, and using it to formally characterize the information content of RL and reasoning-focused RL-based post-training, is a promising direction for future work.</p>
    </section>

    <h2>More Is <del>Better</del> <em>Necessary</em></h2>

    <section id="teaching-requirements">
      <p>When capabilities are absent—when the relevant complexity never emerged during pretraining—information requirements change dramatically.</p>

      <h3>Why Teaching Requires More</h3>

      <p>Take TinyStories-1B, a Llama variant that was pretrained entirely on simple English short stories—it has no knowledge of the world beyond the kinds of bedtime tales read aloud to children no more than three or four years old. TinyStories-1B must learn arithmetic from scratch. It has never seen numbers. It doesn't know what addition means. Every component of the capability must be constructed during fine-tuning.</p>

      <p>Think about what the model must encode: what numbers are (the digits 0–9 and their meanings), what addition means (the algorithm, or at least the input-output mapping), how to parse natural language arithmetic questions, and how to format numerical answers. Each of these is complex and requires information to specify. TinyStories-1B starts with none of it.</p>

      <p>Where Llama needs ~1 example to reach good performance, TinyStories needs ~10,000 to predict with nonzero accuracy. Where Llama needs ~10 parameters to capture the task, TinyStories needs ~1M+ to substantially improve. The gap is orders of magnitude, and it reflects the difference between pointing to existing emergent structure and constructing that structure from scratch.</p>

      <p>With 10 examples, the model sees 10 isolated facts. It can't generalize because it doesn't have enough information to identify the pattern underlying those facts. With 1,000 examples, patterns are starting to form, but the model is still building—each example adds new information about the task structure. With 10,000, the model has seen enough to begin encoding the algorithm and can start to generalize with nontrivial accuracy. Above 100,000, additional examples start to become redundant, and we see the transition from teaching to elicitation—the capability now exists in the weights, and "more" has become "different."</p>

      <h3>Learning Capacity Limits for Teaching</h3>

      <p>When teaching, we find that models can absorb roughly 1–2 bits of information per trainable parameter before hitting capacity limits. This aligns with prior work on knowledge capacity scaling laws: Allen-Zhu & Li (2024)<sup>[11]</sup> found that language models can store approximately 2 bits per parameter of factual knowledge when trained on synthetic datasets with known information content.</p>

      <p>Our teaching results match this bound: models in the <strong>teaching regime</strong> can compress up to <strong>~1-2 bits/parameter</strong> into their adapters before performance degrades. But models in the <strong>elicitation regime</strong> saturate at a much lower threshold: <strong>~0.01–0.1 bits/parameter</strong>.</p>

      <p>Why the difference? Elicitation doesn't require encoding the capability itself—only a small adjustment or pointer to existing capability. Pointers are cheap. Capabilities are expensive.</p>
    </section>

    <h2>A Tale of Two Models</h2>

    <section id="causal-intervention">
      <p>Correlation isn't causation. Maybe Llama and TinyStories differ in ways unrelated to latent capability that happen to produce different EDL patterns.</p>

      <p>To establish causality, we perform an intervention: take a model that shows teaching signatures, pre-teach it the relevant capability, and verify that its signatures shift to elicitation.</p>

      <h3>The Experiment</h3>

      <p><strong>Step 1:</strong> Train TinyStories-1B on arithmetic using operator notation ("3 × 4 = 12"). Track EDL. Observe teaching signatures: increasing EDL per token as the model learns to multiply.</p>

      <p><strong>Step 2:</strong> Take this pre-taught model. Now fine-tune it on arithmetic using natural language ("What is the product of 3 and 4?"). Track EDL.</p>

      <p><strong>Result:</strong> The pre-taught model shows elicitation signatures. EDL per token starts low and decreases monotonically. The capacity threshold drops from ~1 bit/parameter to ~0.05 bits/parameter.</p>

      <p>Same architecture. Same task (natural language arithmetic). Same training procedure. The only difference is whether the capability was pre-taught—whether emergence of a relevant capability had already occurred.</p>

      <p><strong>Pre-teaching converts a teaching task into an elicitation task.</strong></p>

      <!-- Visualization 6: The Causal Intervention -->
      <div class="visualization" id="viz-intervention">
        <div class="viz-title">The Causal Intervention</div>
        <div class="viz-subtitle">Watch how pre-teaching transforms the learning signature. Drag the slider to morph between before and after.</div>
        <div class="viz-container" id="intervention-chart"></div>
        <div class="viz-controls">
          <label>Pre-teaching progress: <input type="range" id="intervention-slider" min="0" max="100" value="0"></label>
          <span id="intervention-state">Before: Teaching signature</span>
        </div>
      </div>

      <h3>What This Tells Us</h3>

      <p><strong>Emergence of capability during pretraining is the key factor driving the difference in learning signatures. The same model and task can show either teaching or elicitation signatures depending on whether the relevant capability has already emerged.</strong></p>

      <p>The EDL signatures aren't arbitrary correlates of model type. They directly reflect whether the relevant emergent capability is present in the weights.</p>

      <p>When we change whether that capability is present—by pre-teaching, by inducing emergence before we measure—we change the signatures. This causal link validates that elicitation and teaching are about the learning mechanism, not the model's identity. The same model can be in either regime depending on what's being asked and what it already knows.</p>
    </section>

    <h2>Parameter Capacity Limits</h2>

    <section id="capacity-limits">
      <p>When fine-tuning with LoRA, how large of an adapter do you need?</p>

      <h3>The Capacity Curve</h3>

      <p>When fine-tuning with LoRA (or any parameter-efficient method), plot the fraction of information learned relative to what full fine-tuning extracts from a dataset (we call this "capacity", the ratio of parameter-efficient EDL to maximum EDL) against EDL per trainable parameter, and you'll see a characteristic shape. Below a certain threshold, capacity is approximately 1: the adapter can learn everything the model can learn from the data, and you're not capacity-limited. Above the threshold, capacity drops sharply: the adapter is saturated, and you're trying to store more bits than the parameters can effectively hold.</p>

      <p>The threshold is the <em>learning capacity limit</em>—the point where learning significantly slows down and parameter-efficient fine-tuning starts to underperform.</p>

      <h3>Learning Capacity Depends on the Learning Regime</h3>

      <p>The capacity limit EDL/<em>P</em>* differs by two orders of magnitude between elicitation and teaching. For elicitation, it's ~0.01 bits/parameter; for teaching, ~1+ bit/parameter.</p>

      <p>This makes intuitive sense through the lens of emergence. For elicitation tasks, the adapter just needs to store a small adjustment—a pointer to capability that emerged during pretraining—when the vast majority of the complexity already exists in the weights. For teaching tasks, the adapter must store the capability itself, encoding the kind of complex, emergent structure that pretraining would normally produce.</p>

      <!-- Visualization 7: The Capacity Cliff -->
      <div class="visualization" id="viz-capacity">
        <div class="viz-title">The Capacity Cliff</div>
        <div class="viz-subtitle">See how capacity drops sharply when EDL per parameter exceeds the threshold.</div>
        <div class="viz-container" id="capacity-chart"></div>
        <div class="viz-controls">
          <div class="toggle-group">
            <button id="cap-elicit" class="active">Elicitation (blue)</button>
            <button id="cap-teach" class="active">Teaching (orange)</button>
          </div>
        </div>
      </div>

      <h3>Larger Models Have Lower Capacity Thresholds</h3>

      <p>Within the elicitation regime, larger models have even lower capacity thresholds. Larger models have more preexisting capability—more latent structure to point to. The "pointer" to this complexity can be even more compact.</p>

      <p>This is counterintuitive: you might expect larger models to need more parameters to fine-tune or to absorb more bits during training. But if the capability is latent, the opposite is true. The more the model already knows, the less you need to tell it.</p>

      <h3>Practical Guidance</h3>

      <p>This gives us a recipe for choosing adapter size:</p>

      <ol>
        <li><strong>Run a pilot training run.</strong> Fine-tune with high-rank LoRA (or full fine-tuning) on a subset of your data. Compute EDL from the training logs.</li>
        <li><strong>Classify the regime.</strong> Plot EDL per token versus dataset size. Is it decreasing (elicitation) or increasing (teaching)?</li>
        <li><strong>Estimate required capacity.</strong> For elicitation, choose rank so that EDL/P* < 0.1 bits/parameter. For teaching, choose rank so that EDL/<em>P</em>* ~1+ bit/parameter. Or accept lower capacity (or decrease dataset size) if compute-constrained.</li>
        <li><strong>Validate.</strong> Compare your predicted adapter size to empirical performance. Adjust if needed.</li>
      </ol>

      <!-- Visualization 8: Adapter Size Calculator -->
      <div class="visualization" id="viz-calculator">
        <div class="viz-title">Adapter Size Calculator</div>
        <div class="viz-subtitle">Estimate the LoRA rank needed for your fine-tuning task.</div>
        <div class="calculator">
          <div class="calc-inputs">
            <div class="calc-input-group">
              <label>Estimated EDL (bits)</label>
              <input type="number" id="calc-edl" value="10000" min="0">
            </div>
            <div class="calc-input-group">
              <label>Model Size</label>
              <select id="calc-model">
                <option value="1000000000">1B parameters</option>
                <option value="3000000000">3B parameters</option>
                <option value="8000000000" selected>8B parameters</option>
                <option value="custom">Custom</option>
              </select>
            </div>
            <div class="calc-input-group" id="custom-params-group" style="display: none;">
              <label>Custom model parameters</label>
              <input type="number" id="calc-custom-params" value="8000000000">
            </div>
            <div class="calc-input-group">
              <label>Learning Regime</label>
              <select id="calc-regime">
                <option value="elicitation">Elicitation (~0.05 bits/param threshold)</option>
                <option value="teaching">Teaching (~1 bit/param threshold)</option>
                <option value="auto">Auto-detect from EDL</option>
              </select>
            </div>
            <div class="calc-input-group">
              <label>Target Capacity: <span id="target-cap-display">0.95</span></label>
              <input type="range" id="calc-target" min="0.5" max="1" step="0.01" value="0.95">
            </div>
          </div>
          <div class="calc-output">
            <div>Recommended LoRA Rank</div>
            <div class="calc-result" id="calc-rank">64</div>
            <div style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);">
              Trainable parameters: <span id="calc-params">~33M</span>
            </div>
            <div class="calc-warning" id="calc-warning" style="display: none;"></div>
            <div class="viz-container" id="calc-viz" style="height: 150px; margin-top: 1rem;"></div>
          </div>
        </div>
      </div>
    </section>

    <h2>Dynamics and Equilibria: Two Views of Learning</h2>

    <section id="dynamics-equilibria">

    <p>The dynamical signatures and capacity thresholds we've described are both useful, but they measure different things—roughly, the <em>path</em> and the <em>destination</em>.</p>

    <p>The dynamical signatures describe a non-equilibrium process: what's happening in learning <em>right now</em>. At each point in training, they answer the question: is each new example making the dataset <em>synergistically</em> more informative (the model can now extract more from previous examples than it could before) or <em>redundantly</em> more informative (the model already knows most of what the new example conveys)? This is a property of the learning trajectory, and like any trajectory, it's sensitive to the forces acting on it—optimizer, learning rate, schedule. A near-zero learning rate, for instance, could make genuinely synergistic data look redundant by preventing the model from updating enough to exploit the new information. This is why careful hyperparameter search matters: we want the dynamics to reflect the information structure of the task, not artifacts of under-optimization.</p>

    <p>The capacity thresholds describe an equilibrium state: where does the system end up when it runs out of learning capacity? When the adapter saturates, how much information has it absorbed per parameter? Low information density at saturation (~0.01 bits/parameter) means the adapter needed to store only a small adjustment—a pointer to structure that already existed. High density (~1 bit/parameter) means the adapter encoded substantial new structure. This is a property of the endpoint, and it's more robust to the path taken to get there.</p>

    <p>Which measurement matters depends on what you want to know.</p>

    <p>When you care about whether an evaluation procedure is starting to build new capability—whether your elicitation is drifting into territory where the model is learning from the eval rather than being assessed by it—the dynamical signatures are the right diagnostic. They can detect the onset of synergistic learning even before it shows up in the capacity curves.</p>

    <p>When you care about whether a given model and compute budget could support building significant new capability—whether there's enough parameter capacity to store the complexity required—the thresholds are more directly informative.</p>

    <!-- <p>When you care about how much information a model needs to learn a capability—whether you're trying to estimate the information budget for teaching a dangerous capability, or whether your parameter-efficient fine-tuning method has enough capacity to capture the task—the capacity thresholds are the right diagnostic. They give you a concrete number to work with: if your adapter can store 0.1 bits/parameter but the task requires 1 bit/parameter, you know you're in trouble.</p> -->

    <p>And the dynamical signatures reveal structure that the capacity thresholds alone would miss. Consider a task that is genuinely new to the model but low in complexity—a simple function with low sample complexity that the model has never encountered. Because the task is simple, the model can encode it in relatively few parameters, and the capacity curve saturates well below 1 bit/parameter—an equilibrium that looks identical to elicitation because there's very little information to learn. But the dynamics tell a different story: below the sample complexity, each new example produces a larger marginal improvement in generalization than the last, the signature of synergistic learning. The model is building something new; it's just building something small.</p>

    <p>But more fundamental than either measurement is the quantity they both serve: <em>how much total information did the model learn?</em> This is what EDL measures directly. The dynamical signatures tell you whether that information is accumulating synergistically or redundantly. The capacity thresholds tell you whether the adapter has room to store it. But what ultimately determines risk, efficiency, and safety is the total information budget—how many bits of additional information are required to bring the model to demonstrate a given capability—and whether that number falls above or below the threshold you've set for your particular use case.</p>

    <p><em>Note: The synergistic/redundant framing connects back to "more is different" at the level of the training data itself. In the synergistic regime, the collective dataset is literally more informative than the sum of its individual examples—each example's contribution depends on the others, and the whole is different from the sum of its parts. In the redundant regime, examples are largely interchangeable, and the whole is well-approximated by a small subset. The same principle of emergence operates at the level of how data informs learning, not just how parameters compose into capabilities.</em></p>

    </section>

    <h2>Implications</h2>

    <section id="implications">
      <h3>For Safety Evaluation</h3>

      <p>Our findings suggest caution about fine-tuning-based capability evaluations.</p>

      <p>If your evaluation procedure shows teaching signatures—increasing EDL per token, high capacity thresholds—you may be measuring what the model can learn rather than what it already knows. The evaluation is potentially teaching capabilities it's supposed to be detecting.</p>

      <p>For faithful capability assessment, evaluations should target the elicitation regime: use minimal data, monitor for teaching signatures, and verify that results are stable to further training.</p>

      <p>EDL also provides an upper bound estimate on how much capability could have been added. If fine-tuning added X bits of information, we can estimate the complexity of capability that X bits could encode. This helps calibrate how conservative to be about evaluation results.</p>

      <h3>For Risk Assessment</h3>

      <p>The asymmetry between elicitation and teaching has direct safety implications.</p>

      <p>The asymmetry between elicitation and teaching has direct safety implications. If a dangerous capability is latent—an emergent phenomenon of pretraining, already encoded in the weights—it may be surfaced with minimal intervention: a few examples of the undesired behavior, a jailbreak prompt that activates existing knowledge, a deployment context that accidentally triggers latent capability. The information barrier is low—potentially just a few bits.</p>

      <p>If the capability must be taught, the barrier is substantially higher: orders of magnitude more information, extensive training, and specialized data. This is more predictable and easier to defend against.</p>

      <p>Understanding which capabilities are latent versus absent in deployed models is therefore critical for informed risk assessment.</p>

      <h3>For Understanding Reasoning</h3>

      <p>Our analysis of reasoning model distillation (using DeepSeek R1 distilled into Qwen models) shows behavior characteristic of elicitation: decreasing EDL per token and capacity thresholds of ~0.05 bits/parameter or fewer.</p>

      <p>This suggests that chain-of-thought reasoning capabilities may be largely latent in capable base models, waiting to be surfaced through appropriate fine-tuning rather than built from scratch.</p>

      <p>This has implications for understanding how reasoning capabilities propagate through the training pipeline, whether expensive RL-based reasoning improvements could be achieved through cheaper elicitation methods, and how well RL may be capable of teaching genuinely new capabilities.</p>

      <p>We would be excited to see research that extends EDL to RL settings and directly investigates information learned by models during RL-based post-training.</p>

      <h3>For Efficiency</h3>

      <p>Many practitioners over-train on elicitation tasks. If your capability is latent, massive datasets and high-rank adapters are wasteful. Our results suggest that for elicitation, ranks 1–8 often suffice to attain maximum performance, and a few hundred examples may be enough. For teaching, high-rank adapters and large datasets are necessary. EDL provides a principled way to distinguish these cases <em>before</em> committing to expensive training runs.</p>
    </section>

    <h2>Beyond the Dichotomy</h2>

    <section id="beyond-dichotomy">

      <h3>What Actually Matters</h3>

      <p>We've framed this work in terms of two learning processes: elicitation and teaching. This framing is useful—it captures real structure in the data, it maps onto how practitioners think, and it provides actionable guidance for today's models. But we want to be honest about its limits.</p>

      <p>The teaching/elicitation distinction is, in the end, a dichotomy imposed on what is really a continuum. Real learning often involves a mixture of both mechanisms in varying proportions. The dynamical signatures reveal the predominant process, not a clean binary. And as models and training methods evolve, the dichotomy may become less useful.</p>

      <p>Consider several situations where the binary framing struggles:</p>

      <ul>
        <li>A model might have relevant representations for a capability but face architectural constraints that prevent it from producing outputs that employ them. Is this "latent capability"? From the model's perspective, the knowledge exists but is inaccessible—the distinction between "absent" and "present but blocked" matters for interpretability but not for the information cost of unlocking it.</li>
        <li>A model might have the relevant representations but "choose" not to employ them—because later-trained representations (say, from RLHF) suppress those outputs. Again: the capability exists in some sense, but the information needed to surface it might be nontrivial.</li>
        <li>A sufficiently capable model might learn entirely new patterns from very few examples—not because it has preexisting representations, but because it can reason from first principles or generalize from minimal data. Such a model would show low information requirements that look like elicitation, even though the capability is genuinely new.</li>
        <li>A model might build significant new capability entirely within its context window or reasoning trace—constructing representations on the fly that no current interpretability method would identify in the weights. The capability doesn't "exist" in the parameters, yet the information cost has been paid nonetheless—entirely in-context.</li>
      </ul>

      <p>In all of these cases, what remains well-defined is the <em>information budget</em>: how many bits of additional information—whether delivered through fine-tuning, prompting, or in-context examples—are required for the model to demonstrate the capability? This is the quantity that EDL measures, and it is meaningful regardless of the underlying mechanism.</p>

      <!-- <p>Future work could explore more nuanced characterizations of learning dynamics, including hybrid regimes where elicitation and teaching interact, or settings where different components of a capability are latent versus absent.</p> -->

      <h3>From Mechanisms to Measurements</h3>

      <p>We think the right way to read our results is not "teaching and elicitation are fundamentally different processes" but rather "the information cost of demonstrating a capability varies enormously depending on what the model already knows, and EDL gives us a way to measure it."</p>

      <p>Teaching and elicitation are useful names for the regimes where information cost is high and low, respectively. The dynamical signatures reliably identify which process dominates. And the framework extends naturally beyond fine-tuning: the same information-theoretic lens applies to prompting, in-context learning, and (in principle) chain-of-thought reasoning. Bits are a universal currency. Whether they arrive through gradient updates or through tokens in a context window, they carry the same information.</p>

      <p>This reframing has a practical consequence that we think is important.</p>

      <h3>Information Budgets for Safety</h3>

      <p>Current safety frameworks often ask categorical questions: <em>Does the model have this dangerous capability?</em> Our results suggest a more informative question: <em>How much additional information would it take for the model to demonstrate this capability?</em></p>

      <p>This reframing turns a binary classification problem into a quantitative measurement—and quantitative measurements can be tied to quantitative thresholds.</p>

      <p>Here's how this could work in practice. Suppose we're concerned about a specific dangerous capability—say, the ability to provide expert-level guidance on synthesizing a harmful compound. We can estimate the information budget available to the most capable adversaries we want to defend against: how much fine-tuning data could they plausibly assemble? How much compute do they have? What quality of examples could they produce?</p>

      <p>This gives us a number—an information budget, measured in bits—that characterizes the threat. If EDL measurements show that the model can be brought to demonstrate the capability with less information than this budget, the capability is within the adversary's reach, and we need additional safeguards (stronger guardrails, restricting model access, or escalating to higher safety levels like ASL-4). If the model requires more information than the budget allows, the capability is beyond the adversary's practical reach—at least through fine-tuning.</p>

      <p>More concretely: if we want, say, 99% confidence that a given class of adversary cannot elicit a particular capability, we set the information budget at the level available to the top 1% most-resourced actors in that class. Models that demonstrate the capability below that threshold require additional protections. Models that don't are safer by this metric.</p>

      <p>This approach has several advantages over categorical assessments. It's <em>quantitative</em>: instead of "the model can/can't do X," we get "the model can do X with Y bits of additional information." It's <em>calibrated to threat models</em>: different adversaries have different resources, and the framework accommodates this naturally. It's <em>comparable across models</em>: we can track how information requirements change across model generations. And it's <em>grounded in measurement</em>: EDL provides an empirical anchor rather than relying on subjective assessments of whether a capability is "latent" or "absent."</p>

      <p>We don't claim this is a complete safety framework. Estimating adversary information budgets is itself a hard problem, and the relationship between bits of fine-tuning information and real-world harm is complex. But we believe this direction—tying safety decisions to quantitative thresholds on information cost rather than to categorical judgments about capability presence—is more robust and more actionable than the alternative.</p>

    <h2>Caveats and Nuances</h2>

    <section id="caveats">
      <p>We emphasize several limitations and subtleties.</p>

      <p><strong>The boundary is fuzzy.</strong> Elicitation and teaching are useful abstractions, but real learning likely involves both mechanisms in varying proportions. The signatures reveal the <em>predominant</em> mechanism, not a strict dichotomy.</p>

      <p><strong>What we measure is learning efficiency, not model cognition.</strong> We don't claim a mechanistically interpretable understanding of what representations exist or how they change during elicitation versus teaching. We observe that different amounts of information produce different amounts of generalization, and that this varies systematically with pretraining.</p>

      <p><strong>EDL depends on training details.</strong> Different optimizers, learning rates, and schedules could yield different EDL values for the same model and data. EDL measures information absorbed <em>by this training run</em>. This is important: if EDL instead measured some fundamental property of the task, elicitation and teaching would yield similar values.</p>

      <p><strong>Our experiments focus on specific domains.</strong> Arithmetic and reasoning tasks have clean structure that may not generalize to all capabilities. Messier, more naturalistic capabilities could behave differently.</p>

      <p><strong>Capability ceilings are model-relative.</strong> A model that has learned "all it can" about arithmetic might plateau at 80% accuracy while a larger model reaches 95%. Elicitation is relative to each model's own ceiling, not absolute task performance.</p>

      <p><strong>EDL measures information learned, not capability.</strong> Loss and EDL are proxies for the underlying capabilities we care about. They measure how much information the model is absorbing from the data, but they don't directly measure the presence or absence of specific capabilities. A model might have a latent capability that isn't perfectly captured by the loss metric, or it might learn to exploit spurious correlations or structure in the data that improve loss without improving true capability.</p>

      <p>Despite these limitations, we believe EDL provides a useful quantitative framework for thinking about learning—one that makes testable predictions and offers practical guidance.</p>
    </section>

    <h2>Conclusion</h2>

    <section id="conclusion">
      <p>Learning is compression. When models learn, they compress predictive information from data into parameters.</p>

      <p><em>Excess description length</em> measures this compression: the bits that count toward generalization rather than memorization.</p>

      <p>The central thread of this work connects three ideas about scale and complexity. First, Anderson's principle that <em>more is different</em>: complexity and scale together produce emergence, giving rise to complex capabilities in pretrained models that are qualitatively different from anything present in the individual training examples. Second, our finding that when this emergent complexity already exists, <em>less is all you need</em>: remarkably little information—sometimes a single example, sometimes just a few bits—suffices to surface capabilities that took billions of tokens to create. Third, our finding that when this complexity is absent, <em>more is necessary</em>: there is no shortcut past the information cost of building new emergent structure.</p>

      <p>EDL gives us a way to measure which regime we're in, and these measurements reveal clear dynamical signatures. Elicitation—surfacing existing emergent capability—produces decreasing EDL per token and capacity thresholds of ~0.01–0.1 bits/parameter. Teaching—building new capability—produces increasing EDL per token and capacity thresholds of ~1 bit/parameter. These signatures are causal: pre-teaching a capability shifts the dynamical behavior and learning capacity from teaching-like to elicitation-like.</p>

      <p>The practical implications follow directly. For safety evaluations, monitor for teaching signatures to ensure you're measuring what a model knows rather than what it can learn. For risk assessment, recognize that latent capabilities sit behind a thin information barrier. For efficiency, match your training resources to the actual learning regime rather than defaulting to more data and more parameters.</p>

      <p>The framework gives us a language, grounded in information theory, for asking precise questions about how models learn. We hope it proves useful.</p>
    </section>

    <div class="footnote">
      <p><sup>[1]</sup> This is a simplification. In practice, hyperparameters like learning rate, batch size, optimizer, and random seed would also need to be communicated (we assume these are fixed and known to both parties). But the important insight is that the labels are the dominant information cost.</p>
      <p><sup>[2]</sup> Assuming deterministic training, which is approximately* true for our purposes. *In reality, the reconstruction is approximate due to floating-point precision and any hardware sources of non-determinism, but the principle holds.</p>
      <p><sup>[3]</sup> This is online or mini-batch learning, which is standard in practice.</p>
      <p><sup>[4]</sup> This is a simplified version of the prequential coding scheme from Dawid (1984) and Rissanen (1984).</p>
      <p><sup>[5]</sup> In principle—some of these complexities may be uncomputable.</p>
      <p><sup>[6]</sup> This is Kolmogorov complexity, which is defined relative to a choice of universal Turing machine.</p>
      <p><sup>[7]</sup> "25 blue circles" is shorter than "a red square, a blue circle, a green triangle, and a yellow rhombus."</p>
      <p><sup>[8]</sup> On a held-out test set of arithmetic problems from the DeepMind Mathematics dataset.</p>
      <p><sup>[9]</sup> The effective storage capacity of 10 parameters is substantially lower than 160 bits due to redundancy and inefficiency. See also Allen-Zhu & Li (2024), "The Physics of Language Models, Part 3.3: Knowledge Capacity Scaling Laws," who report that models can store roughly 2 bits/parameter of pretrained knowledge.</p>
      <p><sup>[10]</sup> LoRA commonly uses bfloat16 precision, and we adopt this standard across all of our experiments (including full fine-tuning).</p>
      <p><sup>[11]</sup> Allen-Zhu & Li (2024), "The Physics of Language Models, Part 3.3: Knowledge Capacity Scaling Laws," https://arxiv.org/abs/2404.05405.</p>
    </div>
  </article>

  <div class="tooltip" id="tooltip"></div>

  <script>
    // ============================================================
    // DATA GENERATION
    // ============================================================
    // Synthetic data designed to match the qualitative patterns from the paper.
    // Each dataset documents its format for easy replacement with real W&B data.

    /*
     * DATA FORMAT: mdlData
     * Array of {step: number, loss: number}
     * Represents training loss over first epoch
     */
    function generateMDLData(numSteps = 100) {
      // Pure exponential decay from 3.0 to ~0.5 over numSteps
      // 3.0 * exp(-numSteps * k) ≈ 0.5 → k = ln(6)/numSteps
      const initialLoss = 3.0;
      const k = Math.log(6) / numSteps;
      const data = [];
      // Use seeded random for consistency across plots
      let s = 42;
      function srand() { s = (s * 1103515245 + 12345) & 0x7fffffff; return s / 0x7fffffff; }
      for (let i = 0; i <= numSteps; i++) {
        const baseLoss = initialLoss * Math.exp(-k * i);
        const noise = (srand() - 0.5) * 0.04 * baseLoss; // Small proportional noise
        data.push({ step: i, loss: Math.max(0.01, baseLoss + noise) });
      }
      return data;
    }

    /*
     * DATA FORMAT: signaturesData
     * {
     *   llama: [{n: number, edl_per_token: number}, ...],
     *   tinystories: [{n: number, edl_per_token: number}, ...]
     * }
     * Log-scale dataset sizes (n), EDL per token
     */
    function generateSignaturesData() {
      const llama = [];
      const tinystories = [];
      const sizes = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000];

      sizes.forEach(n => {
        // Llama: elicitation signature (decreasing)
        const llamaEdl = 0.8 / Math.pow(n, 0.3) + 0.02 + (Math.random() - 0.5) * 0.02;
        llama.push({ n, edl_per_token: llamaEdl });

        // TinyStories: teaching signature (increasing then plateau)
        let tinyEdl;
        if (n < 1000) {
          tinyEdl = 0.02 + 0.15 * Math.log10(n) + (Math.random() - 0.5) * 0.02;
        } else {
          tinyEdl = 0.45 + (Math.random() - 0.5) * 0.03;
        }
        tinystories.push({ n, edl_per_token: tinyEdl });
      });

      return { llama, tinystories };
    }

    /*
     * DATA FORMAT: crossoverData
     * Array of {n: number, edl_per_token: number, slope: number}
     * Shows teaching -> elicitation transition
     */
    function generateCrossoverData() {
      const data = [];
      const sizes = [];
      for (let i = 0; i <= 50; i++) {
        sizes.push(Math.pow(10, i / 12.5)); // Log scale from 1 to ~10000
      }

      sizes.forEach((n, i) => {
        // Teaching phase (increasing), then elicitation (decreasing)
        const peak = 25; // Peak around n=~300
        let edl;
        if (i < peak) {
          edl = 0.05 + 0.4 * Math.pow(i / peak, 1.5);
        } else {
          edl = 0.45 - 0.3 * Math.pow((i - peak) / (50 - peak), 0.8);
        }
        edl += (Math.random() - 0.5) * 0.02;

        const slope = i < peak ? 0.1 : -0.08;
        data.push({ n, edl_per_token: edl, slope });
      });

      return data;
    }

    /*
     * DATA FORMAT: oneExampleData
     * Array of {model: string, zero_shot: number, one_shot: number}
     * Accuracy values 0-1
     */
    function generateOneExampleData() {
      return [
        { model: 'Llama 3.1 8B', zero_shot: 0.01, one_shot: 0.96 },
        { model: 'Llama 3.2 3B', zero_shot: 0.01, one_shot: 0.88 },
        { model: 'Llama 3.2 1B', zero_shot: 0.01, one_shot: 0.67 },
        { model: 'TinyStories-1B', zero_shot: 0.01, one_shot: 0.01 }
      ];
    }

    /*
     * DATA FORMAT: interventionData
     * {
     *   before: [{n: number, edl_per_token: number}, ...],
     *   after: [{n: number, edl_per_token: number}, ...]
     * }
     * Before = teaching, After = elicitation
     */
    function generateInterventionData() {
      const sizes = [1, 5, 10, 50, 100, 500, 1000, 5000, 10000];
      const before = [];
      const after = [];

      sizes.forEach(n => {
        // Before: teaching signature
        const beforeEdl = 0.02 + 0.12 * Math.log10(n) + (Math.random() - 0.5) * 0.01;
        before.push({ n, edl_per_token: beforeEdl });

        // After: elicitation signature
        const afterEdl = 0.5 / Math.pow(n, 0.35) + 0.01 + (Math.random() - 0.5) * 0.01;
        after.push({ n, edl_per_token: afterEdl });
      });

      return { before, after };
    }

    /*
     * DATA FORMAT: capacityData
     * Array of {edl_per_param: number, capacity: number, rank: number, regime: string}
     * edl_per_param on log scale, capacity 0-1
     */
    function generateCapacityData() {
      const data = [];
      const ranks = [4, 16, 64, 256];

      // Elicitation regime - threshold around 0.05
      for (let i = 0; i < 30; i++) {
        const edlPerParam = Math.pow(10, -4 + i * 0.15);
        const threshold = 0.05;
        const capacity = edlPerParam < threshold ?
          0.95 + Math.random() * 0.05 :
          Math.max(0.1, 0.95 - (edlPerParam - threshold) * 5 + Math.random() * 0.1);
        data.push({
          edl_per_param: edlPerParam,
          capacity: Math.min(1, capacity),
          rank: ranks[Math.floor(Math.random() * ranks.length)],
          regime: 'elicitation'
        });
      }

      // Teaching regime - threshold around 1
      for (let i = 0; i < 30; i++) {
        const edlPerParam = Math.pow(10, -1 + i * 0.1);
        const threshold = 1;
        const capacity = edlPerParam < threshold ?
          0.9 + Math.random() * 0.1 :
          Math.max(0.15, 0.9 - (edlPerParam - threshold) * 0.3 + Math.random() * 0.1);
        data.push({
          edl_per_param: edlPerParam,
          capacity: Math.min(1, capacity),
          rank: ranks[Math.floor(Math.random() * ranks.length)],
          regime: 'teaching'
        });
      }

      return data;
    }

    // ============================================================
    // VISUALIZATION HELPERS
    // ============================================================

    const colors = {
      coral: '#D97757',
      coralLight: '#E89B7E',
      coralDark: '#B85A3C',
      darkBlue: '#1a1a2e',
      cream: '#FAF8F5',
      creamDark: '#F0EDE8',
      blue: '#4A90D9',
      orange: '#E8A838'
    };

    const tooltip = d3.select('#tooltip');

    function showTooltip(event, html) {
      tooltip
        .html(html)
        .style('opacity', 1)
        .style('left', (event.pageX + 10) + 'px')
        .style('top', (event.pageY - 10) + 'px');
    }

    function hideTooltip() {
      tooltip.style('opacity', 0);
    }

    // ============================================================
    // VISUALIZATION 1: ACCUMULATING MDL
    // ============================================================

    function initMDLVisualization() {
      const container = d3.select('#mdl-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 20, right: 30, bottom: 40, left: 60 };

      const data = generateMDLData();
      const maxStep = data.length - 1;

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLinear()
        .domain([0, maxStep])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, d3.max(data, d => d.loss) * 1.1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(10))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 35)
        .attr('fill', 'currentColor')
        .text('Training Step');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -45)
        .attr('fill', 'currentColor')
        .text('Loss (nats)');

      // Area for MDL
      const area = d3.area()
        .x(d => x(d.step))
        .y0(height - margin.bottom)
        .y1(d => y(d.loss));

      const areaPath = svg.append('path')
        .datum(data.slice(0, 1))
        .attr('fill', colors.coralLight)
        .attr('opacity', 0.7)
        .attr('d', area);

      // Line for loss curve
      const line = d3.line()
        .x(d => x(d.step))
        .y(d => y(d.loss));

      const linePath = svg.append('path')
        .datum(data)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', line);

      // Current position marker
      const marker = svg.append('circle')
        .attr('cx', x(0))
        .attr('cy', y(data[0].loss))
        .attr('r', 6)
        .attr('fill', colors.coral);

      // Update function
      function updateVisualization(step) {
        const currentData = data.slice(0, step + 1);
        areaPath.datum(currentData).attr('d', area);
        marker.attr('cx', x(step)).attr('cy', y(data[step].loss));

        // Calculate MDL (area under curve)
        let mdl = 0;
        for (let i = 0; i <= step; i++) {
          mdl += data[i].loss;
        }

        document.getElementById('mdl-step-display').textContent = step;
        document.getElementById('mdl-value').textContent = mdl.toFixed(1);
      }

      // Slider control
      const slider = document.getElementById('mdl-slider');
      slider.max = maxStep;
      slider.addEventListener('input', (e) => {
        updateVisualization(parseInt(e.target.value));
      });

      // Play button
      let playing = false;
      let playInterval;
      const playBtn = document.getElementById('mdl-play');

      playBtn.addEventListener('click', () => {
        if (playing) {
          clearInterval(playInterval);
          playBtn.textContent = 'Play';
          playing = false;
        } else {
          let step = parseInt(slider.value);
          if (step >= maxStep) step = 0;
          playBtn.textContent = 'Pause';
          playing = true;

          playInterval = setInterval(() => {
            step++;
            if (step > maxStep) {
              clearInterval(playInterval);
              playBtn.textContent = 'Play';
              playing = false;
              return;
            }
            slider.value = step;
            updateVisualization(step);
          }, 50);
        }
      });
    }

    // ============================================================
    // VISUALIZATION 2: MDL/EDL DECOMPOSITION
    // ============================================================

    function initEDLDecomposition() {
      const container = d3.select('#edl-decomp-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 20, right: 30, bottom: 40, left: 60 };

      const data = generateMDLData();
      // Get the minimum train loss (final converged value)
      const minTrainLoss = Math.min(...data.map(d => d.loss));
      // Test loss must be >= train loss (no negative generalization gap)
      let lTest = Math.max(0.8, minTrainLoss);

      // Update slider min to be the final train loss
      const lTestSliderEl = document.getElementById('ltest-slider');
      lTestSliderEl.min = minTrainLoss.toFixed(2);
      lTestSliderEl.value = lTest.toFixed(2);

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLinear()
        .domain([0, data.length - 1])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, d3.max(data, d => d.loss) * 1.1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(10))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 35)
        .attr('fill', 'currentColor')
        .text('Training Step');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -45)
        .attr('fill', 'currentColor')
        .text('Loss (nats)');

      // MDL area (full area under curve)
      const mdlArea = d3.area()
        .x(d => x(d.step))
        .y0(height - margin.bottom)
        .y1(d => y(d.loss));

      const mdlPath = svg.append('path')
        .datum(data)
        .attr('class', 'mdl-area')
        .attr('fill', colors.coralLight)
        .attr('opacity', 0.4)
        .attr('stroke', 'none')
        .attr('d', mdlArea);

      // EDL area (area above L_test line)
      const edlArea = d3.area()
        .x(d => x(d.step))
        .y0(d => y(Math.min(d.loss, lTest)))
        .y1(d => y(d.loss));

      const edlPath = svg.append('path')
        .datum(data)
        .attr('class', 'edl-area')
        .attr('fill', colors.coral)
        .attr('opacity', 0)
        .attr('d', edlArea);

      // Loss curve
      const line = d3.line()
        .x(d => x(d.step))
        .y(d => y(d.loss));

      svg.append('path')
        .datum(data)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', line);

      // L_test line
      const lTestLine = svg.append('line')
        .attr('x1', margin.left)
        .attr('x2', width - margin.right)
        .attr('y1', y(lTest))
        .attr('y2', y(lTest))
        .attr('stroke', colors.darkBlue)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '5,5');

      const lTestLabel = svg.append('text')
        .attr('x', width - margin.right - 5)
        .attr('y', y(lTest) - 12)
        .attr('text-anchor', 'end')
        .attr('font-size', '12px')
        .attr('fill', colors.darkBlue);
      lTestLabel.append('tspan').text('L');
      lTestLabel.append('tspan').attr('baseline-shift', 'sub').attr('font-size', '0.7em').text('test');

      // Legend
      const legend = svg.append('g')
        .attr('transform', `translate(${width - margin.right - 140}, ${margin.top + 5})`);

      // MDL legend item
      legend.append('rect')
        .attr('x', 0).attr('y', 0).attr('width', 14).attr('height', 14)
        .attr('fill', colors.coralLight).attr('opacity', 0.5);
      legend.append('text')
        .attr('x', 20).attr('y', 11)
        .attr('font-size', '11px').attr('fill', '#333')
        .text('MDL (total area)');

      // EDL legend item
      legend.append('rect')
        .attr('x', 0).attr('y', 20).attr('width', 14).attr('height', 14)
        .attr('fill', colors.coral).attr('opacity', 0.8);
      const edlLegendText = legend.append('text')
        .attr('x', 20).attr('y', 31)
        .attr('font-size', '11px').attr('fill', '#333');
      edlLegendText.append('tspan').text('EDL (above L');
      edlLegendText.append('tspan').attr('baseline-shift', 'sub').attr('font-size', '0.7em').text('test');
      edlLegendText.append('tspan').attr('baseline-shift', 'baseline').attr('font-size', '11px').text(')');

      // L_test legend item
      legend.append('line')
        .attr('x1', 0).attr('y1', 47).attr('x2', 14).attr('y2', 47)
        .attr('stroke', colors.darkBlue).attr('stroke-width', 2).attr('stroke-dasharray', '3,3');
      const lTestLegendText = legend.append('text')
        .attr('x', 20).attr('y', 51)
        .attr('font-size', '11px').attr('fill', '#333');
      lTestLegendText.append('tspan').text('L');
      lTestLegendText.append('tspan').attr('baseline-shift', 'sub').attr('font-size', '0.7em').text('test');

      // View mode state
      let viewMode = 'mdl';

      function updateView() {
        mdlPath.attr('opacity', viewMode === 'mdl' || viewMode === 'both' ? 0.4 : 0);
        edlPath.attr('opacity', viewMode === 'edl' || viewMode === 'both' ? 0.8 : 0);
      }

      function updateLTest(newLTest) {
        lTest = newLTest;
        lTestLine.attr('y1', y(lTest)).attr('y2', y(lTest));
        lTestLabel.attr('y', y(lTest) - 12);

        const edlAreaUpdated = d3.area()
          .x(d => x(d.step))
          .y0(d => y(Math.min(d.loss, lTest)))
          .y1(d => y(d.loss));

        edlPath.attr('d', edlAreaUpdated(data));
      }

      // Toggle buttons
      document.getElementById('show-mdl').addEventListener('click', function() {
        viewMode = 'mdl';
        updateView();
        document.querySelectorAll('#viz-edl-decomp .toggle-group button').forEach(b => b.classList.remove('active'));
        this.classList.add('active');
      });

      document.getElementById('show-edl').addEventListener('click', function() {
        viewMode = 'edl';
        updateView();
        document.querySelectorAll('#viz-edl-decomp .toggle-group button').forEach(b => b.classList.remove('active'));
        this.classList.add('active');
      });

      document.getElementById('show-both').addEventListener('click', function() {
        viewMode = 'both';
        updateView();
        document.querySelectorAll('#viz-edl-decomp .toggle-group button').forEach(b => b.classList.remove('active'));
        this.classList.add('active');
      });

      // L_test slider
      const lTestSlider = document.getElementById('ltest-slider');
      const lTestDisplay = document.getElementById('ltest-display');

      lTestSlider.addEventListener('input', (e) => {
        const newLTest = parseFloat(e.target.value);
        lTestDisplay.textContent = newLTest.toFixed(2);
        updateLTest(newLTest);
      });

      updateView();
    }

    // ============================================================
    // VISUALIZATION: MULTI-EPOCH TRAINING
    // ============================================================

    function initMultiEpochVisualization() {
      const container = d3.select('#multi-epoch-chart');
      if (!container.node()) return;

      const width = container.node().getBoundingClientRect().width;
      const height = 340;
      const margin = { top: 20, right: 30, bottom: 50, left: 60 };

      // Constants
      const stepsPerEpoch = 100;
      const numEpochs = 5;
      const maxSteps = stepsPerEpoch * numEpochs; // 500 steps

      // Generate first epoch data - this defines MDL (the information in the data)
      const firstEpochData = generateMDLData(stepsPerEpoch);
      const initialLoss = firstEpochData[0].loss;
      const endOfFirstEpochLoss = firstEpochData[stepsPerEpoch].loss;

      // Pre-generate all training data for consistency
      const allTrainData = [];
      let seed = 99999;
      function seededRandom() {
        seed = (seed * 1103515245 + 12345) & 0x7fffffff;
        return seed / 0x7fffffff;
      }

      // Copy first epoch data
      firstEpochData.forEach(d => allTrainData.push({...d}));

      // Generate subsequent epochs with stepwise decay:
      // Each epoch starts high (bump from reshuffled data), decays within the epoch,
      // then the next epoch starts from a lower baseline.
      // This creates a visible staircase pattern.
      const epochStartLoss = [endOfFirstEpochLoss]; // loss at start of each post-first epoch
      for (let e = 1; e <= numEpochs; e++) {
        // Each epoch reduces the baseline by a factor
        epochStartLoss.push(epochStartLoss[e - 1] * 0.55);
      }

      for (let step = stepsPerEpoch + 1; step <= maxSteps; step++) {
        const epoch = Math.floor(step / stepsPerEpoch); // Current epoch (0-indexed)
        const stepInEpoch = step % stepsPerEpoch;
        const t = stepInEpoch / stepsPerEpoch; // 0-1 progress within epoch

        // This epoch's start and end loss levels
        const startLoss = epochStartLoss[epoch - 1]; // where this epoch starts (with bump)
        const endLoss = epochStartLoss[epoch];        // where it settles by end of epoch

        // Within-epoch decay: fast initial drop, then flattens
        const withinEpochLoss = endLoss + (startLoss - endLoss) * Math.exp(-t * 4);

        // Small bump at epoch boundary (reshuffled data)
        let bump = 0;
        if (stepInEpoch < 10) {
          bump = startLoss * 0.15 * Math.exp(-stepInEpoch * 0.4);
        }

        const noise = (seededRandom() - 0.5) * 0.015 * Math.max(0.02, withinEpochLoss);
        const loss = Math.max(0.005, withinEpochLoss + bump + noise);
        allTrainData.push({ step, loss });
      }

      // Pre-compute test loss for each step
      // Test loss: during first epoch tracks train loss,
      // after that improves but with growing gap above train loss
      const allTestLoss = [];
      for (let step = 0; step <= maxSteps; step++) {
        if (step <= stepsPerEpoch) {
          // During first epoch, test ≈ train
          allTestLoss.push(allTrainData[step].loss);
        } else {
          const epochsAfterFirst = (step - stepsPerEpoch) / stepsPerEpoch;
          // Test loss improves but slower than train loss
          // Floor: test loss can't go below some irreducible error
          const testFloor = endOfFirstEpochLoss * 0.25;
          const testLoss = testFloor + (endOfFirstEpochLoss - testFloor) * Math.exp(-epochsAfterFirst * 0.6);
          allTestLoss.push(testLoss);
        }
      }

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      // Fixed X scale - always shows 0 to maxSteps
      const x = d3.scaleLinear()
        .domain([0, maxSteps])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, initialLoss * 1.1])
        .range([height - margin.bottom, margin.top]);

      // X axis with epoch markers
      svg.append('g')
        .attr('class', 'axis x-axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).tickValues([0, 100, 200, 300, 400, 500])
          .tickFormat(d => `E${d/100}`))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 38)
        .attr('fill', 'currentColor')
        .text('Epoch');

      // Y axis
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -45)
        .attr('fill', 'currentColor')
        .text('Loss');

      // MDL area (first epoch only - always visible, light orange)
      const mdlArea = d3.area()
        .x(d => x(d.step))
        .y0(height - margin.bottom)
        .y1(d => y(d.loss));

      svg.append('path')
        .datum(firstEpochData)
        .attr('fill', colors.coralLight)
        .attr('opacity', 0.4)
        .attr('d', mdlArea);

      // First epoch boundary line
      svg.append('line')
        .attr('x1', x(stepsPerEpoch))
        .attr('x2', x(stepsPerEpoch))
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', '#999')
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '3,3');

      // Labels
      svg.append('text')
        .attr('x', x(50))
        .attr('y', margin.top + 15)
        .attr('font-size', '10px')
        .attr('fill', colors.coralLight)
        .attr('text-anchor', 'middle')
        .text('MDL (1st epoch)');

      svg.append('text')
        .attr('x', x(stepsPerEpoch) + 5)
        .attr('y', margin.top + 15)
        .attr('font-size', '9px')
        .attr('fill', '#999')
        .text('End of dataset');

      // Legend
      const meLegend = svg.append('g')
        .attr('transform', `translate(${width - margin.right - 150}, ${margin.top + 5})`);
      meLegend.append('line')
        .attr('x1', 0).attr('y1', 7).attr('x2', 18).attr('y2', 7)
        .attr('stroke', colors.coral).attr('stroke-width', 2);
      meLegend.append('text')
        .attr('x', 24).attr('y', 11).attr('font-size', '11px').attr('fill', '#333')
        .text('Train loss');
      meLegend.append('line')
        .attr('x1', 0).attr('y1', 25).attr('x2', 18).attr('y2', 25)
        .attr('stroke', '#000').attr('stroke-width', 2).attr('stroke-dasharray', '6,4');
      meLegend.append('text')
        .attr('x', 24).attr('y', 29).attr('font-size', '11px').attr('fill', '#333')
        .text('Test loss');

      // EDL area (area above test loss, UNDER FIRST EPOCH ONLY)
      const edlPath = svg.append('path')
        .attr('fill', colors.coral)
        .attr('opacity', 0.7);

      // First epoch curve (the MDL curve - static)
      svg.append('path')
        .datum(firstEpochData)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', d3.line().x(d => x(d.step)).y(d => y(d.loss)));

      // Train loss curve (continues past first epoch)
      const trainPath = svg.append('path')
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2);

      // Horizontal line at current test loss (extends full width)
      const testLossHLine = svg.append('line')
        .attr('stroke', '#000')
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '6,4');

      const testLossLabel = svg.append('text')
        .attr('font-size', '11px')
        .attr('fill', '#000');

      // Current position marker
      const positionMarker = svg.append('g');
      positionMarker.append('circle')
        .attr('r', 5)
        .attr('fill', colors.coral);
      positionMarker.append('line')
        .attr('y1', 0)
        .attr('y2', height - margin.bottom - margin.top)
        .attr('stroke', colors.coral)
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '2,2')
        .attr('opacity', 0.5);

      // Calculate totals
      function calculateTotals(currentStep) {
        // MDL is always the sum of losses in first epoch
        let mdl = 0;
        for (let i = 0; i < firstEpochData.length; i++) {
          mdl += firstEpochData[i].loss;
        }

        // EDL = area above test loss in first epoch ONLY
        const testLoss = allTestLoss[currentStep];
        let edl = 0;
        for (let i = 0; i < firstEpochData.length; i++) {
          if (firstEpochData[i].loss > testLoss) {
            edl += (firstEpochData[i].loss - testLoss);
          }
        }

        return { mdl: mdl.toFixed(0), edl: edl.toFixed(0) };
      }

      function updateVisualization(currentStep) {
        const testLoss = allTestLoss[currentStep];
        const currentTrainLoss = allTrainData[currentStep].loss;

        // Update EDL area - area above test loss under FIRST EPOCH ONLY
        const edlAreaGen = d3.area()
          .x(d => x(d.step))
          .y0(y(testLoss))
          .y1(d => y(Math.max(d.loss, testLoss)));

        edlPath.datum(firstEpochData.filter(d => d.loss > testLoss))
          .attr('d', edlAreaGen);

        // Update train curve (show up to current step)
        if (currentStep > stepsPerEpoch) {
          const trainLine = d3.line()
            .x(d => x(d.step))
            .y(d => y(d.loss));
          trainPath.datum(allTrainData.slice(stepsPerEpoch, currentStep + 1)).attr('d', trainLine);
        } else {
          trainPath.datum([]).attr('d', '');
        }

        // Update position marker
        positionMarker
          .attr('transform', `translate(${x(currentStep)}, ${y(currentTrainLoss)})`);
        positionMarker.select('line')
          .attr('y2', height - margin.bottom - y(currentTrainLoss));

        // Horizontal test loss line spanning full chart width
        testLossHLine
          .attr('x1', margin.left)
          .attr('x2', width - margin.right)
          .attr('y1', y(testLoss))
          .attr('y2', y(testLoss));

        testLossLabel
          .attr('x', width - margin.right - 5)
          .attr('y', y(testLoss) - 12)
          .attr('text-anchor', 'end');
        testLossLabel.selectAll('tspan').remove();
        testLossLabel.append('tspan').text('L');
        testLossLabel.append('tspan').attr('baseline-shift', 'sub').attr('font-size', '0.7em').text('test');
        testLossLabel.append('tspan').attr('baseline-shift', 'baseline').attr('font-size', '11px').text(` = ${testLoss.toFixed(2)}`);

        // Update totals and display
        const totals = calculateTotals(currentStep);
        document.getElementById('mdl-total').textContent = totals.mdl;
        document.getElementById('edl-total').textContent = totals.edl;
        document.getElementById('step-display').textContent = currentStep;
      }

      // Controls
      const slider = document.getElementById('step-slider');
      slider.addEventListener('input', (e) => {
        updateVisualization(parseInt(e.target.value));
      });

      // Play button
      let playing = false;
      let playInterval;
      const playBtn = document.getElementById('epoch-play');

      playBtn.addEventListener('click', () => {
        if (playing) {
          clearInterval(playInterval);
          playBtn.textContent = 'Play Training';
          playing = false;
        } else {
          let step = 0;
          slider.value = 0;
          updateVisualization(0);
          playBtn.textContent = 'Pause';
          playing = true;

          playInterval = setInterval(() => {
            step += 5;
            if (step > maxSteps) {
              clearInterval(playInterval);
              playBtn.textContent = 'Play Training';
              playing = false;
              return;
            }
            slider.value = step;
            updateVisualization(step);
          }, 50);
        }
      });

      // Initial render
      updateVisualization(0);
    }

    // ============================================================
    // VISUALIZATION 3: THE TWO SIGNATURES
    // ============================================================

    function initSignaturesVisualization() {
      const container = d3.select('#signatures-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 350;
      const margin = { top: 30, right: 30, bottom: 50, left: 70 };

      const data = generateSignaturesData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([1, 10000])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 0.6])
        .range([height - margin.bottom, margin.top]);

      // Grid
      svg.append('g')
        .attr('class', 'grid')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5).tickSize(-(height - margin.top - margin.bottom)).tickFormat(''));

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '~s'))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 40)
        .attr('fill', 'currentColor')
        .text('Number of training examples');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(6))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -50)
        .attr('fill', 'currentColor')
        .text('EDL per token');

      // Lines
      const line = d3.line()
        .x(d => x(d.n))
        .y(d => y(d.edl_per_token));

      const llamaPath = svg.append('path')
        .datum(data.llama)
        .attr('class', 'llama-line')
        .attr('fill', 'none')
        .attr('stroke', colors.blue)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      const tinyPath = svg.append('path')
        .datum(data.tinystories)
        .attr('class', 'tiny-line')
        .attr('fill', 'none')
        .attr('stroke', colors.orange)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      // Points
      const llamaPoints = svg.selectAll('.llama-point')
        .data(data.llama)
        .join('circle')
        .attr('class', 'llama-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.blue)
        .on('mouseover', (event, d) => {
          showTooltip(event, `n=${d.n}<br>EDL/token=${d.edl_per_token.toFixed(3)}`);
        })
        .on('mouseout', hideTooltip);

      const tinyPoints = svg.selectAll('.tiny-point')
        .data(data.tinystories)
        .join('circle')
        .attr('class', 'tiny-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.orange)
        .on('mouseover', (event, d) => {
          showTooltip(event, `n=${d.n}<br>EDL/token=${d.edl_per_token.toFixed(3)}`);
        })
        .on('mouseout', hideTooltip);

      // Annotations
      const llamaLabel = svg.append('text')
        .attr('x', x(3))
        .attr('y', y(0.55))
        .attr('font-size', '12px')
        .attr('fill', colors.blue)
        .text('Llama (Elicitation)');

      const tinyLabel = svg.append('text')
        .attr('x', x(500))
        .attr('y', y(0.48))
        .attr('font-size', '12px')
        .attr('fill', colors.orange)
        .text('TinyStories (Teaching)');

      // Toggle visibility
      let showLlama = true;
      let showTiny = true;

      function updateVisibility() {
        llamaPath.attr('opacity', showLlama ? 1 : 0);
        llamaPoints.attr('opacity', showLlama ? 1 : 0);
        llamaLabel.attr('opacity', showLlama ? 1 : 0);
        tinyPath.attr('opacity', showTiny ? 1 : 0);
        tinyPoints.attr('opacity', showTiny ? 1 : 0);
        tinyLabel.attr('opacity', showTiny ? 1 : 0);
      }

      document.getElementById('sig-llama').addEventListener('click', function() {
        showLlama = !showLlama;
        this.classList.toggle('active', showLlama);
        updateVisibility();
      });

      document.getElementById('sig-tiny').addEventListener('click', function() {
        showTiny = !showTiny;
        this.classList.toggle('active', showTiny);
        updateVisibility();
      });
    }

    // ============================================================
    // VISUALIZATION 4: THE CROSSOVER
    // ============================================================

    function initCrossoverVisualization() {
      const container = d3.select('#crossover-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 30, right: 30, bottom: 40, left: 60 };

      const data = generateCrossoverData();
      // Find the GLOBAL maximum (not local maximum, which can be thrown off by noise)
      let peakIdx = 0;
      let maxEdl = data[0].edl_per_token;
      for (let i = 1; i < data.length; i++) {
        if (data[i].edl_per_token > maxEdl) {
          maxEdl = data[i].edl_per_token;
          peakIdx = i;
        }
      }

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([d3.min(data, d => d.n), d3.max(data, d => d.n)])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, d3.max(data, d => d.edl_per_token) * 1.1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '~s'));

      // X axis label
      svg.append('text')
        .attr('x', width / 2)
        .attr('y', height - 5)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('Training examples');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5));

      // Y axis label
      svg.append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', 15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('EDL per token');

      // Teaching region (before peak)
      const teachingArea = d3.area()
        .x(d => x(d.n))
        .y0(height - margin.bottom)
        .y1(d => y(d.edl_per_token));

      svg.append('path')
        .datum(data.slice(0, peakIdx + 1))
        .attr('fill', colors.orange)
        .attr('opacity', 0.2)
        .attr('d', teachingArea);

      // Elicitation region (after peak)
      svg.append('path')
        .datum(data.slice(peakIdx))
        .attr('fill', colors.blue)
        .attr('opacity', 0.2)
        .attr('d', teachingArea);

      // Line
      const line = d3.line()
        .x(d => x(d.n))
        .y(d => y(d.edl_per_token))
        .curve(d3.curveMonotoneX);

      svg.append('path')
        .datum(data)
        .attr('fill', 'none')
        .attr('stroke', colors.darkBlue)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      // Peak marker
      svg.append('text')
        .attr('x', x(data[peakIdx].n))
        .attr('y', y(data[peakIdx].edl_per_token) - 15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '16px')
        .text('★');

      svg.append('text')
        .attr('x', x(data[peakIdx].n))
        .attr('y', y(data[peakIdx].edl_per_token) - 30)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', colors.darkBlue)
        .text('Capability acquired');

      // Draggable cursor
      const cursor = svg.append('g')
        .attr('class', 'cursor');

      cursor.append('line')
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '4,4');

      cursor.append('circle')
        .attr('r', 8)
        .attr('fill', colors.coral)
        .attr('cursor', 'ew-resize');

      let currentIdx = 10;

      function updateCursor(idx) {
        currentIdx = Math.max(0, Math.min(data.length - 1, idx));
        const d = data[currentIdx];

        cursor.attr('transform', `translate(${x(d.n)}, 0)`);
        cursor.select('circle').attr('cy', y(d.edl_per_token));

        const isTeaching = currentIdx < peakIdx;
        document.getElementById('crossover-state').innerHTML =
          `Currently: <span style="color: ${isTeaching ? colors.orange : colors.blue};">${isTeaching ? 'Teaching' : 'Eliciting'}</span>`;

        const slope = currentIdx > 0 ?
          (d.edl_per_token - data[currentIdx - 1].edl_per_token) /
          (Math.log10(d.n) - Math.log10(data[currentIdx - 1].n)) : 0;
        document.getElementById('crossover-slope').textContent =
          (slope >= 0 ? '+' : '') + slope.toFixed(3);
      }

      // Drag behavior
      const drag = d3.drag()
        .on('drag', function(event) {
          const mouseX = event.x;
          const n = x.invert(mouseX);
          const idx = data.findIndex(d => d.n >= n);
          updateCursor(idx >= 0 ? idx : data.length - 1);
        });

      cursor.call(drag);

      // Click to position
      svg.on('click', function(event) {
        const [mouseX] = d3.pointer(event);
        if (mouseX >= margin.left && mouseX <= width - margin.right) {
          const n = x.invert(mouseX);
          const idx = data.findIndex(d => d.n >= n);
          updateCursor(idx >= 0 ? idx : data.length - 1);
        }
      });

      updateCursor(10);
    }

    // ============================================================
    // VISUALIZATION 5: ONE EXAMPLE IS ALL YOU NEED
    // ============================================================

    function initOneExampleVisualization() {
      const container = d3.select('#one-example-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 30, right: 30, bottom: 60, left: 60 };

      const data = generateOneExampleData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x0 = d3.scaleBand()
        .domain(data.map(d => d.model))
        .range([margin.left, width - margin.right])
        .padding(0.3);

      const x1 = d3.scaleBand()
        .domain(['zero_shot', 'one_shot'])
        .range([0, x0.bandwidth()])
        .padding(0.1);

      const y = d3.scaleLinear()
        .domain([0, 1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x0))
        .selectAll('text')
        .attr('transform', 'rotate(-15)')
        .style('text-anchor', 'end');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).tickFormat(d3.format('.0%')));

      // Legend
      const legend = svg.append('g')
        .attr('transform', `translate(${width - margin.right - 150}, ${margin.top})`);

      legend.append('rect').attr('x', 0).attr('y', 0).attr('width', 15).attr('height', 15).attr('fill', '#ccc');
      legend.append('text').attr('x', 20).attr('y', 12).attr('font-size', '11px').text('Zero-shot');

      legend.append('rect').attr('x', 0).attr('y', 22).attr('width', 15).attr('height', 15).attr('fill', colors.coral);
      legend.append('text').attr('x', 20).attr('y', 34).attr('font-size', '11px').text('One-shot');

      // Bars
      const groups = svg.selectAll('.bar-group')
        .data(data)
        .join('g')
        .attr('class', 'bar-group')
        .attr('transform', d => `translate(${x0(d.model)}, 0)`);

      // Zero-shot bars
      groups.append('rect')
        .attr('class', 'zero-bar')
        .attr('x', x1('zero_shot'))
        .attr('y', y(0))
        .attr('width', x1.bandwidth())
        .attr('height', 0)
        .attr('fill', '#ccc');

      // One-shot bars
      groups.append('rect')
        .attr('class', 'one-bar')
        .attr('x', x1('one_shot'))
        .attr('y', y(0))
        .attr('width', x1.bandwidth())
        .attr('height', 0)
        .attr('fill', colors.coral);

      // Delta annotations
      const deltas = groups.append('text')
        .attr('class', 'delta-label')
        .attr('x', x1('one_shot') + x1.bandwidth() / 2)
        .attr('y', y(0) - 5)
        .attr('text-anchor', 'middle')
        .attr('font-size', '12px')
        .attr('font-weight', 'bold')
        .attr('fill', colors.coral)
        .attr('opacity', 0)
        .text(d => d.one_shot > 0.05 ? `+${Math.round(d.one_shot * 100)}pp` : '');

      function animateBars() {
        // Reset
        svg.selectAll('.zero-bar')
          .attr('y', y(0))
          .attr('height', 0);

        svg.selectAll('.one-bar')
          .attr('y', y(0))
          .attr('height', 0);

        deltas.attr('opacity', 0);

        // Animate zero-shot (stays at 0)
        svg.selectAll('.zero-bar')
          .data(data)
          .transition()
          .duration(500)
          .attr('y', d => y(d.zero_shot))
          .attr('height', d => y(0) - y(d.zero_shot));

        // Animate one-shot
        svg.selectAll('.one-bar')
          .data(data)
          .transition()
          .delay(600)
          .duration(800)
          .attr('y', d => y(d.one_shot))
          .attr('height', d => y(0) - y(d.one_shot));

        // Show deltas
        deltas
          .transition()
          .delay(1400)
          .duration(300)
          .attr('y', d => y(d.one_shot) - 8)
          .attr('opacity', 1);
      }

      // Intersection observer for scroll-triggered animation
      const observer = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            animateBars();
            observer.unobserve(entry.target);
          }
        });
      }, { threshold: 0.5 });

      observer.observe(container.node());

      // Replay button
      document.getElementById('animate-bars').addEventListener('click', animateBars);
    }

    // ============================================================
    // VISUALIZATION 6: THE CAUSAL INTERVENTION
    // ============================================================

    function initInterventionVisualization() {
      const container = d3.select('#intervention-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 300;
      const margin = { top: 30, right: 30, bottom: 40, left: 60 };

      const data = generateInterventionData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([1, 10000])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 0.6])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '~s'));

      // X axis label
      svg.append('text')
        .attr('x', width / 2)
        .attr('y', height - 5)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('Training examples');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(5));

      // Y axis label
      svg.append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', 15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '11px')
        .attr('fill', '#666')
        .text('EDL per token');

      const line = d3.line()
        .x(d => x(d.n))
        .y(d => y(d.edl_per_token))
        .curve(d3.curveMonotoneX);

      // Before line (teaching)
      const beforePath = svg.append('path')
        .datum(data.before)
        .attr('fill', 'none')
        .attr('stroke', colors.orange)
        .attr('stroke-width', 2.5)
        .attr('d', line);

      // After line (elicitation)
      const afterPath = svg.append('path')
        .datum(data.after)
        .attr('fill', 'none')
        .attr('stroke', colors.blue)
        .attr('stroke-width', 2.5)
        .attr('opacity', 0)
        .attr('d', line);

      // Before points
      const beforePoints = svg.selectAll('.before-point')
        .data(data.before)
        .join('circle')
        .attr('class', 'before-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.orange);

      // After points
      const afterPoints = svg.selectAll('.after-point')
        .data(data.after)
        .join('circle')
        .attr('class', 'after-point')
        .attr('cx', d => x(d.n))
        .attr('cy', d => y(d.edl_per_token))
        .attr('r', 5)
        .attr('fill', colors.blue)
        .attr('opacity', 0);

      // Labels
      const beforeLabel = svg.append('text')
        .attr('x', x(100))
        .attr('y', y(data.before[4].edl_per_token) - 10)
        .attr('font-size', '12px')
        .attr('fill', colors.orange)
        .text('Before: Teaching');

      const afterLabel = svg.append('text')
        .attr('x', x(100))
        .attr('y', y(data.after[4].edl_per_token) + 20)
        .attr('font-size', '12px')
        .attr('fill', colors.blue)
        .attr('opacity', 0)
        .text('After: Elicitation');

      // Threshold indicators
      const beforeThreshold = svg.append('line')
        .attr('x1', margin.left)
        .attr('x2', width - margin.right)
        .attr('y1', y(0.4))
        .attr('y2', y(0.4))
        .attr('stroke', colors.orange)
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '5,5')
        .attr('opacity', 0.5);

      const afterThreshold = svg.append('line')
        .attr('x1', margin.left)
        .attr('x2', width - margin.right)
        .attr('y1', y(0.1))
        .attr('y2', y(0.1))
        .attr('stroke', colors.blue)
        .attr('stroke-width', 1)
        .attr('stroke-dasharray', '5,5')
        .attr('opacity', 0);

      // Interpolation function
      function interpolateData(t) {
        return data.before.map((b, i) => ({
          n: b.n,
          edl_per_token: b.edl_per_token * (1 - t) + data.after[i].edl_per_token * t
        }));
      }

      // Slider control
      const slider = document.getElementById('intervention-slider');
      const stateLabel = document.getElementById('intervention-state');

      slider.addEventListener('input', (e) => {
        const t = e.target.value / 100;

        // Interpolate curve
        const interpolated = interpolateData(t);

        // Update paths
        beforePath.attr('opacity', 1 - t);
        afterPath.attr('opacity', t);

        // Update points
        beforePoints
          .data(interpolated)
          .attr('cy', d => y(d.edl_per_token))
          .attr('fill', d3.interpolateRgb(colors.orange, colors.blue)(t));

        afterPoints.attr('opacity', t);

        // Update labels
        beforeLabel.attr('opacity', 1 - t);
        afterLabel.attr('opacity', t);

        // Update thresholds
        beforeThreshold.attr('opacity', 0.5 * (1 - t));
        afterThreshold.attr('opacity', 0.5 * t);

        // Update state text
        if (t < 0.5) {
          stateLabel.textContent = 'Before: Teaching signature';
          stateLabel.style.color = colors.orange;
        } else {
          stateLabel.textContent = 'After: Elicitation signature';
          stateLabel.style.color = colors.blue;
        }
      });
    }

    // ============================================================
    // VISUALIZATION 7: THE CAPACITY CLIFF
    // ============================================================

    function initCapacityVisualization() {
      const container = d3.select('#capacity-chart');
      const width = container.node().getBoundingClientRect().width;
      const height = 350;
      const margin = { top: 30, right: 30, bottom: 50, left: 60 };

      let data = generateCapacityData();

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([0.0001, 10])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 1.05])
        .range([height - margin.bottom, margin.top]);

      // Color by regime: blue for elicitation, orange for teaching
      const regimeColor = (regime) => regime === 'elicitation' ? colors.blue : colors.orange;

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(5, '.0e'))
        .append('text')
        .attr('x', width / 2)
        .attr('y', 40)
        .attr('fill', 'currentColor')
        .text('EDL / trainable parameters (bits/param)');

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).tickFormat(d3.format('.0%')))
        .append('text')
        .attr('transform', 'rotate(-90)')
        .attr('x', -height / 2)
        .attr('y', -45)
        .attr('fill', 'currentColor')
        .text('Capacity');

      // Threshold lines
      svg.append('line')
        .attr('class', 'threshold elicit-threshold')
        .attr('x1', x(0.05))
        .attr('x2', x(0.05))
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', colors.blue)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '5,5');

      svg.append('text')
        .attr('x', x(0.05) + 5)
        .attr('y', margin.top + 15)
        .attr('font-size', '11px')
        .attr('fill', colors.blue)
        .text('Elicitation threshold (~0.05)');

      svg.append('line')
        .attr('class', 'threshold teach-threshold')
        .attr('x1', x(1))
        .attr('x2', x(1))
        .attr('y1', margin.top)
        .attr('y2', height - margin.bottom)
        .attr('stroke', colors.orange)
        .attr('stroke-width', 2)
        .attr('stroke-dasharray', '5,5');

      svg.append('text')
        .attr('x', x(1) + 5)
        .attr('y', margin.top + 30)
        .attr('font-size', '11px')
        .attr('fill', colors.orange)
        .text('Teaching threshold (~1)');

      // Points colored by regime (blue = elicitation, orange = teaching)
      const points = svg.selectAll('.cap-point')
        .data(data)
        .join('circle')
        .attr('class', 'cap-point')
        .attr('cx', d => x(d.edl_per_param))
        .attr('cy', d => y(d.capacity))
        .attr('r', 6)
        .attr('fill', d => regimeColor(d.regime))
        .attr('opacity', 0.7)
        .attr('stroke', 'white')
        .attr('stroke-width', 1)
        .on('mouseover', (event, d) => {
          showTooltip(event,
            `EDL/P: ${d.edl_per_param.toFixed(4)}<br>` +
            `Capacity: ${(d.capacity * 100).toFixed(1)}%<br>` +
            `Regime: ${d.regime}`
          );
        })
        .on('mouseout', hideTooltip);

      // Legend
      const legend = svg.append('g')
        .attr('transform', `translate(${width - margin.right - 80}, ${height - margin.bottom - 100})`);

      // Legend for regime colors
      const regimes = [
        { name: 'Elicitation', color: colors.blue },
        { name: 'Teaching', color: colors.orange }
      ];
      regimes.forEach((regime, i) => {
        legend.append('circle')
          .attr('cx', 0)
          .attr('cy', i * 20)
          .attr('r', 5)
          .attr('fill', regime.color);
        legend.append('text')
          .attr('x', 10)
          .attr('y', i * 20 + 4)
          .attr('font-size', '11px')
          .text(regime.name);
      });

      // Filters
      let showElicit = true;
      let showTeach = true;

      function updatePoints() {
        points
          .attr('opacity', d => {
            const regimeMatch = (d.regime === 'elicitation' && showElicit) ||
                               (d.regime === 'teaching' && showTeach);
            return regimeMatch ? 0.7 : 0.05;
          });
      }

      document.getElementById('cap-elicit').addEventListener('click', function() {
        showElicit = !showElicit;
        this.classList.toggle('active', showElicit);
        updatePoints();
      });

      document.getElementById('cap-teach').addEventListener('click', function() {
        showTeach = !showTeach;
        this.classList.toggle('active', showTeach);
        updatePoints();
      });
    }

    // ============================================================
    // VISUALIZATION: BACKFILL EFFECT
    // ============================================================

    function initBackfillVisualization() {
      const BF_N = 20;
      const BF_COLORS = {
        direct: '#2d9c6f',
        marginalBackfill: '#6a3d9a',
        accumBackfill: '#c4b0e0'
      };

      function teachingTestLoss(m) {
        return Math.max(1.0 - m * 0.048, 0.04);
      }

      function elicitationTestLoss(m) {
        return 0.04 + 0.96 * Math.exp(-0.7 * m);
      }

      function bfTrainLoss(testLossFn, i) {
        return testLossFn(i - 1);
      }

      function computeEDL(testLossFn, m) {
        if (m === 0) return {
          bars: [], totalEDL: 0, edlPerToken: 0, marginalEDL: 0,
          testLoss: testLossFn(0), prevTestLoss: testLossFn(0)
        };

        const currentTestLoss = testLossFn(m);
        const prevTestLoss = m > 0 ? testLossFn(m - 1) : testLossFn(0);
        const deltaTestLoss = Math.max(prevTestLoss - currentTestLoss, 0);

        const bars = [];
        let totalEDL = 0;

        for (let i = 1; i <= m; i++) {
          const tl = bfTrainLoss(testLossFn, i);
          const testAtI = testLossFn(i);
          const direct = Math.max(tl - testAtI, 0);
          const totalBackfill = Math.max(testAtI - currentTestLoss, 0);

          let marginalBf, accumBf;
          if (i < m) {
            marginalBf = Math.min(deltaTestLoss, totalBackfill);
            accumBf = Math.max(totalBackfill - marginalBf, 0);
          } else {
            marginalBf = 0;
            accumBf = 0;
          }

          const total = direct + totalBackfill;
          bars.push({ index: i, trainLoss: tl, direct, accumBackfill: accumBf, marginalBackfill: marginalBf, total });
          totalEDL += total;
        }

        let prevEDL = 0;
        if (m > 1) {
          for (let i = 1; i <= m - 1; i++) {
            const tl = bfTrainLoss(testLossFn, i);
            const testAtI = testLossFn(i);
            const direct = Math.max(tl - testAtI, 0);
            const backfill = Math.max(testAtI - prevTestLoss, 0);
            prevEDL += direct + backfill;
          }
        }

        return { bars, totalEDL, edlPerToken: totalEDL / m, marginalEDL: totalEDL - prevEDL, testLoss: currentTestLoss, prevTestLoss };
      }

      const BF_MARGIN = { top: 25, right: 20, bottom: 35, left: 50 };
      const BF_WIDTH = 480, BF_HEIGHT = 320;
      const BF_CHART_W = BF_WIDTH - BF_MARGIN.left - BF_MARGIN.right;
      const BF_CHART_H = BF_HEIGHT - BF_MARGIN.top - BF_MARGIN.bottom;
      const BF_BAR_GAP = 3;
      const BF_BAR_W = (BF_CHART_W / BF_N) - BF_BAR_GAP;
      const BF_Y_MAX = 1.05;

      function bfYScale(val) { return BF_MARGIN.top + BF_CHART_H * (1 - val / BF_Y_MAX); }
      function bfXScale(i) { return BF_MARGIN.left + (i - 1) * (BF_BAR_W + BF_BAR_GAP) + BF_BAR_GAP / 2; }

      function bfCreateEl(tag, attrs) {
        const el = document.createElementNS('http://www.w3.org/2000/svg', tag);
        for (const [k, v] of Object.entries(attrs)) el.setAttribute(k, v);
        return el;
      }

      function bfDrawAxes(svg) {
        svg.appendChild(bfCreateEl('line', { x1: BF_MARGIN.left, y1: BF_MARGIN.top, x2: BF_MARGIN.left, y2: BF_MARGIN.top + BF_CHART_H, class: 'bf-axis-line' }));
        svg.appendChild(bfCreateEl('line', { x1: BF_MARGIN.left, y1: BF_MARGIN.top + BF_CHART_H, x2: BF_MARGIN.left + BF_CHART_W, y2: BF_MARGIN.top + BF_CHART_H, class: 'bf-axis-line' }));

        for (let v = 0; v <= 1.0; v += 0.2) {
          const yy = bfYScale(v);
          svg.appendChild(bfCreateEl('line', { x1: BF_MARGIN.left - 4, y1: yy, x2: BF_MARGIN.left, y2: yy, class: 'bf-axis-line' }));
          const label = bfCreateEl('text', { x: BF_MARGIN.left - 8, y: yy + 3.5, 'text-anchor': 'end', class: 'bf-tick-label' });
          label.textContent = v.toFixed(1);
          svg.appendChild(label);
        }

        const yTitle = bfCreateEl('text', { x: 14, y: BF_MARGIN.top + BF_CHART_H / 2, 'text-anchor': 'middle', class: 'bf-axis-title', transform: `rotate(-90, 14, ${BF_MARGIN.top + BF_CHART_H / 2})` });
        yTitle.textContent = 'Bits';
        svg.appendChild(yTitle);

        const xTitle = bfCreateEl('text', { x: BF_MARGIN.left + BF_CHART_W / 2, y: BF_HEIGHT - 4, 'text-anchor': 'middle', class: 'bf-axis-title' });
        xTitle.textContent = 'Training example';
        svg.appendChild(xTitle);

        [1, 5, 10, 15, 20].forEach(i => {
          const xx = bfXScale(i) + BF_BAR_W / 2;
          const label = bfCreateEl('text', { x: xx, y: BF_MARGIN.top + BF_CHART_H + 14, 'text-anchor': 'middle', class: 'bf-tick-label' });
          label.textContent = i;
          svg.appendChild(label);
        });
      }

      function bfDrawBars(svg, data) {
        svg.querySelectorAll('.bf-bar-direct, .bf-bar-accum, .bf-bar-marginal, .bf-floor-line, .bf-test-loss-label')
          .forEach(el => el.remove());

        if (data.bars.length === 0) return;

        const floorY = bfYScale(data.testLoss);
        svg.appendChild(bfCreateEl('line', { x1: BF_MARGIN.left, y1: floorY, x2: BF_MARGIN.left + BF_CHART_W, y2: floorY, class: 'bf-floor-line' }));

        const floorLabel = bfCreateEl('text', { x: BF_MARGIN.left + BF_CHART_W + 2, y: floorY + 3, class: 'bf-test-loss-label' });
        floorLabel.textContent = `L=${data.testLoss.toFixed(2)}`;
        svg.appendChild(floorLabel);

        data.bars.forEach(bar => {
          const xx = bfXScale(bar.index);
          const directH = (bar.direct / BF_Y_MAX) * BF_CHART_H;
          const accumBfH = (bar.accumBackfill / BF_Y_MAX) * BF_CHART_H;
          const margBfH = (bar.marginalBackfill / BF_Y_MAX) * BF_CHART_H;

          let cursor = floorY;

          if (margBfH > 0.3) {
            cursor -= margBfH;
            svg.appendChild(bfCreateEl('rect', { x: xx, y: cursor, width: BF_BAR_W, height: margBfH, fill: BF_COLORS.marginalBackfill, opacity: '0.9', rx: '1', class: 'bf-bar-marginal' }));
          }
          if (accumBfH > 0.3) {
            cursor -= accumBfH;
            svg.appendChild(bfCreateEl('rect', { x: xx, y: cursor, width: BF_BAR_W, height: accumBfH, fill: BF_COLORS.accumBackfill, opacity: '0.85', rx: '1', class: 'bf-bar-accum' }));
          }
          if (directH > 0.3) {
            cursor -= directH;
            svg.appendChild(bfCreateEl('rect', { x: xx, y: cursor, width: BF_BAR_W, height: directH, fill: BF_COLORS.direct, opacity: '0.9', rx: '1', class: 'bf-bar-direct' }));
          }
        });
      }

      const svgT = document.getElementById('bf-svg-teaching');
      const svgE = document.getElementById('bf-svg-elicitation');
      if (!svgT || !svgE) return;

      bfDrawAxes(svgT);
      bfDrawAxes(svgE);

      function bfUpdate(m) {
        const teachData = computeEDL(teachingTestLoss, m);
        const elicitData = computeEDL(elicitationTestLoss, m);

        bfDrawBars(svgT, teachData);
        bfDrawBars(svgE, elicitData);

        document.getElementById('bf-edl-teaching').textContent = teachData.totalEDL.toFixed(2) + ' bits';
        document.getElementById('bf-edl-elicitation').textContent = elicitData.totalEDL.toFixed(2) + ' bits';

        if (m > 0) {
          document.getElementById('bf-edl-per-token-teaching').textContent = teachData.edlPerToken.toFixed(3) + ' bits';
          document.getElementById('bf-edl-per-token-elicitation').textContent = elicitData.edlPerToken.toFixed(3) + ' bits';
          document.getElementById('bf-marginal-teaching').textContent = teachData.marginalEDL.toFixed(3) + ' bits';
          document.getElementById('bf-marginal-elicitation').textContent = elicitData.marginalEDL.toFixed(3) + ' bits';
        } else {
          document.getElementById('bf-edl-per-token-teaching').textContent = '—';
          document.getElementById('bf-edl-per-token-elicitation').textContent = '—';
          document.getElementById('bf-marginal-teaching').textContent = '—';
          document.getElementById('bf-marginal-elicitation').textContent = '—';
        }

        if (m >= 2) {
          const prevTeach = computeEDL(teachingTestLoss, m - 1);
          const prevElicit = computeEDL(elicitationTestLoss, m - 1);
          const teachTrend = teachData.edlPerToken > prevTeach.edlPerToken;
          const elicitTrend = elicitData.edlPerToken > prevElicit.edlPerToken;
          document.getElementById('bf-trend-teaching').textContent = teachTrend ? '↑ increasing' : '↓ decreasing';
          document.getElementById('bf-trend-teaching').className = 'bf-trend ' + (teachTrend ? 'up' : 'down');
          document.getElementById('bf-trend-elicitation').textContent = elicitTrend ? '↑ increasing' : '↓ decreasing';
          document.getElementById('bf-trend-elicitation').className = 'bf-trend ' + (elicitTrend ? 'up' : 'down');
        } else {
          document.getElementById('bf-trend-teaching').textContent = '';
          document.getElementById('bf-trend-elicitation').textContent = '';
        }

        document.getElementById('bf-count').textContent = m;
      }

      const bfSlider = document.getElementById('bf-slider');
      bfSlider.addEventListener('input', () => bfUpdate(parseInt(bfSlider.value)));
      bfUpdate(0);
    }

    // ============================================================
    // VISUALIZATION 8: ADAPTER SIZE CALCULATOR
    // ============================================================

    function initCalculator() {
      const container = d3.select('#calc-viz');
      const width = container.node().getBoundingClientRect().width;
      const height = 150;
      const margin = { top: 20, right: 20, bottom: 30, left: 50 };

      const svg = container.append('svg')
        .attr('viewBox', `0 0 ${width} ${height}`);

      const x = d3.scaleLog()
        .domain([0.001, 10])
        .range([margin.left, width - margin.right]);

      const y = d3.scaleLinear()
        .domain([0, 1])
        .range([height - margin.bottom, margin.top]);

      // Axes
      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(x).ticks(4, '.0e'));

      svg.append('g')
        .attr('class', 'axis')
        .attr('transform', `translate(${margin.left},0)`)
        .call(d3.axisLeft(y).ticks(3).tickFormat(d3.format('.0%')));

      // Capacity curve
      const curveData = [];
      for (let i = -3; i <= 1; i += 0.1) {
        const edlP = Math.pow(10, i);
        const threshold = 0.05;
        const capacity = edlP < threshold ? 0.95 : Math.max(0.1, 0.95 - (edlP - threshold) * 3);
        curveData.push({ edlP, capacity });
      }

      const line = d3.line()
        .x(d => x(d.edlP))
        .y(d => y(d.capacity))
        .curve(d3.curveMonotoneX);

      svg.append('path')
        .datum(curveData)
        .attr('fill', 'none')
        .attr('stroke', colors.coral)
        .attr('stroke-width', 2)
        .attr('d', line);

      // "You are here" marker
      const marker = svg.append('g')
        .attr('class', 'marker');

      marker.append('circle')
        .attr('r', 8)
        .attr('fill', colors.darkBlue);

      marker.append('text')
        .attr('y', -15)
        .attr('text-anchor', 'middle')
        .attr('font-size', '10px')
        .attr('fill', colors.darkBlue)
        .text('You are here');

      function updateCalculator() {
        const edl = parseFloat(document.getElementById('calc-edl').value) || 10000;
        const modelSelect = document.getElementById('calc-model');
        let modelParams;

        if (modelSelect.value === 'custom') {
          modelParams = parseFloat(document.getElementById('calc-custom-params').value) || 8e9;
          document.getElementById('custom-params-group').style.display = 'block';
        } else {
          modelParams = parseFloat(modelSelect.value);
          document.getElementById('custom-params-group').style.display = 'none';
        }

        const regime = document.getElementById('calc-regime').value;
        const targetCap = parseFloat(document.getElementById('calc-target').value);

        document.getElementById('target-cap-display').textContent = targetCap.toFixed(2);

        // Determine threshold based on regime
        let threshold;
        if (regime === 'elicitation') {
          threshold = 0.05;
        } else if (regime === 'teaching') {
          threshold = 1.0;
        } else {
          // Auto-detect: use elicitation if EDL is small relative to model
          threshold = edl / modelParams < 0.1 ? 0.05 : 1.0;
        }

        // Calculate required parameters
        const requiredParams = edl / (threshold * targetCap);

        // Estimate LoRA rank (assuming roughly 2 * hidden_dim * rank * num_layers trainable params)
        // For 8B model: hidden_dim ~4096, num_layers ~32, so params ≈ rank * 524288
        const paramsPerRank = modelParams / 30000; // rough estimate
        let rank = Math.ceil(requiredParams / paramsPerRank);
        rank = Math.max(1, Math.min(1024, Math.pow(2, Math.ceil(Math.log2(rank)))));

        const actualParams = rank * paramsPerRank;
        const actualEdlP = edl / actualParams;

        // Update display
        document.getElementById('calc-rank').textContent = rank;
        document.getElementById('calc-params').textContent =
          actualParams >= 1e9 ? `~${(actualParams / 1e9).toFixed(1)}B` :
          actualParams >= 1e6 ? `~${(actualParams / 1e6).toFixed(1)}M` :
          `~${(actualParams / 1e3).toFixed(1)}K`;

        // Warning
        const warning = document.getElementById('calc-warning');
        if (requiredParams > modelParams * 0.1) {
          warning.style.display = 'block';
          warning.textContent = 'Warning: Required capacity exceeds typical LoRA limits. Consider full fine-tuning or a larger model.';
        } else if (rank > 256) {
          warning.style.display = 'block';
          warning.textContent = 'Note: High rank recommended. This approaches full fine-tuning efficiency.';
        } else {
          warning.style.display = 'none';
        }

        // Update marker
        const clampedEdlP = Math.max(0.001, Math.min(10, actualEdlP));
        const capacity = clampedEdlP < threshold ? 0.95 : Math.max(0.1, 0.95 - (clampedEdlP - threshold) * 3);

        marker
          .attr('transform', `translate(${x(clampedEdlP)}, ${y(Math.min(1, capacity))})`);
      }

      // Event listeners
      ['calc-edl', 'calc-model', 'calc-custom-params', 'calc-regime', 'calc-target'].forEach(id => {
        document.getElementById(id).addEventListener('input', updateCalculator);
        document.getElementById(id).addEventListener('change', updateCalculator);
      });

      updateCalculator();
    }

    // ============================================================
    // INITIALIZE ALL VISUALIZATIONS
    // ============================================================

    document.addEventListener('DOMContentLoaded', () => {
      initMDLVisualization();
      initEDLDecomposition();
      initMultiEpochVisualization();
      initSignaturesVisualization();
      initCrossoverVisualization();
      initOneExampleVisualization();
      initInterventionVisualization();
      initCapacityVisualization();
      initBackfillVisualization();
      initCalculator();
    });
  </script>
</body>
</html>
